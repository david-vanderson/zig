diff --git a/lib/std/Thread.zig b/lib/std/Thread.zig
index a611ff38d..331e722d8 100644
--- a/lib/std/Thread.zig
+++ b/lib/std/Thread.zig
@@ -50,7 +50,7 @@ pub const SetNameError = error{
     Unexpected,
 } || os.PrctlError || os.WriteError || std.fs.File.OpenError || std.fmt.BufPrintError;
 
-pub fn setName(self: Thread, name: []const u8) SetNameError!void {
+pub fn setName(self: *const Thread, name: []const u8) SetNameError!void {
     if (name.len > max_name_len) return error.NameTooLong;
 
     const name_with_terminator = blk: {
@@ -164,7 +164,7 @@ pub const GetNameError = error{
     Unexpected,
 } || os.PrctlError || os.ReadError || std.fs.File.OpenError || std.fmt.BufPrintError;
 
-pub fn getName(self: Thread, buffer_ptr: *[max_name_len:0]u8) GetNameError!?[]const u8 {
+pub fn getName(self: *const Thread, buffer_ptr: *[max_name_len:0]u8) GetNameError!?[]const u8 {
     buffer_ptr[max_name_len] = 0;
     var buffer = std.mem.span(buffer_ptr);
 
@@ -332,19 +332,19 @@ pub fn spawn(config: SpawnConfig, comptime function: anytype, args: anytype) Spa
 pub const Handle = Impl.ThreadHandle;
 
 /// Returns the handle of this thread
-pub fn getHandle(self: Thread) Handle {
+pub fn getHandle(self: *const Thread) Handle {
     return self.impl.getHandle();
 }
 
 /// Release the obligation of the caller to call `join()` and have the thread clean up its own resources on completion.
 /// Once called, this consumes the Thread object and invoking any other functions on it is considered undefined behavior.
-pub fn detach(self: Thread) void {
+pub fn detach(self: *const Thread) void {
     return self.impl.detach();
 }
 
 /// Waits for the thread to complete, then deallocates any resources created on `spawn()`.
 /// Once called, this consumes the Thread object and invoking any other functions on it is considered undefined behavior.
-pub fn join(self: Thread) void {
+pub fn join(self: *const Thread) void {
     return self.impl.join();
 }
 
@@ -443,15 +443,15 @@ const UnsupportedImpl = struct {
         return unsupported(.{ config, f, args });
     }
 
-    fn getHandle(self: Impl) ThreadHandle {
+    fn getHandle(self: *const Impl) ThreadHandle {
         return unsupported(self);
     }
 
-    fn detach(self: Impl) void {
+    fn detach(self: *const Impl) void {
         return unsupported(self);
     }
 
-    fn join(self: Impl) void {
+    fn join(self: *const Impl) void {
         return unsupported(self);
     }
 
@@ -483,7 +483,7 @@ const WindowsThreadImpl = struct {
         heap_handle: windows.HANDLE,
         thread_handle: windows.HANDLE = undefined,
 
-        fn free(self: ThreadCompletion) void {
+        fn free(self: *const ThreadCompletion) void {
             const status = windows.kernel32.HeapFree(self.heap_handle, 0, self.heap_ptr);
             assert(status != 0);
         }
@@ -544,11 +544,11 @@ const WindowsThreadImpl = struct {
         return Impl{ .thread = &instance.thread };
     }
 
-    fn getHandle(self: Impl) ThreadHandle {
+    fn getHandle(self: *const Impl) ThreadHandle {
         return self.thread.thread_handle;
     }
 
-    fn detach(self: Impl) void {
+    fn detach(self: *const Impl) void {
         windows.CloseHandle(self.thread.thread_handle);
         switch (self.thread.completion.swap(.detached, .SeqCst)) {
             .running => {},
@@ -557,7 +557,7 @@ const WindowsThreadImpl = struct {
         }
     }
 
-    fn join(self: Impl) void {
+    fn join(self: *const Impl) void {
         windows.WaitForSingleObjectEx(self.thread.thread_handle, windows.INFINITE, false) catch unreachable;
         windows.CloseHandle(self.thread.thread_handle);
         assert(self.thread.completion.load(.SeqCst) == .completed);
@@ -695,11 +695,11 @@ const PosixThreadImpl = struct {
         }
     }
 
-    fn getHandle(self: Impl) ThreadHandle {
+    fn getHandle(self: *const Impl) ThreadHandle {
         return self.handle;
     }
 
-    fn detach(self: Impl) void {
+    fn detach(self: *const Impl) void {
         switch (c.pthread_detach(self.handle)) {
             .SUCCESS => {},
             .INVAL => unreachable, // thread handle is not joinable
@@ -708,7 +708,7 @@ const PosixThreadImpl = struct {
         }
     }
 
-    fn join(self: Impl) void {
+    fn join(self: *const Impl) void {
         switch (c.pthread_join(self.handle, null)) {
             .SUCCESS => {},
             .INVAL => unreachable, // thread handle is not joinable (or another thread is already joining in)
@@ -1008,11 +1008,11 @@ const LinuxThreadImpl = struct {
         }
     }
 
-    fn getHandle(self: Impl) ThreadHandle {
+    fn getHandle(self: *const Impl) ThreadHandle {
         return self.thread.parent_tid;
     }
 
-    fn detach(self: Impl) void {
+    fn detach(self: *const Impl) void {
         switch (self.thread.completion.swap(.detached, .SeqCst)) {
             .running => {},
             .completed => self.join(),
@@ -1020,7 +1020,7 @@ const LinuxThreadImpl = struct {
         }
     }
 
-    fn join(self: Impl) void {
+    fn join(self: *const Impl) void {
         defer os.munmap(self.thread.mapped);
 
         var spin: u8 = 10;
diff --git a/lib/std/Thread/Mutex.zig b/lib/std/Thread/Mutex.zig
index 973a31266..94f93f1d2 100644
--- a/lib/std/Thread/Mutex.zig
+++ b/lib/std/Thread/Mutex.zig
@@ -206,7 +206,7 @@ const NonAtomicCounter = struct {
     // direct u128 could maybe use xmm ops on x86 which are atomic
     value: [2]u64 = [_]u64{ 0, 0 },
 
-    fn get(self: NonAtomicCounter) u128 {
+    fn get(self: *const NonAtomicCounter) u128 {
         return @bitCast(u128, self.value);
     }
 
diff --git a/lib/std/array_hash_map.zig b/lib/std/array_hash_map.zig
index a502c5fa3..dd8356061 100644
--- a/lib/std/array_hash_map.zig
+++ b/lib/std/array_hash_map.zig
@@ -150,18 +150,18 @@ pub fn ArrayHashMap(
         }
 
         /// Returns the number of KV pairs stored in this map.
-        pub fn count(self: Self) usize {
+        pub fn count(self: *const Self) usize {
             return self.unmanaged.count();
         }
 
         /// Returns the backing array of keys in this map.
         /// Modifying the map may invalidate this array.
-        pub fn keys(self: Self) []K {
+        pub fn keys(self: *const Self) []K {
             return self.unmanaged.keys();
         }
         /// Returns the backing array of values in this map.
         /// Modifying the map may invalidate this array.
-        pub fn values(self: Self) []V {
+        pub fn values(self: *const Self) []V {
             return self.unmanaged.values();
         }
 
@@ -258,58 +258,58 @@ pub fn ArrayHashMap(
         }
 
         /// Finds pointers to the key and value storage associated with a key.
-        pub fn getEntry(self: Self, key: K) ?Entry {
+        pub fn getEntry(self: *const Self, key: K) ?Entry {
             return self.unmanaged.getEntryContext(key, self.ctx);
         }
-        pub fn getEntryAdapted(self: Self, key: anytype, ctx: anytype) ?Entry {
+        pub fn getEntryAdapted(self: *const Self, key: anytype, ctx: anytype) ?Entry {
             return self.unmanaged.getEntryAdapted(key, ctx);
         }
 
         /// Finds the index in the `entries` array where a key is stored
-        pub fn getIndex(self: Self, key: K) ?usize {
+        pub fn getIndex(self: *const Self, key: K) ?usize {
             return self.unmanaged.getIndexContext(key, self.ctx);
         }
-        pub fn getIndexAdapted(self: Self, key: anytype, ctx: anytype) ?usize {
+        pub fn getIndexAdapted(self: *const Self, key: anytype, ctx: anytype) ?usize {
             return self.unmanaged.getIndexAdapted(key, ctx);
         }
 
         /// Find the value associated with a key
-        pub fn get(self: Self, key: K) ?V {
+        pub fn get(self: *const Self, key: K) ?V {
             return self.unmanaged.getContext(key, self.ctx);
         }
-        pub fn getAdapted(self: Self, key: anytype, ctx: anytype) ?V {
+        pub fn getAdapted(self: *const Self, key: anytype, ctx: anytype) ?V {
             return self.unmanaged.getAdapted(key, ctx);
         }
 
         /// Find a pointer to the value associated with a key
-        pub fn getPtr(self: Self, key: K) ?*V {
+        pub fn getPtr(self: *const Self, key: K) ?*V {
             return self.unmanaged.getPtrContext(key, self.ctx);
         }
-        pub fn getPtrAdapted(self: Self, key: anytype, ctx: anytype) ?*V {
+        pub fn getPtrAdapted(self: *const Self, key: anytype, ctx: anytype) ?*V {
             return self.unmanaged.getPtrAdapted(key, ctx);
         }
 
         /// Find the actual key associated with an adapted key
-        pub fn getKey(self: Self, key: K) ?K {
+        pub fn getKey(self: *const Self, key: K) ?K {
             return self.unmanaged.getKeyContext(key, self.ctx);
         }
-        pub fn getKeyAdapted(self: Self, key: anytype, ctx: anytype) ?K {
+        pub fn getKeyAdapted(self: *const Self, key: anytype, ctx: anytype) ?K {
             return self.unmanaged.getKeyAdapted(key, ctx);
         }
 
         /// Find a pointer to the actual key associated with an adapted key
-        pub fn getKeyPtr(self: Self, key: K) ?*K {
+        pub fn getKeyPtr(self: *const Self, key: K) ?*K {
             return self.unmanaged.getKeyPtrContext(key, self.ctx);
         }
-        pub fn getKeyPtrAdapted(self: Self, key: anytype, ctx: anytype) ?*K {
+        pub fn getKeyPtrAdapted(self: *const Self, key: anytype, ctx: anytype) ?*K {
             return self.unmanaged.getKeyPtrAdapted(key, ctx);
         }
 
         /// Check whether a key is stored in the map
-        pub fn contains(self: Self, key: K) bool {
+        pub fn contains(self: *const Self, key: K) bool {
             return self.unmanaged.containsContext(key, self.ctx);
         }
-        pub fn containsAdapted(self: Self, key: anytype, ctx: anytype) bool {
+        pub fn containsAdapted(self: *const Self, key: anytype, ctx: anytype) bool {
             return self.unmanaged.containsAdapted(key, ctx);
         }
 
@@ -374,27 +374,27 @@ pub fn ArrayHashMap(
 
         /// Create a copy of the hash map which can be modified separately.
         /// The copy uses the same context and allocator as this instance.
-        pub fn clone(self: Self) !Self {
+        pub fn clone(self: *const Self) !Self {
             var other = try self.unmanaged.cloneContext(self.allocator, self.ctx);
             return other.promoteContext(self.allocator, self.ctx);
         }
         /// Create a copy of the hash map which can be modified separately.
         /// The copy uses the same context as this instance, but the specified
         /// allocator.
-        pub fn cloneWithAllocator(self: Self, allocator: Allocator) !Self {
+        pub fn cloneWithAllocator(self: *const Self, allocator: Allocator) !Self {
             var other = try self.unmanaged.cloneContext(allocator, self.ctx);
             return other.promoteContext(allocator, self.ctx);
         }
         /// Create a copy of the hash map which can be modified separately.
         /// The copy uses the same allocator as this instance, but the
         /// specified context.
-        pub fn cloneWithContext(self: Self, ctx: anytype) !ArrayHashMap(K, V, @TypeOf(ctx), store_hash) {
+        pub fn cloneWithContext(self: *const Self, ctx: anytype) !ArrayHashMap(K, V, @TypeOf(ctx), store_hash) {
             var other = try self.unmanaged.cloneContext(self.allocator, ctx);
             return other.promoteContext(self.allocator, ctx);
         }
         /// Create a copy of the hash map which can be modified separately.
         /// The copy uses the specified allocator and context.
-        pub fn cloneWithAllocatorAndContext(self: Self, allocator: Allocator, ctx: anytype) !ArrayHashMap(K, V, @TypeOf(ctx), store_hash) {
+        pub fn cloneWithAllocatorAndContext(self: *const Self, allocator: Allocator, ctx: anytype) !ArrayHashMap(K, V, @TypeOf(ctx), store_hash) {
             var other = try self.unmanaged.cloneContext(allocator, ctx);
             return other.promoteContext(allocator, ctx);
         }
@@ -541,14 +541,14 @@ pub fn ArrayHashMapUnmanaged(
 
         /// Convert from an unmanaged map to a managed map.  After calling this,
         /// the promoted map should no longer be used.
-        pub fn promote(self: Self, allocator: Allocator) Managed {
+        pub fn promote(self: *const Self, allocator: Allocator) Managed {
             if (@sizeOf(Context) != 0)
                 @compileError("Cannot infer context " ++ @typeName(Context) ++ ", call promoteContext instead.");
             return self.promoteContext(allocator, undefined);
         }
-        pub fn promoteContext(self: Self, allocator: Allocator, ctx: Context) Managed {
+        pub fn promoteContext(self: *const Self, allocator: Allocator, ctx: Context) Managed {
             return .{
-                .unmanaged = self,
+                .unmanaged = self.*,
                 .allocator = allocator,
                 .ctx = ctx,
             };
@@ -587,24 +587,24 @@ pub fn ArrayHashMapUnmanaged(
         }
 
         /// Returns the number of KV pairs stored in this map.
-        pub fn count(self: Self) usize {
+        pub fn count(self: *const Self) usize {
             return self.entries.len;
         }
 
         /// Returns the backing array of keys in this map.
         /// Modifying the map may invalidate this array.
-        pub fn keys(self: Self) []K {
+        pub fn keys(self: *const Self) []K {
             return self.entries.items(.key);
         }
         /// Returns the backing array of values in this map.
         /// Modifying the map may invalidate this array.
-        pub fn values(self: Self) []V {
+        pub fn values(self: *const Self) []V {
             return self.entries.items(.value);
         }
 
         /// Returns an iterator over the pairs in this map.
         /// Modifying the map may invalidate this iterator.
-        pub fn iterator(self: Self) Iterator {
+        pub fn iterator(self: *const Self) Iterator {
             const slice = self.entries.slice();
             return .{
                 .keys = slice.items(.key).ptr,
@@ -805,7 +805,7 @@ pub fn ArrayHashMapUnmanaged(
 
         /// Returns the number of total elements which may be present before it is
         /// no longer guaranteed that no allocations will be performed.
-        pub fn capacity(self: Self) usize {
+        pub fn capacity(self: *const Self) usize {
             const entry_cap = self.entries.capacity;
             const header = self.index_header orelse return math.min(linear_scan_max, entry_cap);
             const indexes_cap = header.capacity();
@@ -904,15 +904,15 @@ pub fn ArrayHashMapUnmanaged(
         }
 
         /// Finds pointers to the key and value storage associated with a key.
-        pub fn getEntry(self: Self, key: K) ?Entry {
+        pub fn getEntry(self: *const Self, key: K) ?Entry {
             if (@sizeOf(Context) != 0)
                 @compileError("Cannot infer context " ++ @typeName(Context) ++ ", call getEntryContext instead.");
             return self.getEntryContext(key, undefined);
         }
-        pub fn getEntryContext(self: Self, key: K, ctx: Context) ?Entry {
+        pub fn getEntryContext(self: *const Self, key: K, ctx: Context) ?Entry {
             return self.getEntryAdapted(key, ctx);
         }
-        pub fn getEntryAdapted(self: Self, key: anytype, ctx: anytype) ?Entry {
+        pub fn getEntryAdapted(self: *const Self, key: anytype, ctx: anytype) ?Entry {
             const index = self.getIndexAdapted(key, ctx) orelse return null;
             const slice = self.entries.slice();
             return Entry{
@@ -923,15 +923,15 @@ pub fn ArrayHashMapUnmanaged(
         }
 
         /// Finds the index in the `entries` array where a key is stored
-        pub fn getIndex(self: Self, key: K) ?usize {
+        pub fn getIndex(self: *const Self, key: K) ?usize {
             if (@sizeOf(Context) != 0)
                 @compileError("Cannot infer context " ++ @typeName(Context) ++ ", call getIndexContext instead.");
             return self.getIndexContext(key, undefined);
         }
-        pub fn getIndexContext(self: Self, key: K, ctx: Context) ?usize {
+        pub fn getIndexContext(self: *const Self, key: K, ctx: Context) ?usize {
             return self.getIndexAdapted(key, ctx);
         }
-        pub fn getIndexAdapted(self: Self, key: anytype, ctx: anytype) ?usize {
+        pub fn getIndexAdapted(self: *const Self, key: anytype, ctx: anytype) ?usize {
             const header = self.index_header orelse {
                 // Linear scan.
                 const h = if (store_hash) checkedHash(ctx, key) else {};
@@ -951,79 +951,79 @@ pub fn ArrayHashMapUnmanaged(
                 .u32 => return self.getIndexWithHeaderGeneric(key, ctx, header, u32),
             }
         }
-        fn getIndexWithHeaderGeneric(self: Self, key: anytype, ctx: anytype, header: *IndexHeader, comptime I: type) ?usize {
+        fn getIndexWithHeaderGeneric(self: *const Self, key: anytype, ctx: anytype, header: *IndexHeader, comptime I: type) ?usize {
             const indexes = header.indexes(I);
             const slot = self.getSlotByKey(key, ctx, header, I, indexes) orelse return null;
             return indexes[slot].entry_index;
         }
 
         /// Find the value associated with a key
-        pub fn get(self: Self, key: K) ?V {
+        pub fn get(self: *const Self, key: K) ?V {
             if (@sizeOf(Context) != 0)
                 @compileError("Cannot infer context " ++ @typeName(Context) ++ ", call getContext instead.");
             return self.getContext(key, undefined);
         }
-        pub fn getContext(self: Self, key: K, ctx: Context) ?V {
+        pub fn getContext(self: *const Self, key: K, ctx: Context) ?V {
             return self.getAdapted(key, ctx);
         }
-        pub fn getAdapted(self: Self, key: anytype, ctx: anytype) ?V {
+        pub fn getAdapted(self: *const Self, key: anytype, ctx: anytype) ?V {
             const index = self.getIndexAdapted(key, ctx) orelse return null;
             return self.values()[index];
         }
 
         /// Find a pointer to the value associated with a key
-        pub fn getPtr(self: Self, key: K) ?*V {
+        pub fn getPtr(self: *const Self, key: K) ?*V {
             if (@sizeOf(Context) != 0)
                 @compileError("Cannot infer context " ++ @typeName(Context) ++ ", call getPtrContext instead.");
             return self.getPtrContext(key, undefined);
         }
-        pub fn getPtrContext(self: Self, key: K, ctx: Context) ?*V {
+        pub fn getPtrContext(self: *const Self, key: K, ctx: Context) ?*V {
             return self.getPtrAdapted(key, ctx);
         }
-        pub fn getPtrAdapted(self: Self, key: anytype, ctx: anytype) ?*V {
+        pub fn getPtrAdapted(self: *const Self, key: anytype, ctx: anytype) ?*V {
             const index = self.getIndexAdapted(key, ctx) orelse return null;
             // workaround for #6974
             return if (@sizeOf(*V) == 0) @as(*V, undefined) else &self.values()[index];
         }
 
         /// Find the actual key associated with an adapted key
-        pub fn getKey(self: Self, key: K) ?K {
+        pub fn getKey(self: *const Self, key: K) ?K {
             if (@sizeOf(Context) != 0)
                 @compileError("Cannot infer context " ++ @typeName(Context) ++ ", call getKeyContext instead.");
             return self.getKeyContext(key, undefined);
         }
-        pub fn getKeyContext(self: Self, key: K, ctx: Context) ?K {
+        pub fn getKeyContext(self: *const Self, key: K, ctx: Context) ?K {
             return self.getKeyAdapted(key, ctx);
         }
-        pub fn getKeyAdapted(self: Self, key: anytype, ctx: anytype) ?K {
+        pub fn getKeyAdapted(self: *const Self, key: anytype, ctx: anytype) ?K {
             const index = self.getIndexAdapted(key, ctx) orelse return null;
             return self.keys()[index];
         }
 
         /// Find a pointer to the actual key associated with an adapted key
-        pub fn getKeyPtr(self: Self, key: K) ?*K {
+        pub fn getKeyPtr(self: *const Self, key: K) ?*K {
             if (@sizeOf(Context) != 0)
                 @compileError("Cannot infer context " ++ @typeName(Context) ++ ", call getKeyPtrContext instead.");
             return self.getKeyPtrContext(key, undefined);
         }
-        pub fn getKeyPtrContext(self: Self, key: K, ctx: Context) ?*K {
+        pub fn getKeyPtrContext(self: *const Self, key: K, ctx: Context) ?*K {
             return self.getKeyPtrAdapted(key, ctx);
         }
-        pub fn getKeyPtrAdapted(self: Self, key: anytype, ctx: anytype) ?*K {
+        pub fn getKeyPtrAdapted(self: *const Self, key: anytype, ctx: anytype) ?*K {
             const index = self.getIndexAdapted(key, ctx) orelse return null;
             return &self.keys()[index];
         }
 
         /// Check whether a key is stored in the map
-        pub fn contains(self: Self, key: K) bool {
+        pub fn contains(self: *const Self, key: K) bool {
             if (@sizeOf(Context) != 0)
                 @compileError("Cannot infer context " ++ @typeName(Context) ++ ", call containsContext instead.");
             return self.containsContext(key, undefined);
         }
-        pub fn containsContext(self: Self, key: K, ctx: Context) bool {
+        pub fn containsContext(self: *const Self, key: K, ctx: Context) bool {
             return self.containsAdapted(key, ctx);
         }
-        pub fn containsAdapted(self: Self, key: anytype, ctx: anytype) bool {
+        pub fn containsAdapted(self: *const Self, key: anytype, ctx: anytype) bool {
             return self.getIndexAdapted(key, ctx) != null;
         }
 
@@ -1138,12 +1138,12 @@ pub fn ArrayHashMapUnmanaged(
 
         /// Create a copy of the hash map which can be modified separately.
         /// The copy uses the same context and allocator as this instance.
-        pub fn clone(self: Self, allocator: Allocator) !Self {
+        pub fn clone(self: *const Self, allocator: Allocator) !Self {
             if (@sizeOf(ByIndexContext) != 0)
                 @compileError("Cannot infer context " ++ @typeName(Context) ++ ", call cloneContext instead.");
             return self.cloneContext(allocator, undefined);
         }
-        pub fn cloneContext(self: Self, allocator: Allocator, ctx: Context) !Self {
+        pub fn cloneContext(self: *const Self, allocator: Allocator, ctx: Context) !Self {
             var other: Self = .{};
             other.entries = try self.entries.clone(allocator);
             errdefer other.entries.deinit(allocator);
@@ -1574,7 +1574,7 @@ pub fn ArrayHashMapUnmanaged(
             unreachable;
         }
 
-        fn getSlotByKey(self: Self, key: anytype, ctx: anytype, header: *IndexHeader, comptime I: type, indexes: []Index(I)) ?usize {
+        fn getSlotByKey(self: *const Self, key: anytype, ctx: anytype, header: *IndexHeader, comptime I: type, indexes: []Index(I)) ?usize {
             const slice = self.entries.slice();
             const hashes_array = if (store_hash) slice.items(.hash) else {};
             const keys_array = slice.items(.key);
@@ -1650,7 +1650,7 @@ pub fn ArrayHashMapUnmanaged(
         inline fn checkedHash(ctx: anytype, key: anytype) u32 {
             comptime std.hash_map.verifyContext(@TypeOf(ctx), @TypeOf(key), K, u32, true);
             // If you get a compile error on the next line, it means that
-            const hash = ctx.hash(key); // your generic hash function doesn't accept your key
+            const hash = @TypeOf(ctx).hash(ctx, key); // your generic hash function doesn't accept your key
             if (@TypeOf(hash) != u32) {
                 @compileError("Context " ++ @typeName(@TypeOf(ctx)) ++ " has a generic hash function that returns the wrong type!\n" ++
                     @typeName(u32) ++ " was expected, but found " ++ @typeName(@TypeOf(hash)));
@@ -1660,7 +1660,7 @@ pub fn ArrayHashMapUnmanaged(
         inline fn checkedEql(ctx: anytype, a: anytype, b: K, b_index: usize) bool {
             comptime std.hash_map.verifyContext(@TypeOf(ctx), @TypeOf(a), K, u32, true);
             // If you get a compile error on the next line, it means that
-            const eql = ctx.eql(a, b, b_index); // your generic eql function doesn't accept (self, adapt key, K, index)
+            const eql = @TypeOf(ctx).eql(ctx, a, b, b_index); // your generic eql function doesn't accept (self, adapt key, K, index)
             if (@TypeOf(eql) != bool) {
                 @compileError("Context " ++ @typeName(@TypeOf(ctx)) ++ " has a generic eql function that returns the wrong type!\n" ++
                     @typeName(bool) ++ " was expected, but found " ++ @typeName(@TypeOf(eql)));
@@ -1668,12 +1668,12 @@ pub fn ArrayHashMapUnmanaged(
             return eql;
         }
 
-        fn dumpState(self: Self, comptime keyFmt: []const u8, comptime valueFmt: []const u8) void {
+        fn dumpState(self: *const Self, comptime keyFmt: []const u8, comptime valueFmt: []const u8) void {
             if (@sizeOf(ByIndexContext) != 0)
                 @compileError("Cannot infer context " ++ @typeName(Context) ++ ", call dumpStateContext instead.");
             self.dumpStateContext(keyFmt, valueFmt, undefined);
         }
-        fn dumpStateContext(self: Self, comptime keyFmt: []const u8, comptime valueFmt: []const u8, ctx: Context) void {
+        fn dumpStateContext(self: *const Self, comptime keyFmt: []const u8, comptime valueFmt: []const u8, ctx: Context) void {
             const p = std.debug.print;
             p("{s}:\n", .{@typeName(Self)});
             const slice = self.entries.slice();
@@ -1829,7 +1829,7 @@ const IndexHeader = struct {
     bit_index: u8 align(@alignOf(u32)),
 
     /// Map from an incrementing index to an index slot in the attached arrays.
-    fn constrainIndex(header: IndexHeader, i: usize) usize {
+    fn constrainIndex(header: *const IndexHeader, i: usize) usize {
         // This is an optimization for modulo of power of two integers;
         // it requires `indexes_len` to always be a power of two.
         return @intCast(usize, i & header.mask());
@@ -1843,17 +1843,17 @@ const IndexHeader = struct {
     }
 
     /// Returns the type used for the index arrays.
-    fn capacityIndexType(header: IndexHeader) CapacityIndexType {
+    fn capacityIndexType(header: *const IndexHeader) CapacityIndexType {
         return hash_map.capacityIndexType(header.bit_index);
     }
 
-    fn capacity(self: IndexHeader) u32 {
+    fn capacity(self: *const IndexHeader) u32 {
         return index_capacities[self.bit_index];
     }
-    fn length(self: IndexHeader) usize {
+    fn length(self: *const IndexHeader) usize {
         return @as(usize, 1) << @intCast(math.Log2Int(usize), self.bit_index);
     }
-    fn mask(self: IndexHeader) u32 {
+    fn mask(self: *const IndexHeader) u32 {
         return @intCast(u32, self.length() - 1);
     }
 
@@ -2271,7 +2271,7 @@ test "sort" {
     const C = struct {
         keys: []i32,
 
-        pub fn lessThan(ctx: @This(), a_index: usize, b_index: usize) bool {
+        pub fn lessThan(ctx: *const @This(), a_index: usize, b_index: usize) bool {
             return ctx.keys[a_index] < ctx.keys[b_index];
         }
     };
diff --git a/lib/std/bit_set.zig b/lib/std/bit_set.zig
index 2c4e50dee..f09726b1f 100644
--- a/lib/std/bit_set.zig
+++ b/lib/std/bit_set.zig
@@ -77,20 +77,20 @@ pub fn IntegerBitSet(comptime size: u16) type {
         }
 
         /// Returns the number of bits in this bit set
-        pub inline fn capacity(self: Self) usize {
+        pub inline fn capacity(self: *const Self) usize {
             _ = self;
             return bit_length;
         }
 
         /// Returns true if the bit at the specified index
         /// is present in the set, false otherwise.
-        pub fn isSet(self: Self, index: usize) bool {
+        pub fn isSet(self: *const Self, index: usize) bool {
             assert(index < bit_length);
             return (self.mask & maskBit(index)) != 0;
         }
 
         /// Returns the total number of set bits in this bit set.
-        pub fn count(self: Self) usize {
+        pub fn count(self: *const Self) usize {
             return @popCount(self.mask);
         }
 
@@ -176,7 +176,7 @@ pub fn IntegerBitSet(comptime size: u16) type {
 
         /// Finds the index of the first set bit.
         /// If no bits are set, returns null.
-        pub fn findFirstSet(self: Self) ?usize {
+        pub fn findFirstSet(self: *const Self) ?usize {
             const mask = self.mask;
             if (mask == 0) return null;
             return @ctz(mask);
@@ -330,21 +330,21 @@ pub fn ArrayBitSet(comptime MaskIntType: type, comptime size: usize) type {
         }
 
         /// Returns the number of bits in this bit set
-        pub inline fn capacity(self: Self) usize {
+        pub inline fn capacity(self: *const Self) usize {
             _ = self;
             return bit_length;
         }
 
         /// Returns true if the bit at the specified index
         /// is present in the set, false otherwise.
-        pub fn isSet(self: Self, index: usize) bool {
+        pub fn isSet(self: *const Self, index: usize) bool {
             assert(index < bit_length);
             if (num_masks == 0) return false; // doesn't compile in this case
             return (self.masks[maskIndex(index)] & maskBit(index)) != 0;
         }
 
         /// Returns the total number of set bits in this bit set.
-        pub fn count(self: Self) usize {
+        pub fn count(self: *const Self) usize {
             var total: usize = 0;
             for (self.masks) |mask| {
                 total += @popCount(mask);
@@ -469,7 +469,7 @@ pub fn ArrayBitSet(comptime MaskIntType: type, comptime size: usize) type {
 
         /// Finds the index of the first set bit.
         /// If no bits are set, returns null.
-        pub fn findFirstSet(self: Self) ?usize {
+        pub fn findFirstSet(self: *const Self) ?usize {
             var offset: usize = 0;
             const mask = for (self.masks) |mask| {
                 if (mask != 0) break mask;
@@ -640,19 +640,19 @@ pub const DynamicBitSetUnmanaged = struct {
     }
 
     /// Returns the number of bits in this bit set
-    pub inline fn capacity(self: Self) usize {
+    pub inline fn capacity(self: *const Self) usize {
         return self.bit_length;
     }
 
     /// Returns true if the bit at the specified index
     /// is present in the set, false otherwise.
-    pub fn isSet(self: Self, index: usize) bool {
+    pub fn isSet(self: *const Self, index: usize) bool {
         assert(index < self.bit_length);
         return (self.masks[maskIndex(index)] & maskBit(index)) != 0;
     }
 
     /// Returns the total number of set bits in this bit set.
-    pub fn count(self: Self) usize {
+    pub fn count(self: *const Self) usize {
         const num_masks = (self.bit_length + (@bitSizeOf(MaskInt) - 1)) / @bitSizeOf(MaskInt);
         var total: usize = 0;
         for (self.masks[0..num_masks]) |mask| {
@@ -787,7 +787,7 @@ pub const DynamicBitSetUnmanaged = struct {
 
     /// Finds the index of the first set bit.
     /// If no bits are set, returns null.
-    pub fn findFirstSet(self: Self) ?usize {
+    pub fn findFirstSet(self: *const Self) ?usize {
         var offset: usize = 0;
         var mask = self.masks;
         while (offset < self.bit_length) {
@@ -899,18 +899,18 @@ pub const DynamicBitSet = struct {
     }
 
     /// Returns the number of bits in this bit set
-    pub inline fn capacity(self: Self) usize {
+    pub inline fn capacity(self: *const Self) usize {
         return self.unmanaged.capacity();
     }
 
     /// Returns true if the bit at the specified index
     /// is present in the set, false otherwise.
-    pub fn isSet(self: Self, index: usize) bool {
+    pub fn isSet(self: *const Self, index: usize) bool {
         return self.unmanaged.isSet(index);
     }
 
     /// Returns the total number of set bits in this bit set.
-    pub fn count(self: Self) usize {
+    pub fn count(self: *const Self) usize {
         return self.unmanaged.count();
     }
 
@@ -971,7 +971,7 @@ pub const DynamicBitSet = struct {
 
     /// Finds the index of the first set bit.
     /// If no bits are set, returns null.
-    pub fn findFirstSet(self: Self) ?usize {
+    pub fn findFirstSet(self: *const Self) ?usize {
         return self.unmanaged.findFirstSet();
     }
 
diff --git a/lib/std/bounded_array.zig b/lib/std/bounded_array.zig
index 3d74e5e47..6cec0fa73 100644
--- a/lib/std/bounded_array.zig
+++ b/lib/std/bounded_array.zig
@@ -29,13 +29,13 @@ pub fn BoundedArray(comptime T: type, comptime buffer_capacity: usize) type {
         }
 
         /// View the internal array as a slice whose size was previously set.
-        pub fn slice(self: anytype) mem.Span(@TypeOf(&self.buffer)) {
+        pub fn slice(self: *Self) []T {
             return self.buffer[0..self.len];
         }
 
         /// View the internal array as a constant slice whose size was previously set.
         pub fn constSlice(self: *const Self) []const T {
-            return self.slice();
+            return self.buffer[0..self.len];
         }
 
         /// Adjust the slice's length to `len`.
@@ -53,7 +53,7 @@ pub fn BoundedArray(comptime T: type, comptime buffer_capacity: usize) type {
         }
 
         /// Return the element at index `i` of the slice.
-        pub fn get(self: Self, i: usize) T {
+        pub fn get(self: *const Self, i: usize) T {
             return self.constSlice()[i];
         }
 
@@ -63,12 +63,12 @@ pub fn BoundedArray(comptime T: type, comptime buffer_capacity: usize) type {
         }
 
         /// Return the maximum length of a slice.
-        pub fn capacity(self: Self) usize {
+        pub fn capacity(self: *const Self) usize {
             return self.buffer.len;
         }
 
         /// Check that the slice can hold at least `additional_count` items.
-        pub fn ensureUnusedCapacity(self: Self, additional_count: usize) error{Overflow}!void {
+        pub fn ensureUnusedCapacity(self: *const Self, additional_count: usize) error{Overflow}!void {
             if (self.len + additional_count > buffer_capacity) {
                 return error.Overflow;
             }
diff --git a/lib/std/buf_map.zig b/lib/std/buf_map.zig
index 2a6239c49..6c79b85df 100644
--- a/lib/std/buf_map.zig
+++ b/lib/std/buf_map.zig
@@ -62,14 +62,14 @@ pub const BufMap = struct {
 
     /// Find the address of the value associated with a key.
     /// The returned pointer is invalidated if the map resizes.
-    pub fn getPtr(self: BufMap, key: []const u8) ?*[]const u8 {
+    pub fn getPtr(self: *const BufMap, key: []const u8) ?*[]const u8 {
         return self.hash_map.getPtr(key);
     }
 
     /// Return the map's copy of the value associated with
     /// a key.  The returned string is invalidated if this
     /// key is removed from the map.
-    pub fn get(self: BufMap, key: []const u8) ?[]const u8 {
+    pub fn get(self: *const BufMap, key: []const u8) ?[]const u8 {
         return self.hash_map.get(key);
     }
 
@@ -82,7 +82,7 @@ pub const BufMap = struct {
     }
 
     /// Returns the number of KV pairs stored in the map.
-    pub fn count(self: BufMap) BufMapHashMap.Size {
+    pub fn count(self: *const BufMap) BufMapHashMap.Size {
         return self.hash_map.count();
     }
 
@@ -91,11 +91,11 @@ pub const BufMap = struct {
         return self.hash_map.iterator();
     }
 
-    fn free(self: BufMap, value: []const u8) void {
+    fn free(self: *const BufMap, value: []const u8) void {
         self.hash_map.allocator.free(value);
     }
 
-    fn copy(self: BufMap, value: []const u8) ![]u8 {
+    fn copy(self: *const BufMap, value: []const u8) ![]u8 {
         return self.hash_map.allocator.dupe(u8, value);
     }
 };
diff --git a/lib/std/build.zig b/lib/std/build.zig
index 3f903a0b1..36ff5cc59 100644
--- a/lib/std/build.zig
+++ b/lib/std/build.zig
@@ -1086,7 +1086,7 @@ pub const Builder = struct {
             log.info("cp {s} {s} ", .{ source_path, dest_path });
         }
         const cwd = fs.cwd();
-        const prev_status = try fs.Dir.updateFile(cwd, source_path, cwd, dest_path, .{});
+        const prev_status = try cwd.updateFile(source_path, cwd, dest_path, .{});
         if (self.verbose) switch (prev_status) {
             .stale => log.info("# installed", .{}),
             .fresh => log.info("# up-to-date", .{}),
@@ -1391,7 +1391,7 @@ pub const GeneratedFile = struct {
     /// This value must be set in the `fn make()` of the `step` and must not be `null` afterwards.
     path: ?[]const u8 = null,
 
-    pub fn getPath(self: GeneratedFile) []const u8 {
+    pub fn getPath(self: *const GeneratedFile) []const u8 {
         return self.path orelse std.debug.panic(
             "getPath() was called on a GeneratedFile that wasn't build yet. Is there a missing Step dependency on step '{s}'?",
             .{self.step.name},
@@ -1418,24 +1418,24 @@ pub const FileSource = union(enum) {
 
     /// Returns a string that can be shown to represent the file source.
     /// Either returns the path or `"generated"`.
-    pub fn getDisplayName(self: FileSource) []const u8 {
-        return switch (self) {
+    pub fn getDisplayName(self: *const FileSource) []const u8 {
+        return switch (self.*) {
             .path => self.path,
             .generated => "generated",
         };
     }
 
     /// Adds dependencies this file source implies to the given step.
-    pub fn addStepDependencies(self: FileSource, step: *Step) void {
-        switch (self) {
+    pub fn addStepDependencies(self: *const FileSource, step: *Step) void {
+        switch (self.*) {
             .path => {},
             .generated => |gen| step.dependOn(gen.step),
         }
     }
 
     /// Should only be called during make(), returns a path relative to the build root or absolute.
-    pub fn getPath(self: FileSource, builder: *Builder) []const u8 {
-        const path = switch (self) {
+    pub fn getPath(self: *const FileSource, builder: *Builder) []const u8 {
+        const path = switch (self.*) {
             .path => |p| builder.pathFromRoot(p),
             .generated => |gen| gen.getPath(),
         };
@@ -1443,8 +1443,8 @@ pub const FileSource = union(enum) {
     }
 
     /// Duplicates the file source for a given builder.
-    pub fn dupe(self: FileSource, b: *Builder) FileSource {
-        return switch (self) {
+    pub fn dupe(self: *const FileSource, b: *Builder) FileSource {
+        return switch (self.*) {
             .path => |p| .{ .path = b.dupePath(p) },
             .generated => |gen| .{ .generated = gen },
         };
@@ -3745,7 +3745,7 @@ pub const InstalledFile = struct {
     path: []const u8,
 
     /// Duplicates the installed file path and directory.
-    pub fn dupe(self: InstalledFile, builder: *Builder) InstalledFile {
+    pub fn dupe(self: *const InstalledFile, builder: *Builder) InstalledFile {
         return .{
             .dir = self.dir.dupe(builder),
             .path = builder.dupe(self.path),
diff --git a/lib/std/builtin.zig b/lib/std/builtin.zig
index 430a29c9d..e288f8a4a 100644
--- a/lib/std/builtin.zig
+++ b/lib/std/builtin.zig
@@ -475,7 +475,7 @@ pub const Version = struct {
 
         /// Checks if system is guaranteed to be at least `version` or older than `version`.
         /// Returns `null` if a runtime check is required.
-        pub fn isAtLeast(self: Range, ver: Version) ?bool {
+        pub fn isAtLeast(self: *const Range, ver: Version) ?bool {
             if (self.min.order(ver) != .lt) return true;
             if (self.max.order(ver) == .lt) return false;
             return null;
diff --git a/lib/std/crypto/25519/curve25519.zig b/lib/std/crypto/25519/curve25519.zig
index f5938dd21..d873675f3 100644
--- a/lib/std/crypto/25519/curve25519.zig
+++ b/lib/std/crypto/25519/curve25519.zig
@@ -33,19 +33,19 @@ pub const Curve25519 = struct {
     }
 
     /// Reject the neutral element.
-    pub fn rejectIdentity(p: Curve25519) IdentityElementError!void {
+    pub fn rejectIdentity(p: *const Curve25519) IdentityElementError!void {
         if (p.x.isZero()) {
             return error.IdentityElement;
         }
     }
 
     /// Multiply a point by the cofactor, returning WeakPublicKey if the element is in a small-order group.
-    pub fn clearCofactor(p: Curve25519) WeakPublicKeyError!Curve25519 {
+    pub fn clearCofactor(p: *const Curve25519) WeakPublicKeyError!Curve25519 {
         const cofactor = [_]u8{8} ++ [_]u8{0} ** 31;
         return ladder(p, cofactor, 4) catch return error.WeakPublicKey;
     }
 
-    fn ladder(p: Curve25519, s: [32]u8, comptime bits: usize) IdentityElementError!Curve25519 {
+    fn ladder(p: *const Curve25519, s: [32]u8, comptime bits: usize) IdentityElementError!Curve25519 {
         var x1 = p.x;
         var x2 = Fe.one;
         var z2 = Fe.zero;
@@ -86,7 +86,7 @@ pub const Curve25519 = struct {
     /// way to use Curve25519 for a DH operation.
     /// Return error.IdentityElement if the resulting point is
     /// the identity element.
-    pub fn clampedMul(p: Curve25519, s: [32]u8) IdentityElementError!Curve25519 {
+    pub fn clampedMul(p: *const Curve25519, s: [32]u8) IdentityElementError!Curve25519 {
         var t: [32]u8 = s;
         scalar.clamp(&t);
         return try ladder(p, t, 255);
@@ -96,7 +96,7 @@ pub const Curve25519 = struct {
     /// Return error.IdentityElement if the resulting point is
     /// the identity element or error.WeakPublicKey if the public
     /// key is a low-order point.
-    pub fn mul(p: Curve25519, s: [32]u8) (IdentityElementError || WeakPublicKeyError)!Curve25519 {
+    pub fn mul(p: *const Curve25519, s: [32]u8) (IdentityElementError || WeakPublicKeyError)!Curve25519 {
         _ = try p.clearCofactor();
         return try ladder(p, s, 256);
     }
diff --git a/lib/std/crypto/25519/edwards25519.zig b/lib/std/crypto/25519/edwards25519.zig
index f7b07738a..79e9016e4 100644
--- a/lib/std/crypto/25519/edwards25519.zig
+++ b/lib/std/crypto/25519/edwards25519.zig
@@ -48,7 +48,7 @@ pub const Edwards25519 = struct {
     }
 
     /// Encode an Edwards25519 point.
-    pub fn toBytes(p: Edwards25519) [encoded_length]u8 {
+    pub fn toBytes(p: *const Edwards25519) [encoded_length]u8 {
         const zi = p.z.invert();
         var s = p.y.mul(zi).toBytes();
         s[31] ^= @as(u8, @boolToInt(p.x.mul(zi).isNegative())) << 7;
@@ -72,24 +72,24 @@ pub const Edwards25519 = struct {
     pub const identityElement = Edwards25519{ .x = Fe.zero, .y = Fe.one, .z = Fe.one, .t = Fe.zero };
 
     /// Reject the neutral element.
-    pub fn rejectIdentity(p: Edwards25519) IdentityElementError!void {
+    pub fn rejectIdentity(p: *const Edwards25519) IdentityElementError!void {
         if (p.x.isZero()) {
             return error.IdentityElement;
         }
     }
 
     /// Multiply a point by the cofactor
-    pub fn clearCofactor(p: Edwards25519) Edwards25519 {
+    pub fn clearCofactor(p: *const Edwards25519) Edwards25519 {
         return p.dbl().dbl().dbl();
     }
 
     /// Flip the sign of the X coordinate.
-    pub inline fn neg(p: Edwards25519) Edwards25519 {
+    pub inline fn neg(p: *const Edwards25519) Edwards25519 {
         return .{ .x = p.x.neg(), .y = p.y, .z = p.z, .t = p.t.neg() };
     }
 
     /// Double an Edwards25519 point.
-    pub fn dbl(p: Edwards25519) Edwards25519 {
+    pub fn dbl(p: *const Edwards25519) Edwards25519 {
         const t0 = p.x.add(p.y).sq();
         var x = p.x.sq();
         var z = p.y.sq();
@@ -106,7 +106,7 @@ pub const Edwards25519 = struct {
     }
 
     /// Add two Edwards25519 points.
-    pub fn add(p: Edwards25519, q: Edwards25519) Edwards25519 {
+    pub fn add(p: *const Edwards25519, q: Edwards25519) Edwards25519 {
         const a = p.y.sub(p.x).mul(q.y.sub(q.x));
         const b = p.x.add(p.y).mul(q.x.add(q.y));
         const c = p.t.mul(q.t).mul(Fe.edwards25519d2);
@@ -125,7 +125,7 @@ pub const Edwards25519 = struct {
     }
 
     /// Substract two Edwards25519 points.
-    pub fn sub(p: Edwards25519, q: Edwards25519) Edwards25519 {
+    pub fn sub(p: *const Edwards25519, q: Edwards25519) Edwards25519 {
         return p.add(q.neg());
     }
 
@@ -220,16 +220,16 @@ pub const Edwards25519 = struct {
     }
 
     const basePointPc = pc: {
-        @setEvalBranchQuota(10000);
+        @setEvalBranchQuota(5000);
         break :pc precompute(Edwards25519.basePoint, 15);
     };
 
     /// Multiply an Edwards25519 point by a scalar without clamping it.
     /// Return error.WeakPublicKey if the base generates a small-order group,
     /// and error.IdentityElement if the result is the identity element.
-    pub fn mul(p: Edwards25519, s: [32]u8) (IdentityElementError || WeakPublicKeyError)!Edwards25519 {
+    pub fn mul(p: *const Edwards25519, s: [32]u8) (IdentityElementError || WeakPublicKeyError)!Edwards25519 {
         const pc = if (p.is_base) basePointPc else pc: {
-            const xpc = precompute(p, 15);
+            const xpc = precompute(p.*, 15);
             xpc[4].rejectIdentity() catch return error.WeakPublicKey;
             break :pc xpc;
         };
@@ -238,11 +238,11 @@ pub const Edwards25519 = struct {
 
     /// Multiply an Edwards25519 point by a *PUBLIC* scalar *IN VARIABLE TIME*
     /// This can be used for signature verification.
-    pub fn mulPublic(p: Edwards25519, s: [32]u8) (IdentityElementError || WeakPublicKeyError)!Edwards25519 {
+    pub fn mulPublic(p: *const Edwards25519, s: [32]u8) (IdentityElementError || WeakPublicKeyError)!Edwards25519 {
         if (p.is_base) {
             return pcMul16(&basePointPc, s, true);
         } else {
-            const pc = precompute(p, 8);
+            const pc = precompute(p.*, 8);
             pc[4].rejectIdentity() catch return error.WeakPublicKey;
             return pcMul(&pc, s, true);
         }
@@ -250,10 +250,10 @@ pub const Edwards25519 = struct {
 
     /// Double-base multiplication of public parameters - Compute (p1*s1)+(p2*s2) *IN VARIABLE TIME*
     /// This can be used for signature verification.
-    pub fn mulDoubleBasePublic(p1: Edwards25519, s1: [32]u8, p2: Edwards25519, s2: [32]u8) (IdentityElementError || WeakPublicKeyError)!Edwards25519 {
+    pub fn mulDoubleBasePublic(p1: *const Edwards25519, s1: [32]u8, p2: Edwards25519, s2: [32]u8) (IdentityElementError || WeakPublicKeyError)!Edwards25519 {
         var pc1_array: [9]Edwards25519 = undefined;
         const pc1 = if (p1.is_base) basePointPc[0..9] else pc: {
-            pc1_array = precompute(p1, 8);
+            pc1_array = precompute(p1.*, 8);
             pc1_array[4].rejectIdentity() catch return error.WeakPublicKey;
             break :pc &pc1_array;
         };
@@ -331,7 +331,7 @@ pub const Edwards25519 = struct {
     /// This is strongly recommended for DH operations.
     /// Return error.WeakPublicKey if the resulting point is
     /// the identity element.
-    pub fn clampedMul(p: Edwards25519, s: [32]u8) (IdentityElementError || WeakPublicKeyError)!Edwards25519 {
+    pub fn clampedMul(p: *const Edwards25519, s: [32]u8) (IdentityElementError || WeakPublicKeyError)!Edwards25519 {
         var t: [32]u8 = s;
         scalar.clamp(&t);
         return mul(p, t);
diff --git a/lib/std/crypto/25519/field.zig b/lib/std/crypto/25519/field.zig
index 1a786e0c3..5dd298a39 100644
--- a/lib/std/crypto/25519/field.zig
+++ b/lib/std/crypto/25519/field.zig
@@ -76,8 +76,8 @@ pub const Fe = struct {
     }
 
     /// Pack a field element
-    pub fn toBytes(fe: Fe) [32]u8 {
-        var reduced = fe;
+    pub fn toBytes(fe: *const Fe) [32]u8 {
+        var reduced = fe.*;
         reduced.reduce();
         var s: [32]u8 = undefined;
         writeIntLittle(u64, s[0..8], reduced.limbs[0] | (reduced.limbs[1] << 51));
@@ -163,7 +163,7 @@ pub const Fe = struct {
     }
 
     /// Add a field element
-    pub inline fn add(a: Fe, b: Fe) Fe {
+    pub inline fn add(a: *const Fe, b: Fe) Fe {
         var fe: Fe = undefined;
         comptime var i = 0;
         inline while (i < 5) : (i += 1) {
@@ -173,7 +173,7 @@ pub const Fe = struct {
     }
 
     /// Substract a field element
-    pub inline fn sub(a: Fe, b: Fe) Fe {
+    pub inline fn sub(a: *const Fe, b: Fe) Fe {
         var fe = b;
         comptime var i = 0;
         inline while (i < 4) : (i += 1) {
@@ -192,12 +192,12 @@ pub const Fe = struct {
     }
 
     /// Negate a field element
-    pub inline fn neg(a: Fe) Fe {
-        return zero.sub(a);
+    pub inline fn neg(a: *const Fe) Fe {
+        return (&zero).sub(a.*);
     }
 
     /// Return true if a field element is negative
-    pub inline fn isNegative(a: Fe) bool {
+    pub inline fn isNegative(a: *const Fe) bool {
         return (a.toBytes()[0] & 1) != 0;
     }
 
@@ -264,7 +264,7 @@ pub const Fe = struct {
     }
 
     /// Multiply two field elements
-    pub inline fn mul(a: Fe, b: Fe) Fe {
+    pub inline fn mul(a: *const Fe, b: Fe) Fe {
         var ax: [5]u128 = undefined;
         var bx: [5]u128 = undefined;
         var a19: [5]u128 = undefined;
@@ -287,7 +287,7 @@ pub const Fe = struct {
         return _carry128(&r);
     }
 
-    inline fn _sq(a: Fe, comptime double: bool) Fe {
+    inline fn _sq(a: *const Fe, comptime double: bool) Fe {
         var ax: [5]u128 = undefined;
         var r: [5]u128 = undefined;
         comptime var i = 0;
@@ -316,17 +316,17 @@ pub const Fe = struct {
     }
 
     /// Square a field element
-    pub inline fn sq(a: Fe) Fe {
+    pub inline fn sq(a: *const Fe) Fe {
         return _sq(a, false);
     }
 
     /// Square and double a field element
-    pub inline fn sq2(a: Fe) Fe {
+    pub inline fn sq2(a: *const Fe) Fe {
         return _sq(a, true);
     }
 
     /// Multiply a field element with a small (32-bit) integer
-    pub inline fn mul32(a: Fe, comptime n: u32) Fe {
+    pub inline fn mul32(a: *const Fe, comptime n: u32) Fe {
         const sn = @intCast(u128, n);
         var fe: Fe = undefined;
         var x: u128 = 0;
@@ -341,9 +341,9 @@ pub const Fe = struct {
     }
 
     /// Square a field element `n` times
-    fn sqn(a: Fe, n: usize) Fe {
+    fn sqn(a: *const Fe, n: usize) Fe {
         var i: usize = 0;
-        var fe = a;
+        var fe = a.*;
         while (i < n) : (i += 1) {
             fe = fe.sq();
         }
@@ -351,9 +351,9 @@ pub const Fe = struct {
     }
 
     /// Return the inverse of a field element, or 0 if a=0.
-    pub fn invert(a: Fe) Fe {
+    pub fn invert(a: *const Fe) Fe {
         var t0 = a.sq();
-        var t1 = t0.sqn(2).mul(a);
+        var t1 = t0.sqn(2).mul(a.*);
         t0 = t0.mul(t1);
         t1 = t1.mul(t0.sq());
         t1 = t1.mul(t1.sqn(5));
@@ -366,26 +366,26 @@ pub const Fe = struct {
 
     /// Return a^((p-5)/8) = a^(2^252-3)
     /// Used to compute square roots since we have p=5 (mod 8); see Cohen and Frey.
-    pub fn pow2523(a: Fe) Fe {
+    pub fn pow2523(a: *const Fe) Fe {
         var t0 = a.mul(a.sq());
-        var t1 = t0.mul(t0.sqn(2)).sq().mul(a);
+        var t1 = t0.mul(t0.sqn(2)).sq().mul(a.*);
         t0 = t1.sqn(5).mul(t1);
         var t2 = t0.sqn(5).mul(t1);
         t1 = t2.sqn(15).mul(t2);
         t2 = t1.sqn(30).mul(t1);
         t1 = t2.sqn(60).mul(t2);
-        return t1.sqn(120).mul(t1).sqn(10).mul(t0).sqn(2).mul(a);
+        return t1.sqn(120).mul(t1).sqn(10).mul(t0).sqn(2).mul(a.*);
     }
 
     /// Return the absolute value of a field element
-    pub fn abs(a: Fe) Fe {
-        var r = a;
+    pub fn abs(a: *const Fe) Fe {
+        var r = a.*;
         r.cMov(a.neg(), @boolToInt(a.isNegative()));
         return r;
     }
 
     /// Return true if the field element is a square
-    pub fn isSquare(a: Fe) bool {
+    pub fn isSquare(a: *const Fe) bool {
         // Compute the Jacobi symbol x^((p-1)/2)
         const _11 = a.mul(a.sq());
         const _1111 = _11.mul(_11.sq().sq());
@@ -398,9 +398,9 @@ pub const Fe = struct {
         return @bitCast(bool, @truncate(u1, ~(t4.toBytes()[1] & 1)));
     }
 
-    fn uncheckedSqrt(x2: Fe) Fe {
+    fn uncheckedSqrt(x2: *const Fe) Fe {
         var e = x2.pow2523();
-        const p_root = e.mul(x2); // positive root
+        const p_root = e.mul(x2.*); // positive root
         const m_root = p_root.mul(Fe.sqrtm1); // negative root
         const m_root2 = m_root.sq();
         e = x2.sub(m_root2);
@@ -410,8 +410,8 @@ pub const Fe = struct {
     }
 
     /// Compute the square root of `x2`, returning `error.NotSquare` if `x2` was not a square
-    pub fn sqrt(x2: Fe) NotSquareError!Fe {
-        var x2_copy = x2;
+    pub fn sqrt(x2: *const Fe) NotSquareError!Fe {
+        var x2_copy = x2.*;
         const x = x2.uncheckedSqrt();
         const check = x.sq().sub(x2_copy);
         if (check.isZero()) {
diff --git a/lib/std/crypto/25519/ristretto255.zig b/lib/std/crypto/25519/ristretto255.zig
index e33bdb496..e63b5d0b9 100644
--- a/lib/std/crypto/25519/ristretto255.zig
+++ b/lib/std/crypto/25519/ristretto255.zig
@@ -158,7 +158,7 @@ pub const Ristretto255 = struct {
     }
 
     /// Return true if two Ristretto255 elements are equivalent
-    pub fn equivalent(p: Ristretto255, q: Ristretto255) bool {
+    pub fn equivalent(p: *const Ristretto255, q: Ristretto255) bool {
         const p_ = &p.p;
         const q_ = &q.p;
         const a = p_.x.mul(q_.y).equivalent(p_.y.mul(q_.x));
diff --git a/lib/std/crypto/25519/scalar.zig b/lib/std/crypto/25519/scalar.zig
index ff2e6aff8..31afd34d6 100644
--- a/lib/std/crypto/25519/scalar.zig
+++ b/lib/std/crypto/25519/scalar.zig
@@ -134,13 +134,13 @@ pub const Scalar = struct {
     }
 
     /// Return true if the scalar is zero
-    pub fn isZero(n: Scalar) bool {
+    pub fn isZero(n: *const Scalar) bool {
         const limbs = n.limbs;
         return (limbs[0] | limbs[1] | limbs[2] | limbs[3] | limbs[4]) == 0;
     }
 
     /// Return x+y (mod L)
-    pub fn add(x: Scalar, y: Scalar) Scalar {
+    pub fn add(x: *const Scalar, y: Scalar) Scalar {
         const carry0 = (x.limbs[0] + y.limbs[0]) >> 56;
         const t0 = (x.limbs[0] + y.limbs[0]) & 0xffffffffffffff;
         const t00 = t0;
@@ -197,7 +197,7 @@ pub const Scalar = struct {
     }
 
     /// Return x*r (mod L)
-    pub fn mul(x: Scalar, y: Scalar) Scalar {
+    pub fn mul(x: *const Scalar, y: Scalar) Scalar {
         const xy000 = @as(u128, x.limbs[0]) * @as(u128, y.limbs[0]);
         const xy010 = @as(u128, x.limbs[0]) * @as(u128, y.limbs[1]);
         const xy020 = @as(u128, x.limbs[0]) * @as(u128, y.limbs[2]);
@@ -509,14 +509,14 @@ pub const Scalar = struct {
     }
 
     /// Return x^2 (mod L)
-    pub fn sq(x: Scalar) Scalar {
-        return x.mul(x);
+    pub fn sq(x: *const Scalar) Scalar {
+        return x.mul(x.*);
     }
 
     /// Square a scalar `n` times
-    inline fn sqn(x: Scalar, comptime n: comptime_int) Scalar {
+    inline fn sqn(x: *const Scalar, comptime n: comptime_int) Scalar {
         var i: usize = 0;
-        var t = x;
+        var t = x.*;
         while (i < n) : (i += 1) {
             t = t.sq();
         }
@@ -524,12 +524,12 @@ pub const Scalar = struct {
     }
 
     /// Square and multiply
-    fn sqn_mul(x: Scalar, comptime n: comptime_int, y: Scalar) Scalar {
+    fn sqn_mul(x: *const Scalar, comptime n: comptime_int, y: Scalar) Scalar {
         return x.sqn(n).mul(y);
     }
 
     /// Return the inverse of a scalar (mod L), or 0 if x=0.
-    pub fn invert(x: Scalar) Scalar {
+    pub fn invert(x: *const Scalar) Scalar {
         const _10 = x.sq();
         const _11 = x.mul(_10);
         const _100 = x.mul(_11);
diff --git a/lib/std/crypto/ecdsa.zig b/lib/std/crypto/ecdsa.zig
index 3360d7bb8..7ba0b82b9 100644
--- a/lib/std/crypto/ecdsa.zig
+++ b/lib/std/crypto/ecdsa.zig
@@ -42,7 +42,7 @@ pub fn Ecdsa(comptime Curve: type, comptime Hash: type) type {
                 return SecretKey{ .bytes = bytes };
             }
 
-            pub fn toBytes(sk: SecretKey) [encoded_length]u8 {
+            pub fn toBytes(sk: *const SecretKey) [encoded_length]u8 {
                 return sk.bytes;
             }
         };
@@ -62,12 +62,12 @@ pub fn Ecdsa(comptime Curve: type, comptime Hash: type) type {
             }
 
             /// Encode the public key using the compressed SEC-1 format.
-            pub fn toCompressedSec1(pk: PublicKey) [compressed_sec1_encoded_length]u8 {
+            pub fn toCompressedSec1(pk: *const PublicKey) [compressed_sec1_encoded_length]u8 {
                 return pk.p.toCompressedSec1();
             }
 
             /// Encoding the public key using the uncompressed SEC-1 format.
-            pub fn toUncompressedSec1(pk: PublicKey) [uncompressed_sec1_encoded_length]u8 {
+            pub fn toUncompressedSec1(pk: *const PublicKey) [uncompressed_sec1_encoded_length]u8 {
                 return pk.p.toUncompressedSec1();
             }
         };
@@ -87,7 +87,7 @@ pub fn Ecdsa(comptime Curve: type, comptime Hash: type) type {
             /// Verify the signature against a message and public key.
             /// Return IdentityElement or NonCanonical if the public key or signature are not in the expected range,
             /// or SignatureVerificationError if the signature is invalid for the given message and key.
-            pub fn verify(self: Signature, msg: []const u8, public_key: PublicKey) (IdentityElementError || NonCanonicalError || SignatureVerificationError)!void {
+            pub fn verify(self: *const Signature, msg: []const u8, public_key: PublicKey) (IdentityElementError || NonCanonicalError || SignatureVerificationError)!void {
                 const r = try Curve.scalar.Scalar.fromBytes(self.r, .Big);
                 const s = try Curve.scalar.Scalar.fromBytes(self.s, .Big);
                 if (r.isZero() or s.isZero()) return error.IdentityElement;
@@ -225,7 +225,7 @@ pub fn Ecdsa(comptime Curve: type, comptime Hash: type) type {
             /// The noise can be null in order to create deterministic signatures.
             /// If deterministic signatures are not required, the noise should be randomly generated instead.
             /// This helps defend against fault attacks.
-            pub fn sign(key_pair: KeyPair, msg: []const u8, noise: ?[noise_length]u8) (IdentityElementError || NonCanonicalError)!Signature {
+            pub fn sign(key_pair: *const KeyPair, msg: []const u8, noise: ?[noise_length]u8) (IdentityElementError || NonCanonicalError)!Signature {
                 const secret_key = key_pair.secret_key;
 
                 var h: [Hash.digest_length]u8 = undefined;
@@ -243,7 +243,7 @@ pub fn Ecdsa(comptime Curve: type, comptime Hash: type) type {
                 if (r.isZero()) return error.IdentityElement;
 
                 const k_inv = k.invert();
-                const zrs = z.add(r.mul(try Curve.scalar.Scalar.fromBytes(secret_key.bytes, .Big)));
+                const zrs = z.add((&r).mul(try Curve.scalar.Scalar.fromBytes(secret_key.bytes, .Big)));
                 const s = k_inv.mul(zrs);
                 if (s.isZero()) return error.IdentityElement;
 
diff --git a/lib/std/crypto/pcurves/common.zig b/lib/std/crypto/pcurves/common.zig
index 5abc6d348..1bb1b4572 100644
--- a/lib/std/crypto/pcurves/common.zig
+++ b/lib/std/crypto/pcurves/common.zig
@@ -81,7 +81,7 @@ pub fn Field(comptime params: FieldParams) type {
         }
 
         /// Pack a field element.
-        pub fn toBytes(fe: Fe, endian: std.builtin.Endian) [encoded_length]u8 {
+        pub fn toBytes(fe: *const Fe, endian: std.builtin.Endian) [encoded_length]u8 {
             var limbs_z: NonMontgomeryDomainFieldElement = undefined;
             fiat.fromMontgomery(&limbs_z, fe.limbs);
             var s: [encoded_length]u8 = undefined;
@@ -100,25 +100,25 @@ pub fn Field(comptime params: FieldParams) type {
         }
 
         /// Return the field element as an integer.
-        pub fn toInt(fe: Fe) IntRepr {
+        pub fn toInt(fe: *const Fe) IntRepr {
             const s = fe.toBytes(.Little);
             return mem.readIntLittle(IntRepr, &s);
         }
 
         /// Return true if the field element is zero.
-        pub fn isZero(fe: Fe) bool {
+        pub fn isZero(fe: *const Fe) bool {
             var z: @TypeOf(fe.limbs[0]) = undefined;
             fiat.nonzero(&z, fe.limbs);
             return z == 0;
         }
 
         /// Return true if both field elements are equivalent.
-        pub fn equivalent(a: Fe, b: Fe) bool {
+        pub fn equivalent(a: *const Fe, b: Fe) bool {
             return a.sub(b).isZero();
         }
 
         /// Return true if the element is odd.
-        pub fn isOdd(fe: Fe) bool {
+        pub fn isOdd(fe: *const Fe) bool {
             const s = fe.toBytes(.Little);
             return @truncate(u1, s[0]) != 0;
         }
@@ -129,44 +129,44 @@ pub fn Field(comptime params: FieldParams) type {
         }
 
         /// Add field elements.
-        pub fn add(a: Fe, b: Fe) Fe {
+        pub fn add(a: *const Fe, b: Fe) Fe {
             var fe: Fe = undefined;
             fiat.add(&fe.limbs, a.limbs, b.limbs);
             return fe;
         }
 
         /// Subtract field elements.
-        pub fn sub(a: Fe, b: Fe) Fe {
+        pub fn sub(a: *const Fe, b: Fe) Fe {
             var fe: Fe = undefined;
             fiat.sub(&fe.limbs, a.limbs, b.limbs);
             return fe;
         }
 
         /// Double a field element.
-        pub fn dbl(a: Fe) Fe {
+        pub fn dbl(a: *const Fe) Fe {
             var fe: Fe = undefined;
             fiat.add(&fe.limbs, a.limbs, a.limbs);
             return fe;
         }
 
         /// Multiply field elements.
-        pub fn mul(a: Fe, b: Fe) Fe {
+        pub fn mul(a: *const Fe, b: Fe) Fe {
             var fe: Fe = undefined;
             fiat.mul(&fe.limbs, a.limbs, b.limbs);
             return fe;
         }
 
         /// Square a field element.
-        pub fn sq(a: Fe) Fe {
+        pub fn sq(a: *const Fe) Fe {
             var fe: Fe = undefined;
             fiat.square(&fe.limbs, a.limbs);
             return fe;
         }
 
         /// Square a field element n times.
-        fn sqn(a: Fe, comptime n: comptime_int) Fe {
+        fn sqn(a: *const Fe, comptime n: comptime_int) Fe {
             var i: usize = 0;
-            var fe = a;
+            var fe = a.*;
             while (i < n) : (i += 1) {
                 fe = fe.sq();
             }
@@ -174,10 +174,10 @@ pub fn Field(comptime params: FieldParams) type {
         }
 
         /// Compute a^n.
-        pub fn pow(a: Fe, comptime T: type, comptime n: T) Fe {
+        pub fn pow(a: *const Fe, comptime T: type, comptime n: T) Fe {
             var fe = one;
             var x: T = n;
-            var t = a;
+            var t = a.*;
             while (true) {
                 if (@truncate(u1, x) != 0) fe = fe.mul(t);
                 x >>= 1;
@@ -188,7 +188,7 @@ pub fn Field(comptime params: FieldParams) type {
         }
 
         /// Negate a field element.
-        pub fn neg(a: Fe) Fe {
+        pub fn neg(a: *const Fe) Fe {
             var fe: Fe = undefined;
             fiat.opp(&fe.limbs, a.limbs);
             return fe;
@@ -196,7 +196,7 @@ pub fn Field(comptime params: FieldParams) type {
 
         /// Return the inverse of a field element, or 0 if a=0.
         // Field inversion from https://eprint.iacr.org/2021/549.pdf
-        pub fn invert(a: Fe) Fe {
+        pub fn invert(a: *const Fe) Fe {
             const iterations = (49 * field_bits + 57) / 17;
             const Limbs = @TypeOf(a.limbs);
             const Word = @TypeOf(a.limbs[0]);
@@ -246,16 +246,16 @@ pub fn Field(comptime params: FieldParams) type {
         }
 
         /// Return true if the field element is a square.
-        pub fn isSquare(x2: Fe) bool {
+        pub fn isSquare(x2: *const Fe) bool {
             if (field_order == 115792089210356248762697446949407573530086143415290314195533631308867097853951) {
                 const t110 = x2.mul(x2.sq()).sq();
                 const t111 = x2.mul(t110);
                 const t111111 = t111.mul(x2.mul(t110).sqn(3));
                 const x15 = t111111.sqn(6).mul(t111111).sqn(3).mul(t111);
-                const x16 = x15.sq().mul(x2);
+                const x16 = x15.sq().mul(x2.*);
                 const x53 = x16.sqn(16).mul(x16).sqn(15);
                 const x47 = x15.mul(x53);
-                const ls = x47.mul(((x53.sqn(17).mul(x2)).sqn(143).mul(x47)).sqn(47)).sq().mul(x2);
+                const ls = x47.mul(((x53.sqn(17).mul(x2.*)).sqn(143).mul(x47)).sqn(47)).sq().mul(x2.*);
                 return ls.equivalent(Fe.one);
             } else if (field_order == 39402006196394479212279040100143613805079739270465446667948293404245721771496870329047266088258938001861606973112319) {
                 const t111 = x2.mul(x2.mul(x2.sq()).sq());
@@ -264,7 +264,7 @@ pub fn Field(comptime params: FieldParams) type {
                 const t1111111 = x2.mul(t1111110);
                 const x12 = t1111110.sqn(5).mul(t111111);
                 const x31 = x12.sqn(12).mul(x12).sqn(7).mul(t1111111);
-                const x32 = x31.sq().mul(x2);
+                const x32 = x31.sq().mul(x2.*);
                 const x63 = x32.sqn(31).mul(x31);
                 const x126 = x63.sqn(63).mul(x63);
                 const ls = x126.sqn(126).mul(x126).sqn(3).mul(t111).sqn(33).mul(x32).sqn(95).mul(x31);
@@ -276,14 +276,14 @@ pub fn Field(comptime params: FieldParams) type {
         }
 
         // x=x2^((field_order+1)/4) w/ field order=3 (mod 4).
-        fn uncheckedSqrt(x2: Fe) Fe {
+        fn uncheckedSqrt(x2: *const Fe) Fe {
             comptime debug.assert(field_order % 4 == 3);
             if (field_order == 115792089210356248762697446949407573530086143415290314195533631308867097853951) {
                 const t11 = x2.mul(x2.sq());
                 const t1111 = t11.mul(t11.sqn(2));
                 const t11111111 = t1111.mul(t1111.sqn(4));
                 const x16 = t11111111.sqn(8).mul(t11111111);
-                return x16.sqn(16).mul(x16).sqn(32).mul(x2).sqn(96).mul(x2).sqn(94);
+                return x16.sqn(16).mul(x16).sqn(32).mul(x2.*).sqn(96).mul(x2.*).sqn(94);
             } else if (field_order == 39402006196394479212279040100143613805079739270465446667948293404245721771496870329047266088258938001861606973112319) {
                 const t111 = x2.mul(x2.mul(x2.sq()).sq());
                 const t111111 = t111.mul(t111.sqn(3));
@@ -291,10 +291,10 @@ pub fn Field(comptime params: FieldParams) type {
                 const t1111111 = x2.mul(t1111110);
                 const x12 = t1111110.sqn(5).mul(t111111);
                 const x31 = x12.sqn(12).mul(x12).sqn(7).mul(t1111111);
-                const x32 = x31.sq().mul(x2);
+                const x32 = x31.sq().mul(x2.*);
                 const x63 = x32.sqn(31).mul(x31);
                 const x126 = x63.sqn(63).mul(x63);
-                return x126.sqn(126).mul(x126).sqn(3).mul(t111).sqn(33).mul(x32).sqn(64).mul(x2).sqn(30);
+                return x126.sqn(126).mul(x126).sqn(3).mul(t111).sqn(33).mul(x32).sqn(64).mul(x2.*).sqn(30);
             } else if (field_order == 115792089237316195423570985008687907853269984665640564039457584007908834671663) {
                 const t11 = x2.mul(x2.sq());
                 const t1111 = t11.mul(t11.sqn(2));
@@ -312,9 +312,9 @@ pub fn Field(comptime params: FieldParams) type {
         }
 
         /// Compute the square root of `x2`, returning `error.NotSquare` if `x2` was not a square.
-        pub fn sqrt(x2: Fe) NotSquareError!Fe {
+        pub fn sqrt(x2: *const Fe) NotSquareError!Fe {
             const x = x2.uncheckedSqrt();
-            if (x.sq().equivalent(x2)) {
+            if ((&x).sq().equivalent(x2.*)) {
                 return x;
             }
             return error.NotSquare;
diff --git a/lib/std/crypto/pcurves/p256.zig b/lib/std/crypto/pcurves/p256.zig
index 5898f83c1..bc08442dd 100644
--- a/lib/std/crypto/pcurves/p256.zig
+++ b/lib/std/crypto/pcurves/p256.zig
@@ -35,7 +35,7 @@ pub const P256 = struct {
     pub const B = Fe.fromInt(41058363725152142129326129780047268409114441015993725554835256314039467401291) catch unreachable;
 
     /// Reject the neutral element.
-    pub fn rejectIdentity(p: P256) IdentityElementError!void {
+    pub fn rejectIdentity(p: *const P256) IdentityElementError!void {
         if (p.x.isZero()) {
             return error.IdentityElement;
         }
@@ -101,7 +101,7 @@ pub const P256 = struct {
     }
 
     /// Serialize a point using the compressed SEC-1 format.
-    pub fn toCompressedSec1(p: P256) [33]u8 {
+    pub fn toCompressedSec1(p: *const P256) [33]u8 {
         var out: [33]u8 = undefined;
         const xy = p.affineCoordinates();
         out[0] = if (xy.y.isOdd()) 3 else 2;
@@ -110,7 +110,7 @@ pub const P256 = struct {
     }
 
     /// Serialize a point using the uncompressed SEC-1 format.
-    pub fn toUncompressedSec1(p: P256) [65]u8 {
+    pub fn toUncompressedSec1(p: *const P256) [65]u8 {
         var out: [65]u8 = undefined;
         out[0] = 4;
         const xy = p.affineCoordinates();
@@ -126,13 +126,13 @@ pub const P256 = struct {
     }
 
     /// Flip the sign of the X coordinate.
-    pub fn neg(p: P256) P256 {
+    pub fn neg(p: *const P256) P256 {
         return .{ .x = p.x, .y = p.y.neg(), .z = p.z };
     }
 
     /// Double a P256 point.
     // Algorithm 6 from https://eprint.iacr.org/2015/1060.pdf
-    pub fn dbl(p: P256) P256 {
+    pub fn dbl(p: *const P256) P256 {
         var t0 = p.x.sq();
         var t1 = p.y.sq();
         var t2 = p.z.sq();
@@ -175,7 +175,7 @@ pub const P256 = struct {
 
     /// Add P256 points, the second being specified using affine coordinates.
     // Algorithm 5 from https://eprint.iacr.org/2015/1060.pdf
-    pub fn addMixed(p: P256, q: AffineCoordinates) P256 {
+    pub fn addMixed(p: *const P256, q: AffineCoordinates) P256 {
         var t0 = p.x.mul(q.x);
         var t1 = p.y.mul(q.y);
         var t3 = q.x.add(q.y);
@@ -223,7 +223,7 @@ pub const P256 = struct {
 
     /// Add P256 points.
     // Algorithm 4 from https://eprint.iacr.org/2015/1060.pdf
-    pub fn add(p: P256, q: P256) P256 {
+    pub fn add(p: *const P256, q: P256) P256 {
         var t0 = p.x.mul(q.x);
         var t1 = p.y.mul(q.y);
         var t2 = p.z.mul(q.z);
@@ -275,17 +275,17 @@ pub const P256 = struct {
     }
 
     /// Subtract P256 points.
-    pub fn sub(p: P256, q: P256) P256 {
+    pub fn sub(p: *const P256, q: P256) P256 {
         return p.add(q.neg());
     }
 
     /// Subtract P256 points, the second being specified using affine coordinates.
-    pub fn subMixed(p: P256, q: AffineCoordinates) P256 {
+    pub fn subMixed(p: *const P256, q: AffineCoordinates) P256 {
         return p.addMixed(q.neg());
     }
 
     /// Return affine coordinates.
-    pub fn affineCoordinates(p: P256) AffineCoordinates {
+    pub fn affineCoordinates(p: *const P256) AffineCoordinates {
         const zinv = p.z.invert();
         var ret = AffineCoordinates{
             .x = p.x.mul(zinv),
@@ -296,7 +296,7 @@ pub const P256 = struct {
     }
 
     /// Return true if both coordinate sets represent the same point.
-    pub fn equivalent(a: P256, b: P256) bool {
+    pub fn equivalent(a: *const P256, b: P256) bool {
         if (a.sub(b).rejectIdentity()) {
             return false;
         } else |_| {
@@ -395,25 +395,25 @@ pub const P256 = struct {
 
     /// Multiply an elliptic curve point by a scalar.
     /// Return error.IdentityElement if the result is the identity element.
-    pub fn mul(p: P256, s_: [32]u8, endian: std.builtin.Endian) IdentityElementError!P256 {
+    pub fn mul(p: *const P256, s_: [32]u8, endian: std.builtin.Endian) IdentityElementError!P256 {
         const s = if (endian == .Little) s_ else Fe.orderSwap(s_);
         if (p.is_base) {
             return pcMul16(&basePointPc, s, false);
         }
         try p.rejectIdentity();
-        const pc = precompute(p, 15);
+        const pc = precompute(p.*, 15);
         return pcMul16(&pc, s, false);
     }
 
     /// Multiply an elliptic curve point by a *PUBLIC* scalar *IN VARIABLE TIME*
     /// This can be used for signature verification.
-    pub fn mulPublic(p: P256, s_: [32]u8, endian: std.builtin.Endian) IdentityElementError!P256 {
+    pub fn mulPublic(p: *const P256, s_: [32]u8, endian: std.builtin.Endian) IdentityElementError!P256 {
         const s = if (endian == .Little) s_ else Fe.orderSwap(s_);
         if (p.is_base) {
             return pcMul16(&basePointPc, s, true);
         }
         try p.rejectIdentity();
-        const pc = precompute(p, 8);
+        const pc = precompute(p.*, 8);
         return pcMul(&pc, s, true);
     }
 
diff --git a/lib/std/crypto/pcurves/p256/scalar.zig b/lib/std/crypto/pcurves/p256/scalar.zig
index d3ac2a9b9..d0fc10b60 100644
--- a/lib/std/crypto/pcurves/p256/scalar.zig
+++ b/lib/std/crypto/pcurves/p256/scalar.zig
@@ -100,12 +100,12 @@ pub const Scalar = struct {
     }
 
     /// Pack a scalar into bytes.
-    pub fn toBytes(n: Scalar, endian: std.builtin.Endian) CompressedScalar {
+    pub fn toBytes(n: *const Scalar, endian: std.builtin.Endian) CompressedScalar {
         return n.fe.toBytes(endian);
     }
 
     /// Return true if the scalar is zero..
-    pub fn isZero(n: Scalar) bool {
+    pub fn isZero(n: *const Scalar) bool {
         return n.fe.isZero();
     }
 
@@ -125,7 +125,7 @@ pub const Scalar = struct {
     }
 
     /// Compute 2n (mod L)
-    pub fn dbl(n: Scalar) Scalar {
+    pub fn dbl(n: *const Scalar) Scalar {
         return Scalar{ .fe = n.fe.dbl() };
     }
 
@@ -135,7 +135,7 @@ pub const Scalar = struct {
     }
 
     /// Compute x^2 (mod L)
-    pub fn sq(n: Scalar) Scalar {
+    pub fn sq(n: *const Scalar) Scalar {
         return Scalar{ .fe = n.fe.sq() };
     }
 
@@ -145,22 +145,22 @@ pub const Scalar = struct {
     }
 
     /// Compute -x (mod L)
-    pub fn neg(n: Scalar) Scalar {
+    pub fn neg(n: *const Scalar) Scalar {
         return Scalar{ .fe = n.fe.neg() };
     }
 
     /// Compute x^-1 (mod L)
-    pub fn invert(n: Scalar) Scalar {
+    pub fn invert(n: *const Scalar) Scalar {
         return Scalar{ .fe = n.fe.invert() };
     }
 
     /// Return true if n is a quadratic residue mod L.
-    pub fn isSquare(n: Scalar) Scalar {
+    pub fn isSquare(n: *const Scalar) Scalar {
         return n.fe.isSquare();
     }
 
     /// Return the square root of L, or NotSquare if there isn't any solutions.
-    pub fn sqrt(n: Scalar) NotSquareError!Scalar {
+    pub fn sqrt(n: *const Scalar) NotSquareError!Scalar {
         return Scalar{ .fe = try n.fe.sqrt() };
     }
 
diff --git a/lib/std/crypto/pcurves/p384.zig b/lib/std/crypto/pcurves/p384.zig
index 0694d4f25..e54de786e 100644
--- a/lib/std/crypto/pcurves/p384.zig
+++ b/lib/std/crypto/pcurves/p384.zig
@@ -35,7 +35,7 @@ pub const P384 = struct {
     pub const B = Fe.fromInt(27580193559959705877849011840389048093056905856361568521428707301988689241309860865136260764883745107765439761230575) catch unreachable;
 
     /// Reject the neutral element.
-    pub fn rejectIdentity(p: P384) IdentityElementError!void {
+    pub fn rejectIdentity(p: *const P384) IdentityElementError!void {
         if (p.x.isZero()) {
             return error.IdentityElement;
         }
@@ -101,7 +101,7 @@ pub const P384 = struct {
     }
 
     /// Serialize a point using the compressed SEC-1 format.
-    pub fn toCompressedSec1(p: P384) [49]u8 {
+    pub fn toCompressedSec1(p: *const P384) [49]u8 {
         var out: [49]u8 = undefined;
         const xy = p.affineCoordinates();
         out[0] = if (xy.y.isOdd()) 3 else 2;
@@ -110,7 +110,7 @@ pub const P384 = struct {
     }
 
     /// Serialize a point using the uncompressed SEC-1 format.
-    pub fn toUncompressedSec1(p: P384) [97]u8 {
+    pub fn toUncompressedSec1(p: *const P384) [97]u8 {
         var out: [97]u8 = undefined;
         out[0] = 4;
         const xy = p.affineCoordinates();
@@ -126,13 +126,13 @@ pub const P384 = struct {
     }
 
     /// Flip the sign of the X coordinate.
-    pub fn neg(p: P384) P384 {
+    pub fn neg(p: *const P384) P384 {
         return .{ .x = p.x, .y = p.y.neg(), .z = p.z };
     }
 
     /// Double a P384 point.
     // Algorithm 6 from https://eprint.iacr.org/2015/1060.pdf
-    pub fn dbl(p: P384) P384 {
+    pub fn dbl(p: *const P384) P384 {
         var t0 = p.x.sq();
         var t1 = p.y.sq();
         var t2 = p.z.sq();
@@ -175,7 +175,7 @@ pub const P384 = struct {
 
     /// Add P384 points, the second being specified using affine coordinates.
     // Algorithm 5 from https://eprint.iacr.org/2015/1060.pdf
-    pub fn addMixed(p: P384, q: AffineCoordinates) P384 {
+    pub fn addMixed(p: *const P384, q: AffineCoordinates) P384 {
         var t0 = p.x.mul(q.x);
         var t1 = p.y.mul(q.y);
         var t3 = q.x.add(q.y);
@@ -223,7 +223,7 @@ pub const P384 = struct {
 
     /// Add P384 points.
     // Algorithm 4 from https://eprint.iacr.org/2015/1060.pdf
-    pub fn add(p: P384, q: P384) P384 {
+    pub fn add(p: *const P384, q: P384) P384 {
         var t0 = p.x.mul(q.x);
         var t1 = p.y.mul(q.y);
         var t2 = p.z.mul(q.z);
@@ -275,17 +275,17 @@ pub const P384 = struct {
     }
 
     /// Subtract P384 points.
-    pub fn sub(p: P384, q: P384) P384 {
+    pub fn sub(p: *const P384, q: P384) P384 {
         return p.add(q.neg());
     }
 
     /// Subtract P384 points, the second being specified using affine coordinates.
-    pub fn subMixed(p: P384, q: AffineCoordinates) P384 {
+    pub fn subMixed(p: *const P384, q: AffineCoordinates) P384 {
         return p.addMixed(q.neg());
     }
 
     /// Return affine coordinates.
-    pub fn affineCoordinates(p: P384) AffineCoordinates {
+    pub fn affineCoordinates(p: *const P384) AffineCoordinates {
         const zinv = p.z.invert();
         var ret = AffineCoordinates{
             .x = p.x.mul(zinv),
@@ -296,7 +296,7 @@ pub const P384 = struct {
     }
 
     /// Return true if both coordinate sets represent the same point.
-    pub fn equivalent(a: P384, b: P384) bool {
+    pub fn equivalent(a: *const P384, b: P384) bool {
         if (a.sub(b).rejectIdentity()) {
             return false;
         } else |_| {
@@ -389,31 +389,31 @@ pub const P384 = struct {
     }
 
     const basePointPc = pc: {
-        @setEvalBranchQuota(50000);
+        @setEvalBranchQuota(100000);
         break :pc precompute(P384.basePoint, 15);
     };
 
     /// Multiply an elliptic curve point by a scalar.
     /// Return error.IdentityElement if the result is the identity element.
-    pub fn mul(p: P384, s_: [48]u8, endian: std.builtin.Endian) IdentityElementError!P384 {
+    pub fn mul(p: *const P384, s_: [48]u8, endian: std.builtin.Endian) IdentityElementError!P384 {
         const s = if (endian == .Little) s_ else Fe.orderSwap(s_);
         if (p.is_base) {
             return pcMul16(&basePointPc, s, false);
         }
         try p.rejectIdentity();
-        const pc = precompute(p, 15);
+        const pc = precompute(p.*, 15);
         return pcMul16(&pc, s, false);
     }
 
     /// Multiply an elliptic curve point by a *PUBLIC* scalar *IN VARIABLE TIME*
     /// This can be used for signature verification.
-    pub fn mulPublic(p: P384, s_: [48]u8, endian: std.builtin.Endian) IdentityElementError!P384 {
+    pub fn mulPublic(p: *const P384, s_: [48]u8, endian: std.builtin.Endian) IdentityElementError!P384 {
         const s = if (endian == .Little) s_ else Fe.orderSwap(s_);
         if (p.is_base) {
             return pcMul16(&basePointPc, s, true);
         }
         try p.rejectIdentity();
-        const pc = precompute(p, 8);
+        const pc = precompute(p.*, 8);
         return pcMul(&pc, s, true);
     }
 
diff --git a/lib/std/crypto/pcurves/p384/scalar.zig b/lib/std/crypto/pcurves/p384/scalar.zig
index b6db0c83d..1b09308af 100644
--- a/lib/std/crypto/pcurves/p384/scalar.zig
+++ b/lib/std/crypto/pcurves/p384/scalar.zig
@@ -89,67 +89,67 @@ pub const Scalar = struct {
     }
 
     /// Pack a scalar into bytes.
-    pub fn toBytes(n: Scalar, endian: std.builtin.Endian) CompressedScalar {
+    pub fn toBytes(n: *const Scalar, endian: std.builtin.Endian) CompressedScalar {
         return n.fe.toBytes(endian);
     }
 
     /// Return true if the scalar is zero..
-    pub fn isZero(n: Scalar) bool {
+    pub fn isZero(n: *const Scalar) bool {
         return n.fe.isZero();
     }
 
     /// Return true if a and b are equivalent.
-    pub fn equivalent(a: Scalar, b: Scalar) bool {
+    pub fn equivalent(a: *const Scalar, b: Scalar) bool {
         return a.fe.equivalent(b.fe);
     }
 
     /// Compute x+y (mod L)
-    pub fn add(x: Scalar, y: Scalar) Scalar {
+    pub fn add(x: *const Scalar, y: Scalar) Scalar {
         return Scalar{ .fe = x.fe.add(y.fe) };
     }
 
     /// Compute x-y (mod L)
-    pub fn sub(x: Scalar, y: Scalar) Scalar {
+    pub fn sub(x: *const Scalar, y: Scalar) Scalar {
         return Scalar{ .fe = x.fe.sub(y.fe) };
     }
 
     /// Compute 2n (mod L)
-    pub fn dbl(n: Scalar) Scalar {
+    pub fn dbl(n: *const Scalar) Scalar {
         return Scalar{ .fe = n.fe.dbl() };
     }
 
     /// Compute x*y (mod L)
-    pub fn mul(x: Scalar, y: Scalar) Scalar {
+    pub fn mul(x: *const Scalar, y: Scalar) Scalar {
         return Scalar{ .fe = x.fe.mul(y.fe) };
     }
 
     /// Compute x^2 (mod L)
-    pub fn sq(n: Scalar) Scalar {
+    pub fn sq(n: *const Scalar) Scalar {
         return Scalar{ .fe = n.fe.sq() };
     }
 
     /// Compute x^n (mod L)
-    pub fn pow(a: Scalar, comptime T: type, comptime n: T) Scalar {
+    pub fn pow(a: *const Scalar, comptime T: type, comptime n: T) Scalar {
         return Scalar{ .fe = a.fe.pow(n) };
     }
 
     /// Compute -x (mod L)
-    pub fn neg(n: Scalar) Scalar {
+    pub fn neg(n: *const Scalar) Scalar {
         return Scalar{ .fe = n.fe.neg() };
     }
 
     /// Compute x^-1 (mod L)
-    pub fn invert(n: Scalar) Scalar {
+    pub fn invert(n: *const Scalar) Scalar {
         return Scalar{ .fe = n.fe.invert() };
     }
 
     /// Return true if n is a quadratic residue mod L.
-    pub fn isSquare(n: Scalar) Scalar {
+    pub fn isSquare(n: *const Scalar) Scalar {
         return n.fe.isSquare();
     }
 
     /// Return the square root of L, or NotSquare if there isn't any solutions.
-    pub fn sqrt(n: Scalar) NotSquareError!Scalar {
+    pub fn sqrt(n: *const Scalar) NotSquareError!Scalar {
         return Scalar{ .fe = try n.fe.sqrt() };
     }
 
diff --git a/lib/std/crypto/pcurves/secp256k1.zig b/lib/std/crypto/pcurves/secp256k1.zig
index 79698bd7d..3fd32d26d 100644
--- a/lib/std/crypto/pcurves/secp256k1.zig
+++ b/lib/std/crypto/pcurves/secp256k1.zig
@@ -73,14 +73,14 @@ pub const Secp256k1 = struct {
             var buf: [32]u8 = undefined;
 
             mem.writeIntLittle(u256, &buf, c1);
-            const c1x = scalar.mul(buf, b1_neg_s, .Little) catch unreachable;
+            const c1x = scalar.mul(&buf, b1_neg_s, .Little) catch unreachable;
 
             mem.writeIntLittle(u256, &buf, c2);
-            const c2x = scalar.mul(buf, b2_neg_s, .Little) catch unreachable;
+            const c2x = scalar.mul(&buf, b2_neg_s, .Little) catch unreachable;
 
             const r2 = scalar.add(c1x, c2x, .Little) catch unreachable;
 
-            var r1 = scalar.mul(r2, lambda_s, .Little) catch unreachable;
+            var r1 = scalar.mul(&r2, lambda_s, .Little) catch unreachable;
             r1 = scalar.sub(s, r1, .Little) catch unreachable;
 
             return SplitScalar{ .r1 = r1, .r2 = r2 };
@@ -88,7 +88,7 @@ pub const Secp256k1 = struct {
     };
 
     /// Reject the neutral element.
-    pub fn rejectIdentity(p: Secp256k1) IdentityElementError!void {
+    pub fn rejectIdentity(p: *const Secp256k1) IdentityElementError!void {
         if (p.x.isZero()) {
             return error.IdentityElement;
         }
@@ -154,7 +154,7 @@ pub const Secp256k1 = struct {
     }
 
     /// Serialize a point using the compressed SEC-1 format.
-    pub fn toCompressedSec1(p: Secp256k1) [33]u8 {
+    pub fn toCompressedSec1(p: *const Secp256k1) [33]u8 {
         var out: [33]u8 = undefined;
         const xy = p.affineCoordinates();
         out[0] = if (xy.y.isOdd()) 3 else 2;
@@ -163,7 +163,7 @@ pub const Secp256k1 = struct {
     }
 
     /// Serialize a point using the uncompressed SEC-1 format.
-    pub fn toUncompressedSec1(p: Secp256k1) [65]u8 {
+    pub fn toUncompressedSec1(p: *const Secp256k1) [65]u8 {
         var out: [65]u8 = undefined;
         out[0] = 4;
         const xy = p.affineCoordinates();
@@ -179,13 +179,13 @@ pub const Secp256k1 = struct {
     }
 
     /// Flip the sign of the X coordinate.
-    pub fn neg(p: Secp256k1) Secp256k1 {
+    pub fn neg(p: *const Secp256k1) Secp256k1 {
         return .{ .x = p.x, .y = p.y.neg(), .z = p.z };
     }
 
     /// Double a secp256k1 point.
     // Algorithm 9 from https://eprint.iacr.org/2015/1060.pdf
-    pub fn dbl(p: Secp256k1) Secp256k1 {
+    pub fn dbl(p: *const Secp256k1) Secp256k1 {
         var t0 = p.y.sq();
         var Z3 = t0.dbl();
         Z3 = Z3.dbl();
@@ -215,7 +215,7 @@ pub const Secp256k1 = struct {
 
     /// Add secp256k1 points, the second being specified using affine coordinates.
     // Algorithm 8 from https://eprint.iacr.org/2015/1060.pdf
-    pub fn addMixed(p: Secp256k1, q: AffineCoordinates) Secp256k1 {
+    pub fn addMixed(p: *const Secp256k1, q: AffineCoordinates) Secp256k1 {
         var t0 = p.x.mul(q.x);
         var t1 = p.y.mul(q.y);
         var t3 = q.x.add(q.y);
@@ -257,7 +257,7 @@ pub const Secp256k1 = struct {
 
     /// Add secp256k1 points.
     // Algorithm 7 from https://eprint.iacr.org/2015/1060.pdf
-    pub fn add(p: Secp256k1, q: Secp256k1) Secp256k1 {
+    pub fn add(p: *const Secp256k1, q: Secp256k1) Secp256k1 {
         var t0 = p.x.mul(q.x);
         var t1 = p.y.mul(q.y);
         var t2 = p.z.mul(q.z);
@@ -303,17 +303,17 @@ pub const Secp256k1 = struct {
     }
 
     /// Subtract secp256k1 points.
-    pub fn sub(p: Secp256k1, q: Secp256k1) Secp256k1 {
+    pub fn sub(p: *const Secp256k1, q: Secp256k1) Secp256k1 {
         return p.add(q.neg());
     }
 
     /// Subtract secp256k1 points, the second being specified using affine coordinates.
-    pub fn subMixed(p: Secp256k1, q: AffineCoordinates) Secp256k1 {
+    pub fn subMixed(p: *const Secp256k1, q: AffineCoordinates) Secp256k1 {
         return p.addMixed(q.neg());
     }
 
     /// Return affine coordinates.
-    pub fn affineCoordinates(p: Secp256k1) AffineCoordinates {
+    pub fn affineCoordinates(p: *const Secp256k1) AffineCoordinates {
         const zinv = p.z.invert();
         var ret = AffineCoordinates{
             .x = p.x.mul(zinv),
@@ -324,7 +324,7 @@ pub const Secp256k1 = struct {
     }
 
     /// Return true if both coordinate sets represent the same point.
-    pub fn equivalent(a: Secp256k1, b: Secp256k1) bool {
+    pub fn equivalent(a: *const Secp256k1, b: Secp256k1) bool {
         if (a.sub(b).rejectIdentity()) {
             return false;
         } else |_| {
@@ -423,28 +423,28 @@ pub const Secp256k1 = struct {
 
     /// Multiply an elliptic curve point by a scalar.
     /// Return error.IdentityElement if the result is the identity element.
-    pub fn mul(p: Secp256k1, s_: [32]u8, endian: std.builtin.Endian) IdentityElementError!Secp256k1 {
+    pub fn mul(p: *const Secp256k1, s_: [32]u8, endian: std.builtin.Endian) IdentityElementError!Secp256k1 {
         const s = if (endian == .Little) s_ else Fe.orderSwap(s_);
         if (p.is_base) {
             return pcMul16(&basePointPc, s, false);
         }
         try p.rejectIdentity();
-        const pc = precompute(p, 15);
+        const pc = precompute(p.*, 15);
         return pcMul16(&pc, s, false);
     }
 
     /// Multiply an elliptic curve point by a *PUBLIC* scalar *IN VARIABLE TIME*
     /// This can be used for signature verification.
-    pub fn mulPublic(p: Secp256k1, s_: [32]u8, endian: std.builtin.Endian) IdentityElementError!Secp256k1 {
+    pub fn mulPublic(p: *const Secp256k1, s_: [32]u8, endian: std.builtin.Endian) IdentityElementError!Secp256k1 {
         const s = if (endian == .Little) s_ else Fe.orderSwap(s_);
         const zero = comptime scalar.Scalar.zero.toBytes(.Little);
         if (mem.eql(u8, &zero, &s)) {
             return error.IdentityElement;
         }
-        const pc = precompute(p, 8);
+        const pc = precompute(p.*, 8);
         var lambda_p = try pcMul(&pc, Endormorphism.lambda_s, true);
         var split_scalar = Endormorphism.splitScalar(s, .Little);
-        var px = p;
+        var px = p.*;
 
         // If a key is negative, flip the sign to keep it half-sized,
         // and flip the sign of the Y point coordinate to compensate.
diff --git a/lib/std/crypto/pcurves/secp256k1/scalar.zig b/lib/std/crypto/pcurves/secp256k1/scalar.zig
index 2d91f8bc9..52a7fe56b 100644
--- a/lib/std/crypto/pcurves/secp256k1/scalar.zig
+++ b/lib/std/crypto/pcurves/secp256k1/scalar.zig
@@ -43,8 +43,8 @@ pub fn reduce64(s: [64]u8, endian: std.builtin.Endian) CompressedScalar {
 }
 
 /// Return a*b (mod L)
-pub fn mul(a: CompressedScalar, b: CompressedScalar, endian: std.builtin.Endian) NonCanonicalError!CompressedScalar {
-    return (try Scalar.fromBytes(a, endian)).mul(try Scalar.fromBytes(b, endian)).toBytes(endian);
+pub fn mul(a: *const CompressedScalar, b: CompressedScalar, endian: std.builtin.Endian) NonCanonicalError!CompressedScalar {
+    return (try Scalar.fromBytes(a.*, endian)).mul(try Scalar.fromBytes(b, endian)).toBytes(endian);
 }
 
 /// Return a*b+c (mod L)
@@ -100,7 +100,7 @@ pub const Scalar = struct {
     }
 
     /// Pack a scalar into bytes.
-    pub fn toBytes(n: Scalar, endian: std.builtin.Endian) CompressedScalar {
+    pub fn toBytes(n: *const Scalar, endian: std.builtin.Endian) CompressedScalar {
         return n.fe.toBytes(endian);
     }
 
@@ -115,7 +115,7 @@ pub const Scalar = struct {
     }
 
     /// Compute x+y (mod L)
-    pub fn add(x: Scalar, y: Scalar) Scalar {
+    pub fn add(x: *const Scalar, y: Scalar) Scalar {
         return Scalar{ .fe = x.fe.add(y.fe) };
     }
 
@@ -130,7 +130,7 @@ pub const Scalar = struct {
     }
 
     /// Compute x*y (mod L)
-    pub fn mul(x: Scalar, y: Scalar) Scalar {
+    pub fn mul(x: *const Scalar, y: Scalar) Scalar {
         return Scalar{ .fe = x.fe.mul(y.fe) };
     }
 
@@ -150,7 +150,7 @@ pub const Scalar = struct {
     }
 
     /// Compute x^-1 (mod L)
-    pub fn invert(n: Scalar) Scalar {
+    pub fn invert(n: *const Scalar) Scalar {
         return Scalar{ .fe = n.fe.invert() };
     }
 
diff --git a/lib/std/fifo.zig b/lib/std/fifo.zig
index b7c8f761d..c049d1306 100644
--- a/lib/std/fifo.zig
+++ b/lib/std/fifo.zig
@@ -42,11 +42,6 @@ pub fn LinearFifo(
         pub const Reader = std.io.Reader(*Self, error{}, readFn);
         pub const Writer = std.io.Writer(*Self, error{OutOfMemory}, appendWrite);
 
-        // Type of Self argument for slice operations.
-        // If buffer is inline (Static) then we need to ensure we haven't
-        // returned a slice into a copy on the stack
-        const SliceSelfArg = if (buffer_type == .Static) *Self else Self;
-
         pub usingnamespace switch (buffer_type) {
             .Static => struct {
                 pub fn init() Self {
@@ -80,7 +75,7 @@ pub fn LinearFifo(
             },
         };
 
-        pub fn deinit(self: Self) void {
+        pub fn deinit(self: *const Self) void {
             if (buffer_type == .Dynamic) self.allocator.free(self.buf);
         }
 
@@ -141,12 +136,12 @@ pub fn LinearFifo(
         }
 
         /// Returns number of items currently in fifo
-        pub fn readableLength(self: Self) usize {
+        pub fn readableLength(self: *const Self) usize {
             return self.count;
         }
 
         /// Returns a writable slice from the 'read' end of the fifo
-        fn readableSliceMut(self: SliceSelfArg, offset: usize) []T {
+        fn readableSliceMut(self: *Self, offset: usize) []T {
             if (offset > self.count) return &[_]T{};
 
             var start = self.head + offset;
@@ -160,7 +155,7 @@ pub fn LinearFifo(
         }
 
         /// Returns a readable slice from `offset`
-        pub fn readableSlice(self: SliceSelfArg, offset: usize) []const T {
+        pub fn readableSlice(self: *Self, offset: usize) []const T {
             return self.readableSliceMut(offset);
         }
 
@@ -232,13 +227,13 @@ pub fn LinearFifo(
         }
 
         /// Returns number of items available in fifo
-        pub fn writableLength(self: Self) usize {
+        pub fn writableLength(self: *const Self) usize {
             return self.buf.len - self.count;
         }
 
         /// Returns the first section of writable buffer
         /// Note that this may be of length 0
-        pub fn writableSlice(self: SliceSelfArg, offset: usize) []T {
+        pub fn writableSlice(self: *Self, offset: usize) []T {
             if (offset > self.buf.len) return &[_]T{};
 
             const tail = self.head + offset + self.count;
@@ -353,7 +348,7 @@ pub fn LinearFifo(
 
         /// Returns the item at `offset`.
         /// Asserts offset is within bounds.
-        pub fn peekItem(self: Self, offset: usize) T {
+        pub fn peekItem(self: *const Self, offset: usize) T {
             assert(offset < self.count);
 
             var index = self.head + offset;
diff --git a/lib/std/fmt/parse_float/FloatStream.zig b/lib/std/fmt/parse_float/FloatStream.zig
index 803ac65e6..a813638dd 100644
--- a/lib/std/fmt/parse_float/FloatStream.zig
+++ b/lib/std/fmt/parse_float/FloatStream.zig
@@ -13,7 +13,7 @@ pub fn init(s: []const u8) FloatStream {
 }
 
 // Returns the offset from the start *excluding* any underscores that were found.
-pub fn offsetTrue(self: FloatStream) usize {
+pub fn offsetTrue(self: *const FloatStream) usize {
     return self.offset - self.underscore_count;
 }
 
@@ -22,61 +22,61 @@ pub fn reset(self: *FloatStream) void {
     self.underscore_count = 0;
 }
 
-pub fn len(self: FloatStream) usize {
+pub fn len(self: *const FloatStream) usize {
     if (self.offset > self.slice.len) {
         return 0;
     }
     return self.slice.len - self.offset;
 }
 
-pub fn hasLen(self: FloatStream, n: usize) bool {
+pub fn hasLen(self: *const FloatStream, n: usize) bool {
     return self.offset + n <= self.slice.len;
 }
 
-pub fn firstUnchecked(self: FloatStream) u8 {
+pub fn firstUnchecked(self: *const FloatStream) u8 {
     return self.slice[self.offset];
 }
 
-pub fn first(self: FloatStream) ?u8 {
+pub fn first(self: *const FloatStream) ?u8 {
     return if (self.hasLen(1))
         return self.firstUnchecked()
     else
         null;
 }
 
-pub fn isEmpty(self: FloatStream) bool {
+pub fn isEmpty(self: *const FloatStream) bool {
     return !self.hasLen(1);
 }
 
-pub fn firstIs(self: FloatStream, c: u8) bool {
+pub fn firstIs(self: *const FloatStream, c: u8) bool {
     if (self.first()) |ok| {
         return ok == c;
     }
     return false;
 }
 
-pub fn firstIsLower(self: FloatStream, c: u8) bool {
+pub fn firstIsLower(self: *const FloatStream, c: u8) bool {
     if (self.first()) |ok| {
         return ok | 0x20 == c;
     }
     return false;
 }
 
-pub fn firstIs2(self: FloatStream, c1: u8, c2: u8) bool {
+pub fn firstIs2(self: *const FloatStream, c1: u8, c2: u8) bool {
     if (self.first()) |ok| {
         return ok == c1 or ok == c2;
     }
     return false;
 }
 
-pub fn firstIs3(self: FloatStream, c1: u8, c2: u8, c3: u8) bool {
+pub fn firstIs3(self: *const FloatStream, c1: u8, c2: u8, c3: u8) bool {
     if (self.first()) |ok| {
         return ok == c1 or ok == c2 or ok == c3;
     }
     return false;
 }
 
-pub fn firstIsDigit(self: FloatStream, comptime base: u8) bool {
+pub fn firstIsDigit(self: *const FloatStream, comptime base: u8) bool {
     comptime std.debug.assert(base == 10 or base == 16);
 
     if (self.first()) |ok| {
@@ -97,11 +97,11 @@ pub fn skipChars2(self: *FloatStream, c1: u8, c2: u8) void {
     while (self.firstIs2(c1, c2)) : (self.advance(1)) {}
 }
 
-pub fn readU64Unchecked(self: FloatStream) u64 {
+pub fn readU64Unchecked(self: *const FloatStream) u64 {
     return std.mem.readIntSliceLittle(u64, self.slice[self.offset..]);
 }
 
-pub fn readU64(self: FloatStream) ?u64 {
+pub fn readU64(self: *const FloatStream) ?u64 {
     if (self.hasLen(8)) {
         return self.readU64Unchecked();
     }
diff --git a/lib/std/fs.zig b/lib/std/fs.zig
index 30409fdc6..42d545e85 100644
--- a/lib/std/fs.zig
+++ b/lib/std/fs.zig
@@ -113,7 +113,7 @@ pub fn updateFileAbsolute(
     assert(path.isAbsolute(source_path));
     assert(path.isAbsolute(dest_path));
     const my_cwd = cwd();
-    return Dir.updateFile(my_cwd, source_path, my_cwd, dest_path, args);
+    return my_cwd.updateFile(source_path, my_cwd, dest_path, args);
 }
 
 /// Same as `Dir.copyFile`, except asserts that both `source_path` and `dest_path`
@@ -123,7 +123,7 @@ pub fn copyFileAbsolute(source_path: []const u8, dest_path: []const u8, args: Co
     assert(path.isAbsolute(source_path));
     assert(path.isAbsolute(dest_path));
     const my_cwd = cwd();
-    return Dir.copyFile(my_cwd, source_path, my_cwd, dest_path, args);
+    return my_cwd.copyFile(source_path, my_cwd, dest_path, args);
 }
 
 /// TODO update this API to avoid a getrandom syscall for every operation.
@@ -840,18 +840,18 @@ pub const IterableDir = struct {
         else => @compileError("unimplemented"),
     };
 
-    pub fn iterate(self: IterableDir) Iterator {
+    pub fn iterate(self: *const IterableDir) Iterator {
         return self.iterateImpl(true);
     }
 
     /// Like `iterate`, but will not reset the directory cursor before the first
     /// iteration. This should only be used in cases where it is known that the
     /// `IterableDir` has not had its cursor modified yet (e.g. it was just opened).
-    pub fn iterateAssumeFirstIteration(self: IterableDir) Iterator {
+    pub fn iterateAssumeFirstIteration(self: *const IterableDir) Iterator {
         return self.iterateImpl(false);
     }
 
-    fn iterateImpl(self: IterableDir, first_iter_start_value: bool) Iterator {
+    fn iterateImpl(self: *const IterableDir, first_iter_start_value: bool) Iterator {
         switch (builtin.os.tag) {
             .macos,
             .ios,
@@ -976,7 +976,7 @@ pub const IterableDir = struct {
     /// Must call `Walker.deinit` when done.
     /// The order of returned file system entries is undefined.
     /// `self` will not be closed after walking it.
-    pub fn walk(self: IterableDir, allocator: Allocator) !Walker {
+    pub fn walk(self: *const IterableDir, allocator: Allocator) !Walker {
         var name_buffer = std.ArrayList(u8).init(allocator);
         errdefer name_buffer.deinit();
 
@@ -1005,7 +1005,7 @@ pub const IterableDir = struct {
     /// The process must have the correct privileges in order to do this
     /// successfully, or must have the effective user ID matching the owner
     /// of the directory.
-    pub fn chmod(self: IterableDir, new_mode: File.Mode) ChmodError!void {
+    pub fn chmod(self: *const IterableDir, new_mode: File.Mode) ChmodError!void {
         const file: File = .{
             .handle = self.dir.fd,
             .capable_io_mode = .blocking,
@@ -1018,7 +1018,7 @@ pub const IterableDir = struct {
     /// successfully. The group may be changed by the owner of the directory to
     /// any group of which the owner is a member. If the
     /// owner or group is specified as `null`, the ID is not changed.
-    pub fn chown(self: IterableDir, owner: ?File.Uid, group: ?File.Gid) ChownError!void {
+    pub fn chown(self: *const IterableDir, owner: ?File.Uid, group: ?File.Gid) ChownError!void {
         const file: File = .{
             .handle = self.dir.fd,
             .capable_io_mode = .blocking,
@@ -2499,7 +2499,7 @@ pub const Dir = struct {
     /// Returns the previous status of the file before updating.
     /// If any of the directories do not exist for dest_path, they are created.
     pub fn updateFile(
-        source_dir: Dir,
+        source_dir: *const Dir,
         source_path: []const u8,
         dest_dir: Dir,
         dest_path: []const u8,
@@ -2548,7 +2548,7 @@ pub const Dir = struct {
     /// On Linux, until https://patchwork.kernel.org/patch/9636735/ is merged and readily available,
     /// there is a possibility of power loss or application termination leaving temporary files present
     /// in the same directory as dest_path.
-    pub fn copyFile(source_dir: Dir, source_path: []const u8, dest_dir: Dir, dest_path: []const u8, options: CopyFileOptions) CopyFileError!void {
+    pub fn copyFile(source_dir: *const Dir, source_path: []const u8, dest_dir: Dir, dest_path: []const u8, options: CopyFileOptions) CopyFileError!void {
         var in_file = try source_dir.openFile(source_path, .{});
         defer in_file.close();
 
diff --git a/lib/std/fs/file.zig b/lib/std/fs/file.zig
index 738da782b..550c593ae 100644
--- a/lib/std/fs/file.zig
+++ b/lib/std/fs/file.zig
@@ -420,7 +420,7 @@ pub const File = struct {
 
         /// Returns `true` if permissions represent an unwritable file.
         /// On Unix, `true` is returned only if no class has write permissions.
-        pub fn readOnly(self: Self) bool {
+        pub fn readOnly(self: *const Self) bool {
             return self.inner.readOnly();
         }
 
@@ -438,7 +438,7 @@ pub const File = struct {
         const Self = @This();
 
         /// Returns `true` if permissions represent an unwritable file.
-        pub fn readOnly(self: Self) bool {
+        pub fn readOnly(self: *const Self) bool {
             return self.attributes & os.windows.FILE_ATTRIBUTE_READONLY != 0;
         }
 
@@ -460,7 +460,7 @@ pub const File = struct {
 
         /// Returns `true` if permissions represent an unwritable file.
         /// `true` is returned only if no class has write permissions.
-        pub fn readOnly(self: Self) bool {
+        pub fn readOnly(self: *const Self) bool {
             return self.mode & 0o222 == 0;
         }
 
@@ -489,7 +489,7 @@ pub const File = struct {
 
         /// Returns `true` if the chosen class has the selected permission.
         /// This method is only available on Unix platforms.
-        pub fn unixHas(self: Self, class: Class, permission: Permission) bool {
+        pub fn unixHas(self: *const Self, class: Class, permission: Permission) bool {
             const mask = @as(Mode, @enumToInt(permission)) << @as(u3, @enumToInt(class)) * 3;
             return self.mode & mask != 0;
         }
@@ -582,28 +582,28 @@ pub const File = struct {
         const Self = @This();
 
         /// Returns the size of the file
-        pub fn size(self: Self) u64 {
+        pub fn size(self: *const Self) u64 {
             return self.inner.size();
         }
 
         /// Returns a `Permissions` struct, representing the permissions on the file
-        pub fn permissions(self: Self) Permissions {
+        pub fn permissions(self: *const Self) Permissions {
             return self.inner.permissions();
         }
 
         /// Returns the `Kind` of file.
         /// On Windows, can only return: `.File`, `.Directory`, `.SymLink` or `.Unknown`
-        pub fn kind(self: Self) Kind {
+        pub fn kind(self: *const Self) Kind {
             return self.inner.kind();
         }
 
         /// Returns the last time the file was accessed in nanoseconds since UTC 1970-01-01
-        pub fn accessed(self: Self) i128 {
+        pub fn accessed(self: *const Self) i128 {
             return self.inner.accessed();
         }
 
         /// Returns the time the file was modified in nanoseconds since UTC 1970-01-01
-        pub fn modified(self: Self) i128 {
+        pub fn modified(self: *const Self) i128 {
             return self.inner.modified();
         }
 
@@ -612,7 +612,7 @@ pub const File = struct {
         /// On Linux, this returns null if the filesystem does not support creation times, or if the kernel is older than 4.11
         /// On Unices, this returns null if the filesystem or OS does not support creation times
         /// On MacOS, this returns the ctime if the filesystem does not support creation times; this is insanity, and yet another reason to hate on Apple
-        pub fn created(self: Self) ?i128 {
+        pub fn created(self: *const Self) ?i128 {
             return self.inner.created();
         }
     };
@@ -623,17 +623,17 @@ pub const File = struct {
         const Self = @This();
 
         /// Returns the size of the file
-        pub fn size(self: Self) u64 {
+        pub fn size(self: *const Self) u64 {
             return @intCast(u64, self.stat.size);
         }
 
         /// Returns a `Permissions` struct, representing the permissions on the file
-        pub fn permissions(self: Self) Permissions {
+        pub fn permissions(self: *const Self) Permissions {
             return Permissions{ .inner = PermissionsUnix{ .mode = self.stat.mode } };
         }
 
         /// Returns the `Kind` of the file
-        pub fn kind(self: Self) Kind {
+        pub fn kind(self: *const Self) Kind {
             if (builtin.os.tag == .wasi and !builtin.link_libc) return switch (self.stat.filetype) {
                 .BLOCK_DEVICE => Kind.BlockDevice,
                 .CHARACTER_DEVICE => Kind.CharacterDevice,
@@ -667,20 +667,20 @@ pub const File = struct {
         }
 
         /// Returns the last time the file was accessed in nanoseconds since UTC 1970-01-01
-        pub fn accessed(self: Self) i128 {
+        pub fn accessed(self: *const Self) i128 {
             const atime = self.stat.atime();
             return @as(i128, atime.tv_sec) * std.time.ns_per_s + atime.tv_nsec;
         }
 
         /// Returns the last time the file was modified in nanoseconds since UTC 1970-01-01
-        pub fn modified(self: Self) i128 {
+        pub fn modified(self: *const Self) i128 {
             const mtime = self.stat.mtime();
             return @as(i128, mtime.tv_sec) * std.time.ns_per_s + mtime.tv_nsec;
         }
 
         /// Returns the time the file was created in nanoseconds since UTC 1970-01-01
         /// Returns null if this is not supported by the OS or filesystem
-        pub fn created(self: Self) ?i128 {
+        pub fn created(self: *const Self) ?i128 {
             if (!@hasDecl(@TypeOf(self.stat), "birthtime")) return null;
             const birthtime = self.stat.birthtime();
 
@@ -707,17 +707,17 @@ pub const File = struct {
         const Self = @This();
 
         /// Returns the size of the file
-        pub fn size(self: Self) u64 {
+        pub fn size(self: *const Self) u64 {
             return self.statx.size;
         }
 
         /// Returns a `Permissions` struct, representing the permissions on the file
-        pub fn permissions(self: Self) Permissions {
+        pub fn permissions(self: *const Self) Permissions {
             return Permissions{ .inner = PermissionsUnix{ .mode = self.statx.mode } };
         }
 
         /// Returns the `Kind` of the file
-        pub fn kind(self: Self) Kind {
+        pub fn kind(self: *const Self) Kind {
             const m = self.statx.mode & os.S.IFMT;
 
             switch (m) {
@@ -735,18 +735,18 @@ pub const File = struct {
         }
 
         /// Returns the last time the file was accessed in nanoseconds since UTC 1970-01-01
-        pub fn accessed(self: Self) i128 {
+        pub fn accessed(self: *const Self) i128 {
             return @as(i128, self.statx.atime.tv_sec) * std.time.ns_per_s + self.statx.atime.tv_nsec;
         }
 
         /// Returns the last time the file was modified in nanoseconds since UTC 1970-01-01
-        pub fn modified(self: Self) i128 {
+        pub fn modified(self: *const Self) i128 {
             return @as(i128, self.statx.mtime.tv_sec) * std.time.ns_per_s + self.statx.mtime.tv_nsec;
         }
 
         /// Returns the time the file was created in nanoseconds since UTC 1970-01-01
         /// Returns null if this is not supported by the filesystem, or on kernels before than version 4.11
-        pub fn created(self: Self) ?i128 {
+        pub fn created(self: *const Self) ?i128 {
             if (self.statx.mask & os.linux.STATX_BTIME == 0) return null;
             return @as(i128, self.statx.btime.tv_sec) * std.time.ns_per_s + self.statx.btime.tv_nsec;
         }
@@ -763,18 +763,18 @@ pub const File = struct {
         const Self = @This();
 
         /// Returns the size of the file
-        pub fn size(self: Self) u64 {
+        pub fn size(self: *const Self) u64 {
             return self._size;
         }
 
         /// Returns a `Permissions` struct, representing the permissions on the file
-        pub fn permissions(self: Self) Permissions {
+        pub fn permissions(self: *const Self) Permissions {
             return Permissions{ .inner = PermissionsWindows{ .attributes = self.attributes } };
         }
 
         /// Returns the `Kind` of the file.
         /// Can only return: `.File`, `.Directory`, `.SymLink` or `.Unknown`
-        pub fn kind(self: Self) Kind {
+        pub fn kind(self: *const Self) Kind {
             if (self.attributes & windows.FILE_ATTRIBUTE_REPARSE_POINT != 0) {
                 if (self.reparse_tag & 0x20000000 != 0) {
                     return .SymLink;
@@ -788,18 +788,18 @@ pub const File = struct {
         }
 
         /// Returns the last time the file was accessed in nanoseconds since UTC 1970-01-01
-        pub fn accessed(self: Self) i128 {
+        pub fn accessed(self: *const Self) i128 {
             return self.access_time;
         }
 
         /// Returns the time the file was modified in nanoseconds since UTC 1970-01-01
-        pub fn modified(self: Self) i128 {
+        pub fn modified(self: *const Self) i128 {
             return self.modified_time;
         }
 
         /// Returns the time the file was created in nanoseconds since UTC 1970-01-01
         /// This never returns null, only returning an optional for compatibility with other OSes
-        pub fn created(self: Self) ?i128 {
+        pub fn created(self: *const Self) ?i128 {
             return self.creation_time;
         }
     };
@@ -1240,7 +1240,7 @@ pub const File = struct {
 
     pub const CopyRangeError = os.CopyFileRangeError;
 
-    pub fn copyRange(in: File, in_offset: u64, out: File, out_offset: u64, len: u64) CopyRangeError!u64 {
+    pub fn copyRange(in: *const File, in_offset: u64, out: File, out_offset: u64, len: u64) CopyRangeError!u64 {
         const adjusted_len = math.cast(usize, len) orelse math.maxInt(usize);
         const result = try os.copy_file_range(in.handle, in_offset, out.handle, out_offset, adjusted_len, 0);
         return result;
@@ -1248,7 +1248,7 @@ pub const File = struct {
 
     /// Returns the number of bytes copied. If the number read is smaller than `buffer.len`, it
     /// means the in file reached the end. Reaching the end of a file is not an error condition.
-    pub fn copyRangeAll(in: File, in_offset: u64, out: File, out_offset: u64, len: u64) CopyRangeError!u64 {
+    pub fn copyRangeAll(in: *const File, in_offset: u64, out: File, out_offset: u64, len: u64) CopyRangeError!u64 {
         var total_bytes_copied: u64 = 0;
         var in_off = in_offset;
         var out_off = out_offset;
@@ -1384,8 +1384,8 @@ pub const File = struct {
 
     pub const Reader = io.Reader(File, ReadError, readFn);
 
-    pub fn reader(file: File) Reader {
-        return .{ .context = file };
+    pub fn reader(file: *const File) Reader {
+        return .{ .context = file.* };
     }
 
     pub const Writer = io.Writer(File, WriteError, writeFn);
diff --git a/lib/std/hash_map.zig b/lib/std/hash_map.zig
index 76c13238a..0faf55a3f 100644
--- a/lib/std/hash_map.zig
+++ b/lib/std/hash_map.zig
@@ -647,26 +647,26 @@ pub fn HashMap(
         }
 
         /// Creates a copy of this map, using the same allocator
-        pub fn clone(self: Self) Allocator.Error!Self {
+        pub fn clone(self: *const Self) Allocator.Error!Self {
             var other = try self.unmanaged.cloneContext(self.allocator, self.ctx);
             return other.promoteContext(self.allocator, self.ctx);
         }
 
         /// Creates a copy of this map, using a specified allocator
-        pub fn cloneWithAllocator(self: Self, new_allocator: Allocator) Allocator.Error!Self {
+        pub fn cloneWithAllocator(self: *const Self, new_allocator: Allocator) Allocator.Error!Self {
             var other = try self.unmanaged.cloneContext(new_allocator, self.ctx);
             return other.promoteContext(new_allocator, self.ctx);
         }
 
         /// Creates a copy of this map, using a specified context
-        pub fn cloneWithContext(self: Self, new_ctx: anytype) Allocator.Error!HashMap(K, V, @TypeOf(new_ctx), max_load_percentage) {
+        pub fn cloneWithContext(self: *const Self, new_ctx: anytype) Allocator.Error!HashMap(K, V, @TypeOf(new_ctx), max_load_percentage) {
             var other = try self.unmanaged.cloneContext(self.allocator, new_ctx);
             return other.promoteContext(self.allocator, new_ctx);
         }
 
         /// Creates a copy of this map, using a specified allocator and context.
         pub fn cloneWithAllocatorAndContext(
-            self: Self,
+            self: *const Self,
             new_allocator: Allocator,
             new_ctx: anytype,
         ) Allocator.Error!HashMap(K, V, @TypeOf(new_ctx), max_load_percentage) {
@@ -875,7 +875,7 @@ pub fn HashMapUnmanaged(
 
         pub fn promoteContext(self: *const Self, allocator: Allocator, ctx: Context) Managed {
             return .{
-                .unmanaged = self,
+                .unmanaged = self.*,
                 .allocator = allocator,
                 .ctx = ctx,
             };
@@ -1307,7 +1307,7 @@ pub fn HashMapUnmanaged(
 
             // If you get a compile error on this line, it means that your generic hash
             // function is invalid for these parameters.
-            const hash = ctx.hash(key);
+            const hash = @TypeOf(ctx).hash(ctx, key);
             // verifyContext can't verify the return type of generic hash functions,
             // so we need to double-check it here.
             if (@TypeOf(hash) != Hash) {
@@ -1325,7 +1325,7 @@ pub fn HashMapUnmanaged(
                     const test_key = &self.keys()[idx];
                     // If you get a compile error on this line, it means that your generic eql
                     // function is invalid for these parameters.
-                    const eql = ctx.eql(key, test_key.*);
+                    const eql = @TypeOf(ctx).eql(ctx, key, test_key.*);
                     // verifyContext can't verify the return type of generic eql functions,
                     // so we need to double-check it here.
                     if (@TypeOf(eql) != bool) {
@@ -1458,12 +1458,12 @@ pub fn HashMapUnmanaged(
             }
         }
 
-        pub fn clone(self: Self, allocator: Allocator) Allocator.Error!Self {
+        pub fn clone(self: *const Self, allocator: Allocator) Allocator.Error!Self {
             if (@sizeOf(Context) != 0)
                 @compileError("Cannot infer context " ++ @typeName(Context) ++ ", call cloneContext instead.");
             return self.cloneContext(allocator, @as(Context, undefined));
         }
-        pub fn cloneContext(self: Self, allocator: Allocator, new_ctx: anytype) Allocator.Error!HashMapUnmanaged(K, V, @TypeOf(new_ctx), max_load_percentage) {
+        pub fn cloneContext(self: *const Self, allocator: Allocator, new_ctx: anytype) Allocator.Error!HashMapUnmanaged(K, V, @TypeOf(new_ctx), max_load_percentage) {
             var other = HashMapUnmanaged(K, V, @TypeOf(new_ctx), max_load_percentage){};
             if (self.size == 0)
                 return other;
@@ -2082,7 +2082,8 @@ test "std.hash_map getOrPutAdapted" {
         fn hash(self: @This(), adapted_key: []const u8) u64 {
             _ = self;
             const key = std.fmt.parseInt(u64, adapted_key, 10) catch unreachable;
-            return (AutoContext(u64){}).hash(key);
+            const T = AutoContext(u64);
+            return T.hash(T{}, key);
         }
     };
     var map = AutoHashMap(u64, u64).init(testing.allocator);
diff --git a/lib/std/heap/arena_allocator.zig b/lib/std/heap/arena_allocator.zig
index 690d88dfe..0c57f0d88 100644
--- a/lib/std/heap/arena_allocator.zig
+++ b/lib/std/heap/arena_allocator.zig
@@ -33,7 +33,7 @@ pub const ArenaAllocator = struct {
         return (State{}).promote(child_allocator);
     }
 
-    pub fn deinit(self: ArenaAllocator) void {
+    pub fn deinit(self: *const ArenaAllocator) void {
         var it = self.state.buffer_list.first;
         while (it) |node| {
             // this has to occur before the free because the free frees node
diff --git a/lib/std/http/status.zig b/lib/std/http/status.zig
index 91738e053..925bbff1c 100644
--- a/lib/std/http/status.zig
+++ b/lib/std/http/status.zig
@@ -159,8 +159,8 @@ pub const Status = enum(u10) {
         server_error,
     };
 
-    pub fn class(self: Status) ?Class {
-        return switch (@enumToInt(self)) {
+    pub fn class(self: *const Status) ?Class {
+        return switch (@enumToInt(self.*)) {
             100...199 => .informational,
             200...299 => .success,
             300...399 => .redirect,
diff --git a/lib/std/json.zig b/lib/std/json.zig
index 87fe1c9de..72f395cdf 100644
--- a/lib/std/json.zig
+++ b/lib/std/json.zig
@@ -88,7 +88,7 @@ pub const Token = union(enum) {
         /// Whether string contains an escape sequence and cannot be zero-copied
         escapes: StringEscapes,
 
-        pub fn decodedLength(self: @This()) usize {
+        pub fn decodedLength(self: *const @This()) usize {
             return self.count +% switch (self.escapes) {
                 .None => 0,
                 .Some => |s| @bitCast(usize, s.size_diff),
@@ -96,7 +96,7 @@ pub const Token = union(enum) {
         }
 
         /// Slice into the underlying input string.
-        pub fn slice(self: @This(), input: []const u8, i: usize) []const u8 {
+        pub fn slice(self: *const @This(), input: []const u8, i: usize) []const u8 {
             return input[i - self.count .. i];
         }
     },
@@ -108,7 +108,7 @@ pub const Token = union(enum) {
         is_integer: bool,
 
         /// Slice into the underlying input string.
-        pub fn slice(self: @This(), input: []const u8, i: usize) []const u8 {
+        pub fn slice(self: *const @This(), input: []const u8, i: usize) []const u8 {
             return input[i - self.count .. i];
         }
     },
diff --git a/lib/std/math.zig b/lib/std/math.zig
index 1077b4d23..0bd05dab5 100644
--- a/lib/std/math.zig
+++ b/lib/std/math.zig
@@ -1401,16 +1401,16 @@ pub const Order = enum {
     /// Greater than (`>`)
     gt,
 
-    pub fn invert(self: Order) Order {
-        return switch (self) {
+    pub fn invert(self: *const Order) Order {
+        return switch (self.*) {
             .lt => .gt,
             .eq => .eq,
             .gt => .lt,
         };
     }
 
-    pub fn compare(self: Order, op: CompareOperator) bool {
-        return switch (self) {
+    pub fn compare(self: *const Order, op: CompareOperator) bool {
+        return switch (self.*) {
             .lt => switch (op) {
                 .lt => true,
                 .lte => true,
@@ -1509,9 +1509,9 @@ test "order" {
 }
 
 test "order.invert" {
-    try testing.expect(Order.invert(order(0, 0)) == .eq);
-    try testing.expect(Order.invert(order(1, 0)) == .lt);
-    try testing.expect(Order.invert(order(-1, 0)) == .gt);
+    try testing.expect(order(0, 0).invert() == .eq);
+    try testing.expect(order(1, 0).invert() == .lt);
+    try testing.expect(order(-1, 0).invert() == .gt);
 }
 
 test "order.compare" {
diff --git a/lib/std/math/big/int.zig b/lib/std/math/big/int.zig
index b875f73b2..8dff0e523 100644
--- a/lib/std/math/big/int.zig
+++ b/lib/std/math/big/int.zig
@@ -135,7 +135,7 @@ pub const Mutable = struct {
     len: usize,
     positive: bool,
 
-    pub fn toConst(self: Mutable) Const {
+    pub fn toConst(self: *const Mutable) Const {
         return .{
             .limbs = self.limbs[0..self.len],
             .positive = self.positive,
@@ -143,13 +143,13 @@ pub const Mutable = struct {
     }
 
     /// Returns true if `a == 0`.
-    pub fn eqZero(self: Mutable) bool {
+    pub fn eqZero(self: *const Mutable) bool {
         return self.toConst().eqZero();
     }
 
     /// Asserts that the allocator owns the limbs memory. If this is not the case,
     /// use `toConst().toManaged()`.
-    pub fn toManaged(self: Mutable, allocator: Allocator) Managed {
+    pub fn toManaged(self: *const Mutable, allocator: Allocator) Managed {
         return .{
             .allocator = allocator,
             .limbs = self.limbs,
@@ -190,7 +190,7 @@ pub const Mutable = struct {
         mem.swap(Mutable, self, other);
     }
 
-    pub fn dump(self: Mutable) void {
+    pub fn dump(self: *const Mutable) void {
         for (self.limbs[0..self.len]) |limb| {
             std.debug.print("{x} ", .{limb});
         }
@@ -1877,7 +1877,7 @@ pub const Const = struct {
     positive: bool,
 
     /// The result is an independent resource which is managed by the caller.
-    pub fn toManaged(self: Const, allocator: Allocator) Allocator.Error!Managed {
+    pub fn toManaged(self: *const Const, allocator: Allocator) Allocator.Error!Managed {
         const limbs = try allocator.alloc(Limb, math.max(Managed.default_capacity, self.limbs.len));
         mem.copy(Limb, limbs, self.limbs);
         return Managed{
@@ -1891,7 +1891,7 @@ pub const Const = struct {
     }
 
     /// Asserts `limbs` is big enough to store the value.
-    pub fn toMutable(self: Const, limbs: []Limb) Mutable {
+    pub fn toMutable(self: *const Const, limbs: []Limb) Mutable {
         mem.copy(Limb, limbs, self.limbs[0..self.limbs.len]);
         return .{
             .limbs = limbs,
@@ -1900,37 +1900,37 @@ pub const Const = struct {
         };
     }
 
-    pub fn dump(self: Const) void {
+    pub fn dump(self: *const Const) void {
         for (self.limbs[0..self.limbs.len]) |limb| {
             std.debug.print("{x} ", .{limb});
         }
         std.debug.print("positive={}\n", .{self.positive});
     }
 
-    pub fn abs(self: Const) Const {
+    pub fn abs(self: *const Const) Const {
         return .{
             .limbs = self.limbs,
             .positive = true,
         };
     }
 
-    pub fn negate(self: Const) Const {
+    pub fn negate(self: *const Const) Const {
         return .{
             .limbs = self.limbs,
             .positive = !self.positive,
         };
     }
 
-    pub fn isOdd(self: Const) bool {
+    pub fn isOdd(self: *const Const) bool {
         return self.limbs[0] & 1 != 0;
     }
 
-    pub fn isEven(self: Const) bool {
+    pub fn isEven(self: *const Const) bool {
         return !self.isOdd();
     }
 
     /// Returns the number of bits required to represent the absolute value of an integer.
-    pub fn bitCountAbs(self: Const) usize {
+    pub fn bitCountAbs(self: *const Const) usize {
         return (self.limbs.len - 1) * limb_bits + (limb_bits - @clz(self.limbs[self.limbs.len - 1]));
     }
 
@@ -1942,7 +1942,7 @@ pub const Const = struct {
     /// one greater than the returned value.
     ///
     /// e.g. -127 returns 8 as it will fit in an i8. 127 returns 7 since it fits in a u7.
-    pub fn bitCountTwosComp(self: Const) usize {
+    pub fn bitCountTwosComp(self: *const Const) usize {
         var bits = self.bitCountAbs();
 
         // If the entire value has only one bit set (e.g. 0b100000000) then the negation in twos
@@ -1964,7 +1964,7 @@ pub const Const = struct {
         return bits;
     }
 
-    pub fn fitsInTwosComp(self: Const, signedness: Signedness, bit_count: usize) bool {
+    pub fn fitsInTwosComp(self: *const Const, signedness: Signedness, bit_count: usize) bool {
         if (self.eqZero()) {
             return true;
         }
@@ -1977,7 +1977,7 @@ pub const Const = struct {
     }
 
     /// Returns whether self can fit into an integer of the requested type.
-    pub fn fits(self: Const, comptime T: type) bool {
+    pub fn fits(self: *const Const, comptime T: type) bool {
         const info = @typeInfo(T).Int;
         return self.fitsInTwosComp(info.signedness, info.bits);
     }
@@ -1986,7 +1986,7 @@ pub const Const = struct {
     /// the minus sign. This is used for determining the number of characters needed to print the
     /// value. It is inexact and may exceed the given value by ~1-2 bytes.
     /// TODO See if we can make this exact.
-    pub fn sizeInBaseUpperBound(self: Const, base: usize) usize {
+    pub fn sizeInBaseUpperBound(self: *const Const, base: usize) usize {
         const bit_count = @as(usize, @boolToInt(!self.positive)) + self.bitCountAbs();
         return (bit_count / math.log2(base)) + 2;
     }
@@ -1999,7 +1999,7 @@ pub const Const = struct {
     /// Convert self to type T.
     ///
     /// Returns an error if self cannot be narrowed into the requested type without truncation.
-    pub fn to(self: Const, comptime T: type) ConvertError!T {
+    pub fn to(self: *const Const, comptime T: type) ConvertError!T {
         switch (@typeInfo(T)) {
             .Int => |info| {
                 const UT = std.meta.Int(.unsigned, info.bits);
@@ -2044,7 +2044,7 @@ pub const Const = struct {
     /// This is because the rendering algorithm requires reversing a string, which requires O(N) memory.
     /// See `toString` and `toStringAlloc` for a way to print big integers without failure.
     pub fn format(
-        self: Const,
+        self: *const Const,
         comptime fmt: []const u8,
         options: std.fmt.FormatOptions,
         out_stream: anytype,
@@ -2090,7 +2090,7 @@ pub const Const = struct {
     /// Caller owns returned memory.
     /// Asserts that `base` is in the range [2, 16].
     /// See also `toString`, a lower level function than this.
-    pub fn toStringAlloc(self: Const, allocator: Allocator, base: u8, case: std.fmt.Case) Allocator.Error![]u8 {
+    pub fn toStringAlloc(self: *const Const, allocator: Allocator, base: u8, case: std.fmt.Case) Allocator.Error![]u8 {
         assert(base >= 2);
         assert(base <= 16);
 
@@ -2115,7 +2115,7 @@ pub const Const = struct {
     /// length of at least `calcToStringLimbsBufferLen`.
     /// In the case of power-of-two base, `limbs_buffer` is ignored.
     /// See also `toStringAlloc`, a higher level function than this.
-    pub fn toString(self: Const, string: []u8, base: u8, case: std.fmt.Case, limbs_buffer: []Limb) usize {
+    pub fn toString(self: *const Const, string: []u8, base: u8, case: std.fmt.Case, limbs_buffer: []Limb) usize {
         assert(base >= 2);
         assert(base <= 16);
 
@@ -2334,20 +2334,20 @@ pub const Const = struct {
     }
 
     /// Returns true if `a == 0`.
-    pub fn eqZero(a: Const) bool {
+    pub fn eqZero(a: *const Const) bool {
         var d: Limb = 0;
         for (a.limbs) |limb| d |= limb;
         return d == 0;
     }
 
     /// Returns true if `|a| == |b|`.
-    pub fn eqAbs(a: Const, b: Const) bool {
-        return orderAbs(a, b) == .eq;
+    pub fn eqAbs(a: *const Const, b: Const) bool {
+        return orderAbs(a.*, b) == .eq;
     }
 
     /// Returns true if `a == b`.
-    pub fn eq(a: Const, b: Const) bool {
-        return order(a, b) == .eq;
+    pub fn eq(a: *const Const, b: Const) bool {
+        return order(a.*, b) == .eq;
     }
 };
 
@@ -2383,7 +2383,7 @@ pub const Managed = struct {
         return initCapacity(allocator, default_capacity);
     }
 
-    pub fn toMutable(self: Managed) Mutable {
+    pub fn toMutable(self: *const Managed) Mutable {
         return .{
             .limbs = self.limbs,
             .positive = self.isPositive(),
@@ -2391,7 +2391,7 @@ pub const Managed = struct {
         };
     }
 
-    pub fn toConst(self: Managed) Const {
+    pub fn toConst(self: *const Managed) Const {
         return .{
             .limbs = self.limbs[0..self.len()],
             .positive = self.isPositive(),
@@ -2424,12 +2424,12 @@ pub const Managed = struct {
     }
 
     /// Returns the number of limbs currently in use.
-    pub fn len(self: Managed) usize {
+    pub fn len(self: *const Managed) usize {
         return self.metadata & ~sign_bit;
     }
 
     /// Returns whether an Managed is positive.
-    pub fn isPositive(self: Managed) bool {
+    pub fn isPositive(self: *const Managed) bool {
         return self.metadata & sign_bit == 0;
     }
 
@@ -2473,11 +2473,11 @@ pub const Managed = struct {
     /// Returns a `Managed` with the same value. The returned `Managed` is a deep copy and
     /// can be modified separately from the original, and its resources are managed
     /// separately from the original.
-    pub fn clone(other: Managed) !Managed {
+    pub fn clone(other: *const Managed) !Managed {
         return other.cloneWithDifferentAllocator(other.allocator);
     }
 
-    pub fn cloneWithDifferentAllocator(other: Managed, allocator: Allocator) !Managed {
+    pub fn cloneWithDifferentAllocator(other: *const Managed, allocator: Allocator) !Managed {
         return Managed{
             .allocator = allocator,
             .metadata = other.metadata,
@@ -2506,7 +2506,7 @@ pub const Managed = struct {
     }
 
     /// Debugging tool: prints the state to stderr.
-    pub fn dump(self: Managed) void {
+    pub fn dump(self: *const Managed) void {
         for (self.limbs[0..self.len()]) |limb| {
             std.debug.print("{x} ", .{limb});
         }
@@ -2523,16 +2523,16 @@ pub const Managed = struct {
         self.metadata &= ~sign_bit;
     }
 
-    pub fn isOdd(self: Managed) bool {
+    pub fn isOdd(self: *const Managed) bool {
         return self.limbs[0] & 1 != 0;
     }
 
-    pub fn isEven(self: Managed) bool {
+    pub fn isEven(self: *const Managed) bool {
         return !self.isOdd();
     }
 
     /// Returns the number of bits required to represent the absolute value of an integer.
-    pub fn bitCountAbs(self: Managed) usize {
+    pub fn bitCountAbs(self: *const Managed) usize {
         return self.toConst().bitCountAbs();
     }
 
@@ -2544,23 +2544,23 @@ pub const Managed = struct {
     /// one greater than the returned value.
     ///
     /// e.g. -127 returns 8 as it will fit in an i8. 127 returns 7 since it fits in a u7.
-    pub fn bitCountTwosComp(self: Managed) usize {
+    pub fn bitCountTwosComp(self: *const Managed) usize {
         return self.toConst().bitCountTwosComp();
     }
 
-    pub fn fitsInTwosComp(self: Managed, signedness: Signedness, bit_count: usize) bool {
+    pub fn fitsInTwosComp(self: *const Managed, signedness: Signedness, bit_count: usize) bool {
         return self.toConst().fitsInTwosComp(signedness, bit_count);
     }
 
     /// Returns whether self can fit into an integer of the requested type.
-    pub fn fits(self: Managed, comptime T: type) bool {
+    pub fn fits(self: *const Managed, comptime T: type) bool {
         return self.toConst().fits(T);
     }
 
     /// Returns the approximate size of the integer in the given base. Negative values accommodate for
     /// the minus sign. This is used for determining the number of characters needed to print the
     /// value. It is inexact and may exceed the given value by ~1-2 bytes.
-    pub fn sizeInBaseUpperBound(self: Managed, base: usize) usize {
+    pub fn sizeInBaseUpperBound(self: *const Managed, base: usize) usize {
         return self.toConst().sizeInBaseUpperBound(base);
     }
 
@@ -2577,7 +2577,7 @@ pub const Managed = struct {
     /// Convert self to type T.
     ///
     /// Returns an error if self cannot be narrowed into the requested type without truncation.
-    pub fn to(self: Managed, comptime T: type) ConvertError!T {
+    pub fn to(self: *const Managed, comptime T: type) ConvertError!T {
         return self.toConst().to(T);
     }
 
@@ -2618,7 +2618,7 @@ pub const Managed = struct {
 
     /// Converts self to a string in the requested base. Memory is allocated from the provided
     /// allocator and not the one present in self.
-    pub fn toString(self: Managed, allocator: Allocator, base: u8, case: std.fmt.Case) ![]u8 {
+    pub fn toString(self: *const Managed, allocator: Allocator, base: u8, case: std.fmt.Case) ![]u8 {
         if (base < 2 or base > 16) return error.InvalidBase;
         return self.toConst().toStringAlloc(allocator, base, case);
     }
@@ -2629,7 +2629,7 @@ pub const Managed = struct {
     /// This is because the rendering algorithm requires reversing a string, which requires O(N) memory.
     /// See `toString` and `toStringAlloc` for a way to print big integers without failure.
     pub fn format(
-        self: Managed,
+        self: *const Managed,
         comptime fmt: []const u8,
         options: std.fmt.FormatOptions,
         out_stream: anytype,
@@ -2640,27 +2640,27 @@ pub const Managed = struct {
     /// Returns math.Order.lt, math.Order.eq, math.Order.gt if |a| < |b|, |a| ==
     /// |b| or |a| > |b| respectively.
     pub fn orderAbs(a: Managed, b: Managed) math.Order {
-        return a.toConst().orderAbs(b.toConst());
+        return Const.orderAbs(a.toConst(), b.toConst());
     }
 
     /// Returns math.Order.lt, math.Order.eq, math.Order.gt if a < b, a == b or a
     /// > b respectively.
     pub fn order(a: Managed, b: Managed) math.Order {
-        return a.toConst().order(b.toConst());
+        return Const.order(a.toConst(), b.toConst());
     }
 
     /// Returns true if a == 0.
-    pub fn eqZero(a: Managed) bool {
+    pub fn eqZero(a: *const Managed) bool {
         return a.toConst().eqZero();
     }
 
     /// Returns true if |a| == |b|.
-    pub fn eqAbs(a: Managed, b: Managed) bool {
+    pub fn eqAbs(a: *const Managed, b: Managed) bool {
         return a.toConst().eqAbs(b.toConst());
     }
 
     /// Returns true if a == b.
-    pub fn eq(a: Managed, b: Managed) bool {
+    pub fn eq(a: *const Managed, b: Managed) bool {
         return a.toConst().eq(b.toConst());
     }
 
diff --git a/lib/std/math/big/rational.zig b/lib/std/math/big/rational.zig
index 98433b26f..2aeba92c6 100644
--- a/lib/std/math/big/rational.zig
+++ b/lib/std/math/big/rational.zig
@@ -335,14 +335,14 @@ pub const Rational = struct {
 
     /// Returns math.Order.lt, math.Order.eq, math.Order.gt if a < b, a == b or a
     /// > b respectively.
-    pub fn order(a: Rational, b: Rational) !math.Order {
-        return cmpInternal(a, b, false);
+    pub fn order(a: *const Rational, b: Rational) !math.Order {
+        return cmpInternal(a.*, b, false);
     }
 
     /// Returns math.Order.lt, math.Order.eq, math.Order.gt if |a| < |b|, |a| ==
     /// |b| or |a| > |b| respectively.
-    pub fn orderAbs(a: Rational, b: Rational) !math.Order {
-        return cmpInternal(a, b, true);
+    pub fn orderAbs(a: *const Rational, b: Rational) !math.Order {
+        return cmpInternal(a.*, b, true);
     }
 
     // p/q > x/y iff p*y > x*q
diff --git a/lib/std/math/complex.zig b/lib/std/math/complex.zig
index b4a87492c..9704f364f 100644
--- a/lib/std/math/complex.zig
+++ b/lib/std/math/complex.zig
@@ -43,7 +43,7 @@ pub fn Complex(comptime T: type) type {
         }
 
         /// Returns the sum of two complex numbers.
-        pub fn add(self: Self, other: Self) Self {
+        pub fn add(self: *const Self, other: Self) Self {
             return Self{
                 .re = self.re + other.re,
                 .im = self.im + other.im,
@@ -51,7 +51,7 @@ pub fn Complex(comptime T: type) type {
         }
 
         /// Returns the subtraction of two complex numbers.
-        pub fn sub(self: Self, other: Self) Self {
+        pub fn sub(self: *const Self, other: Self) Self {
             return Self{
                 .re = self.re - other.re,
                 .im = self.im - other.im,
@@ -59,7 +59,7 @@ pub fn Complex(comptime T: type) type {
         }
 
         /// Returns the product of two complex numbers.
-        pub fn mul(self: Self, other: Self) Self {
+        pub fn mul(self: *const Self, other: Self) Self {
             return Self{
                 .re = self.re * other.re - self.im * other.im,
                 .im = self.im * other.re + self.re * other.im,
@@ -67,7 +67,7 @@ pub fn Complex(comptime T: type) type {
         }
 
         /// Returns the quotient of two complex numbers.
-        pub fn div(self: Self, other: Self) Self {
+        pub fn div(self: *const Self, other: Self) Self {
             const re_num = self.re * other.re + self.im * other.im;
             const im_num = self.im * other.re - self.re * other.im;
             const den = other.re * other.re + other.im * other.im;
@@ -79,7 +79,7 @@ pub fn Complex(comptime T: type) type {
         }
 
         /// Returns the complex conjugate of a number.
-        pub fn conjugate(self: Self) Self {
+        pub fn conjugate(self: *const Self) Self {
             return Self{
                 .re = self.re,
                 .im = -self.im,
@@ -87,7 +87,7 @@ pub fn Complex(comptime T: type) type {
         }
 
         /// Returns the negation of a complex number.
-        pub fn neg(self: Self) Self {
+        pub fn neg(self: *const Self) Self {
             return Self{
                 .re = -self.re,
                 .im = -self.im,
@@ -95,7 +95,7 @@ pub fn Complex(comptime T: type) type {
         }
 
         /// Returns the product of complex number and i=sqrt(-1)
-        pub fn mulbyi(self: Self) Self {
+        pub fn mulbyi(self: *const Self) Self {
             return Self{
                 .re = -self.im,
                 .im = self.re,
@@ -103,7 +103,7 @@ pub fn Complex(comptime T: type) type {
         }
 
         /// Returns the reciprocal of a complex number.
-        pub fn reciprocal(self: Self) Self {
+        pub fn reciprocal(self: *const Self) Self {
             const m = self.re * self.re + self.im * self.im;
             return Self{
                 .re = self.re / m,
@@ -112,7 +112,7 @@ pub fn Complex(comptime T: type) type {
         }
 
         /// Returns the magnitude of a complex number.
-        pub fn magnitude(self: Self) T {
+        pub fn magnitude(self: *const Self) T {
             return @sqrt(self.re * self.re + self.im * self.im);
         }
     };
diff --git a/lib/std/mem.zig b/lib/std/mem.zig
index 4000030fc..4756c5f09 100644
--- a/lib/std/mem.zig
+++ b/lib/std/mem.zig
@@ -1944,7 +1944,7 @@ pub fn TokenIterator(comptime T: type) type {
         }
 
         /// Returns a slice of the remaining bytes. Does not affect iterator state.
-        pub fn rest(self: Self) []const T {
+        pub fn rest(self: *const Self) []const T {
             // move to beginning of token
             var index: usize = self.index;
             while (index < self.buffer.len and self.isSplitByte(self.buffer[index])) : (index += 1) {}
@@ -1996,7 +1996,7 @@ pub fn SplitIterator(comptime T: type) type {
         }
 
         /// Returns a slice of the remaining bytes. Does not affect iterator state.
-        pub fn rest(self: Self) []const T {
+        pub fn rest(self: *const Self) []const T {
             const end = self.buffer.len;
             const start = self.index orelse end;
             return self.buffer[start..end];
@@ -2038,7 +2038,7 @@ pub fn SplitBackwardsIterator(comptime T: type) type {
         }
 
         /// Returns a slice of the remaining bytes. Does not affect iterator state.
-        pub fn rest(self: Self) []const T {
+        pub fn rest(self: *const Self) []const T {
             const end = self.index orelse 0;
             return self.buffer[0..end];
         }
diff --git a/lib/std/mem/Allocator.zig b/lib/std/mem/Allocator.zig
index 4da37e922..e79e2e704 100644
--- a/lib/std/mem/Allocator.zig
+++ b/lib/std/mem/Allocator.zig
@@ -601,7 +601,7 @@ test "allocBytes non-zero len_align" {
 /// is less than or equal to the old allocation, because it cannot reclaim the memory,
 /// and thus the `std.ArrayList` would be better off retaining its capacity.
 pub fn reallocBytes(
-    self: Allocator,
+    self: *const Allocator,
     /// Must be the same as what was returned from most recent call to `allocFn` or `resizeFn`.
     /// If `old_mem.len == 0` then this is a new allocation and `new_byte_count` must be >= 1.
     old_mem: []u8,
diff --git a/lib/std/meta/trailer_flags.zig b/lib/std/meta/trailer_flags.zig
index 212a47bc2..128cbcd16 100644
--- a/lib/std/meta/trailer_flags.zig
+++ b/lib/std/meta/trailer_flags.zig
@@ -117,7 +117,7 @@ pub fn TrailerFlags(comptime Fields: type) type {
             return @typeInfo(Fields).Struct.fields[@enumToInt(field)].field_type;
         }
 
-        pub fn sizeInBytes(self: Self) usize {
+        pub fn sizeInBytes(self: *const Self) usize {
             var off: usize = 0;
             inline for (@typeInfo(Fields).Struct.fields) |field, i| {
                 if (@sizeOf(field.field_type) == 0)
diff --git a/lib/std/multi_array_list.zig b/lib/std/multi_array_list.zig
index c3bfa6537..68c010bb9 100644
--- a/lib/std/multi_array_list.zig
+++ b/lib/std/multi_array_list.zig
@@ -125,7 +125,7 @@ pub fn MultiArrayList(comptime S: type) type {
         /// Compute pointers to the start of each field of the array.
         /// If you need to access multiple fields, calling this may
         /// be more efficient than calling `items()` multiple times.
-        pub fn slice(self: Self) Slice {
+        pub fn slice(self: *const Self) Slice {
             var result: Slice = .{
                 .ptrs = undefined,
                 .len = self.len,
@@ -142,7 +142,7 @@ pub fn MultiArrayList(comptime S: type) type {
         /// Get the slice of values for a specified field.
         /// If you need multiple fields, consider calling slice()
         /// instead.
-        pub fn items(self: Self, comptime field: Field) []FieldType(field) {
+        pub fn items(self: *const Self, comptime field: Field) []FieldType(field) {
             return self.slice().items(field);
         }
 
@@ -155,7 +155,7 @@ pub fn MultiArrayList(comptime S: type) type {
         }
 
         /// Obtain all the data for one array element.
-        pub fn get(self: Self, index: usize) S {
+        pub fn get(self: *const Self, index: usize) S {
             const slices = self.slice();
             var result: S = undefined;
             inline for (fields) |field_info, i| {
@@ -391,7 +391,7 @@ pub fn MultiArrayList(comptime S: type) type {
 
         /// Create a copy of this list with a new backing store,
         /// using the specified allocator.
-        pub fn clone(self: Self, gpa: Allocator) !Self {
+        pub fn clone(self: *const Self, gpa: Allocator) !Self {
             var result = Self{};
             errdefer result.deinit(gpa);
             try result.ensureTotalCapacity(gpa, self.len);
@@ -409,7 +409,7 @@ pub fn MultiArrayList(comptime S: type) type {
 
         /// `ctx` has the following method:
         /// `fn lessThan(ctx: @TypeOf(ctx), a_index: usize, b_index: usize) bool`
-        pub fn sort(self: Self, ctx: anytype) void {
+        pub fn sort(self: *const Self, ctx: anytype) void {
             const SortContext = struct {
                 sub_ctx: @TypeOf(ctx),
                 slice: Slice,
@@ -441,7 +441,7 @@ pub fn MultiArrayList(comptime S: type) type {
             return @reduce(.Add, capacity_vector * sizes_vector);
         }
 
-        fn allocatedBytes(self: Self) []align(@alignOf(S)) u8 {
+        fn allocatedBytes(self: *const Self) []align(@alignOf(S)) u8 {
             return self.bytes[0..capacityInBytes(self.capacity)];
         }
 
diff --git a/lib/std/net.zig b/lib/std/net.zig
index 21fa36c4e..e47ce8844 100644
--- a/lib/std/net.zig
+++ b/lib/std/net.zig
@@ -169,7 +169,7 @@ pub const Address = extern union {
         return mem.eql(u8, a_bytes, b_bytes);
     }
 
-    pub fn getOsSockLen(self: Address) os.socklen_t {
+    pub fn getOsSockLen(self: *const Address) os.socklen_t {
         switch (self.any.family) {
             os.AF.INET => return self.in.getOsSockLen(),
             os.AF.INET6 => return self.in6.getOsSockLen(),
@@ -286,7 +286,7 @@ pub const Ip4Address = extern struct {
         });
     }
 
-    pub fn getOsSockLen(self: Ip4Address) os.socklen_t {
+    pub fn getOsSockLen(self: *const Ip4Address) os.socklen_t {
         _ = self;
         return @sizeOf(os.sockaddr.in);
     }
@@ -606,7 +606,7 @@ pub const Ip6Address = extern struct {
         try std.fmt.format(out_stream, "]:{}", .{port});
     }
 
-    pub fn getOsSockLen(self: Ip6Address) os.socklen_t {
+    pub fn getOsSockLen(self: *const Ip6Address) os.socklen_t {
         _ = self;
         return @sizeOf(os.sockaddr.in6);
     }
diff --git a/lib/std/os/linux.zig b/lib/std/os/linux.zig
index 8ca20bc33..2ac0016ce 100644
--- a/lib/std/os/linux.zig
+++ b/lib/std/os/linux.zig
@@ -3748,7 +3748,7 @@ pub const io_uring_cqe = extern struct {
     res: i32,
     flags: u32,
 
-    pub fn err(self: io_uring_cqe) E {
+    pub fn err(self: *const io_uring_cqe) E {
         if (self.res > -4096 and self.res < 0) {
             return @intToEnum(E, -self.res);
         }
diff --git a/lib/std/packed_int_array.zig b/lib/std/packed_int_array.zig
index 902e3ee19..bb5f95916 100644
--- a/lib/std/packed_int_array.zig
+++ b/lib/std/packed_int_array.zig
@@ -225,7 +225,7 @@ pub fn PackedIntArrayEndian(comptime Int: type, comptime endian: Endian, comptim
         }
 
         /// Return the integer stored at `index`.
-        pub fn get(self: Self, index: usize) Int {
+        pub fn get(self: *const Self, index: usize) Int {
             debug.assert(index < int_count);
             return Io.get(&self.bytes, index, 0);
         }
@@ -305,7 +305,7 @@ pub fn PackedIntSliceEndian(comptime Int: type, comptime endian: Endian) type {
         }
 
         /// Return the integer stored at `index`.
-        pub fn get(self: Self, index: usize) Int {
+        pub fn get(self: *const Self, index: usize) Int {
             debug.assert(index < self.len);
             return Io.get(self.bytes, index, self.bit_offset);
         }
@@ -317,7 +317,7 @@ pub fn PackedIntSliceEndian(comptime Int: type, comptime endian: Endian) type {
         }
 
         /// Create a PackedIntSlice of this slice from `start` to `end`.
-        pub fn slice(self: Self, start: usize, end: usize) PackedIntSliceEndian(Int, endian) {
+        pub fn slice(self: *const Self, start: usize, end: usize) PackedIntSliceEndian(Int, endian) {
             debug.assert(start < self.len);
             debug.assert(end <= self.len);
             return Io.slice(self.bytes, self.bit_offset, start, end);
@@ -325,14 +325,14 @@ pub fn PackedIntSliceEndian(comptime Int: type, comptime endian: Endian) type {
 
         /// Create a PackedIntSlice of the sclice using `NewInt` as the integer type.
         /// `NewInt`'s bit width must fit evenly within the slice's `Int`'s total bits.
-        pub fn sliceCast(self: Self, comptime NewInt: type) PackedIntSliceEndian(NewInt, endian) {
+        pub fn sliceCast(self: *const Self, comptime NewInt: type) PackedIntSliceEndian(NewInt, endian) {
             return self.sliceCastEndian(NewInt, endian);
         }
 
         /// Create a PackedIntSliceEndian of the slice using `NewInt` as the integer type
         /// and `new_endian` as the new endianess. `NewInt`'s bit width must fit evenly
         /// within the slice's `Int`'s total bits.
-        pub fn sliceCastEndian(self: Self, comptime NewInt: type, comptime new_endian: Endian) PackedIntSliceEndian(NewInt, new_endian) {
+        pub fn sliceCastEndian(self: *const Self, comptime NewInt: type, comptime new_endian: Endian) PackedIntSliceEndian(NewInt, new_endian) {
             return Io.sliceCast(self.bytes, NewInt, new_endian, self.bit_offset, self.len);
         }
     };
diff --git a/lib/std/priority_dequeue.zig b/lib/std/priority_dequeue.zig
index e82b3d9cc..13cb85a04 100644
--- a/lib/std/priority_dequeue.zig
+++ b/lib/std/priority_dequeue.zig
@@ -35,7 +35,7 @@ pub fn PriorityDequeue(comptime T: type, comptime Context: type, comptime compar
         }
 
         /// Free memory used by the dequeue.
-        pub fn deinit(self: Self) void {
+        pub fn deinit(self: *const Self) void {
             self.allocator.free(self.items);
         }
 
@@ -74,7 +74,7 @@ pub fn PriorityDequeue(comptime T: type, comptime Context: type, comptime compar
             return (highest_set_bit & 1) == 0;
         }
 
-        fn nextIsMinLayer(self: Self) bool {
+        fn nextIsMinLayer(self: *const Self) bool {
             return isMinLayer(self.len);
         }
 
@@ -83,7 +83,7 @@ pub fn PriorityDequeue(comptime T: type, comptime Context: type, comptime compar
             min_layer: bool,
         };
 
-        fn getStartForSiftUp(self: Self, child: T, index: usize) StartIndexAndLayer {
+        fn getStartForSiftUp(self: *const Self, child: T, index: usize) StartIndexAndLayer {
             var child_index = index;
             var parent_index = parentIndex(child_index);
             const parent = self.items[parent_index];
@@ -146,7 +146,7 @@ pub fn PriorityDequeue(comptime T: type, comptime Context: type, comptime compar
             return self.bestItemAtIndices(1, 2, .gt).item;
         }
 
-        fn maxIndex(self: Self) ?usize {
+        fn maxIndex(self: *const Self) ?usize {
             if (self.len == 0) return null;
             if (self.len == 1) return 0;
             if (self.len == 2) return 1;
@@ -272,14 +272,14 @@ pub fn PriorityDequeue(comptime T: type, comptime Context: type, comptime compar
             index: usize,
         };
 
-        fn getItem(self: Self, index: usize) ItemAndIndex {
+        fn getItem(self: *const Self, index: usize) ItemAndIndex {
             return .{
                 .item = self.items[index],
                 .index = index,
             };
         }
 
-        fn bestItem(self: Self, item1: ItemAndIndex, item2: ItemAndIndex, target_order: Order) ItemAndIndex {
+        fn bestItem(self: *const Self, item1: ItemAndIndex, item2: ItemAndIndex, target_order: Order) ItemAndIndex {
             if (compareFn(self.context, item1.item, item2.item) == target_order) {
                 return item1;
             } else {
@@ -287,13 +287,13 @@ pub fn PriorityDequeue(comptime T: type, comptime Context: type, comptime compar
             }
         }
 
-        fn bestItemAtIndices(self: Self, index1: usize, index2: usize, target_order: Order) ItemAndIndex {
+        fn bestItemAtIndices(self: *const Self, index1: usize, index2: usize, target_order: Order) ItemAndIndex {
             var item1 = self.getItem(index1);
             var item2 = self.getItem(index2);
             return self.bestItem(item1, item2, target_order);
         }
 
-        fn bestDescendent(self: Self, first_child_index: usize, first_grandchild_index: usize, target_order: Order) ItemAndIndex {
+        fn bestDescendent(self: *const Self, first_child_index: usize, first_grandchild_index: usize, target_order: Order) ItemAndIndex {
             const second_child_index = first_child_index + 1;
             if (first_grandchild_index >= self.len) {
                 // No grandchildren, find the best child (second may not exist)
@@ -325,13 +325,13 @@ pub fn PriorityDequeue(comptime T: type, comptime Context: type, comptime compar
         }
 
         /// Return the number of elements remaining in the dequeue
-        pub fn count(self: Self) usize {
+        pub fn count(self: *const Self) usize {
             return self.len;
         }
 
         /// Return the number of elements that can be added to the
         /// dequeue before more memory is allocated.
-        pub fn capacity(self: Self) usize {
+        pub fn capacity(self: *const Self) usize {
             return self.items.len;
         }
 
diff --git a/lib/std/priority_queue.zig b/lib/std/priority_queue.zig
index 3b65146fa..c5e080565 100644
--- a/lib/std/priority_queue.zig
+++ b/lib/std/priority_queue.zig
@@ -34,7 +34,7 @@ pub fn PriorityQueue(comptime T: type, comptime Context: type, comptime compareF
         }
 
         /// Free memory used by the queue.
-        pub fn deinit(self: Self) void {
+        pub fn deinit(self: *const Self) void {
             self.allocator.free(self.items);
         }
 
@@ -118,13 +118,13 @@ pub fn PriorityQueue(comptime T: type, comptime Context: type, comptime compareF
 
         /// Return the number of elements remaining in the priority
         /// queue.
-        pub fn count(self: Self) usize {
+        pub fn count(self: *const Self) usize {
             return self.len;
         }
 
         /// Return the number of elements that can be added to the
         /// queue before more memory is allocated.
-        pub fn capacity(self: Self) usize {
+        pub fn capacity(self: *const Self) usize {
             return self.items.len;
         }
 
diff --git a/lib/std/process.zig b/lib/std/process.zig
index 2c51ec2d6..5e83436bc 100644
--- a/lib/std/process.zig
+++ b/lib/std/process.zig
@@ -159,7 +159,7 @@ pub const EnvMap = struct {
     /// Find the address of the value associated with a key.
     /// The returned pointer is invalidated if the map resizes.
     /// On Windows `key` must be a valid UTF-8 string.
-    pub fn getPtr(self: EnvMap, key: []const u8) ?*[]const u8 {
+    pub fn getPtr(self: *const EnvMap, key: []const u8) ?*[]const u8 {
         return self.hash_map.getPtr(key);
     }
 
@@ -167,7 +167,7 @@ pub const EnvMap = struct {
     /// a key.  The returned string is invalidated if this
     /// key is removed from the map.
     /// On Windows `key` must be a valid UTF-8 string.
-    pub fn get(self: EnvMap, key: []const u8) ?[]const u8 {
+    pub fn get(self: *const EnvMap, key: []const u8) ?[]const u8 {
         return self.hash_map.get(key);
     }
 
@@ -181,7 +181,7 @@ pub const EnvMap = struct {
     }
 
     /// Returns the number of KV pairs stored in the map.
-    pub fn count(self: EnvMap) HashMap.Size {
+    pub fn count(self: *const EnvMap) HashMap.Size {
         return self.hash_map.count();
     }
 
@@ -190,11 +190,11 @@ pub const EnvMap = struct {
         return self.hash_map.iterator();
     }
 
-    fn free(self: EnvMap, value: []const u8) void {
+    fn free(self: *const EnvMap, value: []const u8) void {
         self.hash_map.allocator.free(value);
     }
 
-    fn copy(self: EnvMap, value: []const u8) ![]u8 {
+    fn copy(self: *const EnvMap, value: []const u8) ![]u8 {
         return self.hash_map.allocator.dupe(u8, value);
     }
 };
diff --git a/lib/std/sort.zig b/lib/std/sort.zig
index 64b0711d8..0b8b1001d 100644
--- a/lib/std/sort.zig
+++ b/lib/std/sort.zig
@@ -117,7 +117,7 @@ const Range = struct {
         };
     }
 
-    fn length(self: Range) usize {
+    fn length(self: *const Range) usize {
         return self.end - self.start;
     }
 };
diff --git a/lib/std/target.zig b/lib/std/target.zig
index 1b6e4aba0..5fd927d95 100644
--- a/lib/std/target.zig
+++ b/lib/std/target.zig
@@ -613,8 +613,8 @@ pub const Target = struct {
         /// Nvidia PTX format
         nvptx,
 
-        pub fn fileExt(of: ObjectFormat, cpu_arch: Cpu.Arch) [:0]const u8 {
-            return switch (of) {
+        pub fn fileExt(of: *const ObjectFormat, cpu_arch: Cpu.Arch) [:0]const u8 {
+            return switch (of.*) {
                 .coff => ".obj",
                 .elf, .macho, .wasm => ".o",
                 .c => ".c",
@@ -704,7 +704,7 @@ pub const Target = struct {
                     } else true;
                 }
 
-                pub fn isEnabled(set: Set, arch_feature_index: Index) bool {
+                pub fn isEnabled(set: *const Set, arch_feature_index: Index) bool {
                     const usize_index = arch_feature_index / @bitSizeOf(usize);
                     const bit_index = @intCast(ShiftInt, arch_feature_index % @bitSizeOf(usize));
                     return (set.ints[usize_index] & (@as(usize, 1) << bit_index)) != 0;
@@ -755,11 +755,11 @@ pub const Target = struct {
                     return @ptrCast(*const [byte_count]u8, &set.ints);
                 }
 
-                pub fn eql(set: Set, other_set: Set) bool {
+                pub fn eql(set: *const Set, other_set: Set) bool {
                     return mem.eql(usize, &set.ints, &other_set.ints);
                 }
 
-                pub fn isSuperSetOf(set: Set, other_set: Set) bool {
+                pub fn isSuperSetOf(set: *const Set, other_set: Set) bool {
                     const V = @Vector(usize_count, usize);
                     const set_v: V = set.ints;
                     const other_v: V = other_set.ints;
@@ -1401,7 +1401,7 @@ pub const Target = struct {
 
     pub const stack_align = 16;
 
-    pub fn zigTriple(self: Target, allocator: mem.Allocator) ![]u8 {
+    pub fn zigTriple(self: *const Target, allocator: mem.Allocator) ![]u8 {
         return std.zig.CrossTarget.fromTarget(self).zigTriple(allocator);
     }
 
@@ -1409,7 +1409,7 @@ pub const Target = struct {
         return std.fmt.allocPrint(allocator, "{s}-{s}-{s}", .{ @tagName(cpu_arch), @tagName(os_tag), @tagName(abi) });
     }
 
-    pub fn linuxTriple(self: Target, allocator: mem.Allocator) ![]u8 {
+    pub fn linuxTriple(self: *const Target, allocator: mem.Allocator) ![]u8 {
         return linuxTripleSimple(allocator, self.cpu.arch, self.os.tag, self.abi);
     }
 
@@ -1425,7 +1425,7 @@ pub const Target = struct {
         };
     }
 
-    pub fn exeFileExt(self: Target) [:0]const u8 {
+    pub fn exeFileExt(self: *const Target) [:0]const u8 {
         return exeFileExtSimple(self.cpu.arch, self.os.tag);
     }
 
@@ -1439,11 +1439,11 @@ pub const Target = struct {
         }
     }
 
-    pub fn staticLibSuffix(self: Target) [:0]const u8 {
+    pub fn staticLibSuffix(self: *const Target) [:0]const u8 {
         return staticLibSuffix_os_abi(self.os.tag, self.abi);
     }
 
-    pub fn dynamicLibSuffix(self: Target) [:0]const u8 {
+    pub fn dynamicLibSuffix(self: *const Target) [:0]const u8 {
         return self.os.tag.dynamicLibSuffix();
     }
 
@@ -1457,39 +1457,39 @@ pub const Target = struct {
         }
     }
 
-    pub fn libPrefix(self: Target) [:0]const u8 {
+    pub fn libPrefix(self: *const Target) [:0]const u8 {
         return libPrefix_os_abi(self.os.tag, self.abi);
     }
 
-    pub fn isMinGW(self: Target) bool {
+    pub fn isMinGW(self: *const Target) bool {
         return self.os.tag == .windows and self.isGnu();
     }
 
-    pub fn isGnu(self: Target) bool {
+    pub fn isGnu(self: *const Target) bool {
         return self.abi.isGnu();
     }
 
-    pub fn isMusl(self: Target) bool {
+    pub fn isMusl(self: *const Target) bool {
         return self.abi.isMusl();
     }
 
-    pub fn isAndroid(self: Target) bool {
+    pub fn isAndroid(self: *const Target) bool {
         return self.abi == .android;
     }
 
-    pub fn isWasm(self: Target) bool {
+    pub fn isWasm(self: *const Target) bool {
         return self.cpu.arch.isWasm();
     }
 
-    pub fn isDarwin(self: Target) bool {
+    pub fn isDarwin(self: *const Target) bool {
         return self.os.tag.isDarwin();
     }
 
-    pub fn isBSD(self: Target) bool {
+    pub fn isBSD(self: *const Target) bool {
         return self.os.tag.isBSD();
     }
 
-    pub fn isBpfFreestanding(self: Target) bool {
+    pub fn isBpfFreestanding(self: *const Target) bool {
         return self.cpu.arch.isBpf() and self.os.tag == .freestanding;
     }
 
@@ -1497,11 +1497,11 @@ pub const Target = struct {
         return os_tag == .linux and abi.isGnu();
     }
 
-    pub fn isGnuLibC(self: Target) bool {
+    pub fn isGnuLibC(self: *const Target) bool {
         return isGnuLibC_os_tag_abi(self.os.tag, self.abi);
     }
 
-    pub fn supportsNewStackCall(self: Target) bool {
+    pub fn supportsNewStackCall(self: *const Target) bool {
         return !self.cpu.arch.isWasm();
     }
 
@@ -1511,11 +1511,11 @@ pub const Target = struct {
         soft_fp,
     };
 
-    pub fn getFloatAbi(self: Target) FloatAbi {
+    pub fn getFloatAbi(self: *const Target) FloatAbi {
         return self.abi.floatAbi();
     }
 
-    pub fn hasDynamicLinker(self: Target) bool {
+    pub fn hasDynamicLinker(self: *const Target) bool {
         if (self.cpu.arch.isWasm()) {
             return false;
         }
@@ -1571,7 +1571,7 @@ pub const Target = struct {
         }
     };
 
-    pub fn standardDynamicLinkerPath(self: Target) DynamicLinker {
+    pub fn standardDynamicLinkerPath(self: *const Target) DynamicLinker {
         var result: DynamicLinker = .{};
         const S = struct {
             fn print(r: *DynamicLinker, comptime fmt: []const u8, args: anytype) DynamicLinker {
diff --git a/lib/std/time.zig b/lib/std/time.zig
index ea830d9dd..ecd3160cb 100644
--- a/lib/std/time.zig
+++ b/lib/std/time.zig
@@ -197,7 +197,7 @@ pub const Instant = struct {
     }
 
     /// Quickly compares two instances between each other.
-    pub fn order(self: Instant, other: Instant) std.math.Order {
+    pub fn order(self: *const Instant, other: Instant) std.math.Order {
         // windows and wasi timestamps are in u64 which is easily comparible
         if (!is_posix) {
             return std.math.order(self.timestamp, other.timestamp);
@@ -213,7 +213,7 @@ pub const Instant = struct {
     /// Returns elapsed time in nanoseconds since the `earlier` Instant.
     /// This assumes that the `earlier` Instant represents a moment in time before or equal to `self`.
     /// This also assumes that the time that has passed between both Instants fits inside a u64 (~585 yrs).
-    pub fn since(self: Instant, earlier: Instant) u64 {
+    pub fn since(self: *const Instant, earlier: Instant) u64 {
         if (builtin.os.tag == .windows) {
             // We don't need to cache QPF as it's internally just a memory read to KUSER_SHARED_DATA
             // (a read-only page of info updated and mapped by the kernel to all processes):
diff --git a/lib/std/time/epoch.zig b/lib/std/time/epoch.zig
index 0a9c18656..b9649a505 100644
--- a/lib/std/time/epoch.zig
+++ b/lib/std/time/epoch.zig
@@ -113,7 +113,7 @@ pub const YearAndDay = struct {
     /// The number of days into the year (0 to 365)
     day: u9,
 
-    pub fn calculateMonthDay(self: YearAndDay) MonthAndDay {
+    pub fn calculateMonthDay(self: *const YearAndDay) MonthAndDay {
         var month: Month = .jan;
         var days_left = self.day;
         const leap_kind: YearLeapKind = if (isLeapYear(self.year)) .leap else .not_leap;
@@ -136,7 +136,7 @@ pub const MonthAndDay = struct {
 // days since epoch Oct 1, 1970
 pub const EpochDay = struct {
     day: u47, // u47 = u64 - u17 (because day = sec(u64) / secs_per_day(u17)
-    pub fn calculateYearDay(self: EpochDay) YearAndDay {
+    pub fn calculateYearDay(self: *const EpochDay) YearAndDay {
         var year_day = self.day;
         var year: Year = epoch_year;
         while (true) {
@@ -155,15 +155,15 @@ pub const DaySeconds = struct {
     secs: u17, // max is 24*60*60 = 86400
 
     /// the number of hours past the start of the day (0 to 23)
-    pub fn getHoursIntoDay(self: DaySeconds) u5 {
+    pub fn getHoursIntoDay(self: *const DaySeconds) u5 {
         return @intCast(u5, @divTrunc(self.secs, 3600));
     }
     /// the number of minutes past the hour (0 to 59)
-    pub fn getMinutesIntoHour(self: DaySeconds) u6 {
+    pub fn getMinutesIntoHour(self: *const DaySeconds) u6 {
         return @intCast(u6, @divTrunc(@mod(self.secs, 3600), 60));
     }
     /// the number of seconds past the start of the minute (0 to 59)
-    pub fn getSecondsIntoMinute(self: DaySeconds) u6 {
+    pub fn getSecondsIntoMinute(self: *const DaySeconds) u6 {
         return math.comptimeMod(self.secs, 60);
     }
 };
@@ -174,13 +174,13 @@ pub const EpochSeconds = struct {
 
     /// Returns the number of days since the epoch as an EpochDay.
     /// Use EpochDay to get information about the day of this time.
-    pub fn getEpochDay(self: EpochSeconds) EpochDay {
+    pub fn getEpochDay(self: *const EpochSeconds) EpochDay {
         return EpochDay{ .day = @intCast(u47, @divTrunc(self.secs, secs_per_day)) };
     }
 
     /// Returns the number of seconds into the day as DaySeconds.
     /// Use DaySeconds to get information about the time.
-    pub fn getDaySeconds(self: EpochSeconds) DaySeconds {
+    pub fn getDaySeconds(self: *const EpochSeconds) DaySeconds {
         return DaySeconds{ .secs = math.comptimeMod(self.secs, secs_per_day) };
     }
 };
diff --git a/lib/std/treap.zig b/lib/std/treap.zig
index a74256356..f6c87043c 100644
--- a/lib/std/treap.zig
+++ b/lib/std/treap.zig
@@ -149,7 +149,7 @@ pub fn Treap(comptime Key: type, comptime compareFn: anytype) type {
             }
         };
 
-        fn find(self: Self, key: Key, parent_ref: *?*Node) ?*Node {
+        fn find(self: *const Self, key: Key, parent_ref: *?*Node) ?*Node {
             var node = self.root;
             parent_ref.* = null;
 
diff --git a/lib/std/x/net/ip.zig b/lib/std/x/net/ip.zig
index a3f5dfecf..0aead40d6 100644
--- a/lib/std/x/net/ip.zig
+++ b/lib/std/x/net/ip.zig
@@ -33,8 +33,8 @@ pub const Address = union(enum) {
     }
 
     /// Re-interpret an IP address into a generic socket address.
-    pub fn into(self: ip.Address) Socket.Address {
-        return switch (self) {
+    pub fn into(self: *const ip.Address) Socket.Address {
+        return switch (self.*) {
             .ipv4 => |ipv4_address| .{ .ipv4 = ipv4_address },
             .ipv6 => |ipv6_address| .{ .ipv6 = ipv6_address },
         };
diff --git a/lib/std/x/net/tcp.zig b/lib/std/x/net/tcp.zig
index a750e27fc..8f0ece9e3 100644
--- a/lib/std/x/net/tcp.zig
+++ b/lib/std/x/net/tcp.zig
@@ -95,17 +95,17 @@ pub const Client = struct {
     }
 
     /// Closes the client.
-    pub fn deinit(self: Client) void {
+    pub fn deinit(self: *const Client) void {
         self.socket.deinit();
     }
 
     /// Shutdown either the read side, write side, or all sides of the client's underlying socket.
-    pub fn shutdown(self: Client, how: os.ShutdownHow) !void {
+    pub fn shutdown(self: *const Client, how: os.ShutdownHow) !void {
         return self.socket.shutdown(how);
     }
 
     /// Have the client attempt to the connect to an address.
-    pub fn connect(self: Client, address: ip.Address) !void {
+    pub fn connect(self: *const Client, address: ip.Address) !void {
         return self.socket.connect(address.into());
     }
 
@@ -116,63 +116,63 @@ pub const Client = struct {
     }
 
     /// Wrap `tcp.Client` into `std.io.Reader`.
-    pub fn reader(self: Client, flags: u32) io.Reader(Client.Reader, ErrorSetOf(Client.Reader.read), Client.Reader.read) {
-        return .{ .context = .{ .client = self, .flags = flags } };
+    pub fn reader(self: *const Client, flags: u32) io.Reader(Client.Reader, ErrorSetOf(Client.Reader.read), Client.Reader.read) {
+        return .{ .context = .{ .client = self.*, .flags = flags } };
     }
 
     /// Wrap `tcp.Client` into `std.io.Writer`.
     pub fn writer(self: Client, flags: u32) io.Writer(Client.Writer, ErrorSetOf(Client.Writer.write), Client.Writer.write) {
-        return .{ .context = .{ .client = self, .flags = flags } };
+        return .{ .context = .{ .client = self.*, .flags = flags } };
     }
 
     /// Read data from the socket into the buffer provided with a set of flags
     /// specified. It returns the number of bytes read into the buffer provided.
-    pub fn read(self: Client, buf: []u8, flags: u32) !usize {
+    pub fn read(self: *const Client, buf: []u8, flags: u32) !usize {
         return self.socket.read(buf, flags);
     }
 
     /// Write a buffer of data provided to the socket with a set of flags specified.
     /// It returns the number of bytes that are written to the socket.
-    pub fn write(self: Client, buf: []const u8, flags: u32) !usize {
+    pub fn write(self: *const Client, buf: []const u8, flags: u32) !usize {
         return self.socket.write(buf, flags);
     }
 
     /// Writes multiple I/O vectors with a prepended message header to the socket
     /// with a set of flags specified. It returns the number of bytes that are
     /// written to the socket.
-    pub fn writeMessage(self: Client, msg: Socket.Message, flags: u32) !usize {
+    pub fn writeMessage(self: *const Client, msg: Socket.Message, flags: u32) !usize {
         return self.socket.writeMessage(msg, flags);
     }
 
     /// Read multiple I/O vectors with a prepended message header from the socket
     /// with a set of flags specified. It returns the number of bytes that were
     /// read into the buffer provided.
-    pub fn readMessage(self: Client, msg: *Socket.Message, flags: u32) !usize {
+    pub fn readMessage(self: *const Client, msg: *Socket.Message, flags: u32) !usize {
         return self.socket.readMessage(msg, flags);
     }
 
     /// Query and return the latest cached error on the client's underlying socket.
-    pub fn getError(self: Client) !void {
+    pub fn getError(self: *const Client) !void {
         return self.socket.getError();
     }
 
     /// Query the read buffer size of the client's underlying socket.
-    pub fn getReadBufferSize(self: Client) !u32 {
+    pub fn getReadBufferSize(self: *const Client) !u32 {
         return self.socket.getReadBufferSize();
     }
 
     /// Query the write buffer size of the client's underlying socket.
-    pub fn getWriteBufferSize(self: Client) !u32 {
+    pub fn getWriteBufferSize(self: *const Client) !u32 {
         return self.socket.getWriteBufferSize();
     }
 
     /// Query the address that the client's socket is locally bounded to.
-    pub fn getLocalAddress(self: Client) !ip.Address {
+    pub fn getLocalAddress(self: *const Client) !ip.Address {
         return ip.Address.from(try self.socket.getLocalAddress());
     }
 
     /// Query the address that the socket is connected to.
-    pub fn getRemoteAddress(self: Client) !ip.Address {
+    pub fn getRemoteAddress(self: *const Client) !ip.Address {
         return ip.Address.from(try self.socket.getRemoteAddress());
     }
 
@@ -180,20 +180,20 @@ pub const Client = struct {
     /// sent, or if the timeout specified in seconds has been reached. It returns `error.UnsupportedSocketOption`
     /// if the host does not support the option for a socket to linger around up until a timeout specified in
     /// seconds.
-    pub fn setLinger(self: Client, timeout_seconds: ?u16) !void {
+    pub fn setLinger(self: *const Client, timeout_seconds: ?u16) !void {
         return self.socket.setLinger(timeout_seconds);
     }
 
     /// Have keep-alive messages be sent periodically. The timing in which keep-alive messages are sent are
     /// dependant on operating system settings. It returns `error.UnsupportedSocketOption` if the host does
     /// not support periodically sending keep-alive messages on connection-oriented sockets.
-    pub fn setKeepAlive(self: Client, enabled: bool) !void {
+    pub fn setKeepAlive(self: *const Client, enabled: bool) !void {
         return self.socket.setKeepAlive(enabled);
     }
 
     /// Disable Nagle's algorithm on a TCP socket. It returns `error.UnsupportedSocketOption` if
     /// the host does not support sockets disabling Nagle's algorithm.
-    pub fn setNoDelay(self: Client, enabled: bool) !void {
+    pub fn setNoDelay(self: *const Client, enabled: bool) !void {
         if (@hasDecl(os.TCP, "NODELAY")) {
             const bytes = mem.asBytes(&@as(usize, @boolToInt(enabled)));
             return self.socket.setOption(os.IPPROTO.TCP, os.TCP.NODELAY, bytes);
@@ -203,7 +203,7 @@ pub const Client = struct {
 
     /// Enables TCP Quick ACK on a TCP socket to immediately send rather than delay ACKs when necessary. It returns
     /// `error.UnsupportedSocketOption` if the host does not support TCP Quick ACK.
-    pub fn setQuickACK(self: Client, enabled: bool) !void {
+    pub fn setQuickACK(self: *const Client, enabled: bool) !void {
         if (@hasDecl(os.TCP, "QUICKACK")) {
             return self.socket.setOption(os.IPPROTO.TCP, os.TCP.QUICKACK, mem.asBytes(&@as(u32, @boolToInt(enabled))));
         }
@@ -211,19 +211,19 @@ pub const Client = struct {
     }
 
     /// Set the write buffer size of the socket.
-    pub fn setWriteBufferSize(self: Client, size: u32) !void {
+    pub fn setWriteBufferSize(self: *const Client, size: u32) !void {
         return self.socket.setWriteBufferSize(size);
     }
 
     /// Set the read buffer size of the socket.
-    pub fn setReadBufferSize(self: Client, size: u32) !void {
+    pub fn setReadBufferSize(self: *const Client, size: u32) !void {
         return self.socket.setReadBufferSize(size);
     }
 
     /// Set a timeout on the socket that is to occur if no messages are successfully written
     /// to its bound destination after a specified number of milliseconds. A subsequent write
     /// to the socket will thereafter return `error.WouldBlock` should the timeout be exceeded.
-    pub fn setWriteTimeout(self: Client, milliseconds: u32) !void {
+    pub fn setWriteTimeout(self: *const Client, milliseconds: u32) !void {
         return self.socket.setWriteTimeout(milliseconds);
     }
 
@@ -231,7 +231,7 @@ pub const Client = struct {
     /// from its bound destination after a specified number of milliseconds. A subsequent
     /// read from the socket will thereafter return `error.WouldBlock` should the timeout be
     /// exceeded.
-    pub fn setReadTimeout(self: Client, milliseconds: u32) !void {
+    pub fn setReadTimeout(self: *const Client, milliseconds: u32) !void {
         return self.socket.setReadTimeout(milliseconds);
     }
 };
@@ -253,58 +253,58 @@ pub const Listener = struct {
     }
 
     /// Closes the listener.
-    pub fn deinit(self: Listener) void {
+    pub fn deinit(self: *const Listener) void {
         self.socket.deinit();
     }
 
     /// Shuts down the underlying listener's socket. The next subsequent call, or
     /// a current pending call to accept() after shutdown is called will return
     /// an error.
-    pub fn shutdown(self: Listener) !void {
+    pub fn shutdown(self: *const Listener) !void {
         return self.socket.shutdown(.recv);
     }
 
     /// Binds the listener's socket to an address.
-    pub fn bind(self: Listener, address: ip.Address) !void {
+    pub fn bind(self: *const Listener, address: ip.Address) !void {
         return self.socket.bind(address.into());
     }
 
     /// Start listening for incoming connections.
-    pub fn listen(self: Listener, max_backlog_size: u31) !void {
+    pub fn listen(self: *const Listener, max_backlog_size: u31) !void {
         return self.socket.listen(max_backlog_size);
     }
 
     /// Accept a pending incoming connection queued to the kernel backlog
     /// of the listener's socket.
-    pub fn accept(self: Listener, flags: std.enums.EnumFieldStruct(Socket.InitFlags, bool, false)) !tcp.Connection {
+    pub fn accept(self: *const Listener, flags: std.enums.EnumFieldStruct(Socket.InitFlags, bool, false)) !tcp.Connection {
         return tcp.Connection.from(try self.socket.accept(flags));
     }
 
     /// Query and return the latest cached error on the listener's underlying socket.
-    pub fn getError(self: Client) !void {
+    pub fn getError(self: *const Client) !void {
         return self.socket.getError();
     }
 
     /// Query the address that the listener's socket is locally bounded to.
-    pub fn getLocalAddress(self: Listener) !ip.Address {
+    pub fn getLocalAddress(self: *const Listener) !ip.Address {
         return ip.Address.from(try self.socket.getLocalAddress());
     }
 
     /// Allow multiple sockets on the same host to listen on the same address. It returns `error.UnsupportedSocketOption` if
     /// the host does not support sockets listening the same address.
-    pub fn setReuseAddress(self: Listener, enabled: bool) !void {
+    pub fn setReuseAddress(self: *const Listener, enabled: bool) !void {
         return self.socket.setReuseAddress(enabled);
     }
 
     /// Allow multiple sockets on the same host to listen on the same port. It returns `error.UnsupportedSocketOption` if
     /// the host does not supports sockets listening on the same port.
-    pub fn setReusePort(self: Listener, enabled: bool) !void {
+    pub fn setReusePort(self: *const Listener, enabled: bool) !void {
         return self.socket.setReusePort(enabled);
     }
 
     /// Enables TCP Fast Open (RFC 7413) on a TCP socket. It returns `error.UnsupportedSocketOption` if the host does not
     /// support TCP Fast Open.
-    pub fn setFastOpen(self: Listener, enabled: bool) !void {
+    pub fn setFastOpen(self: *const Listener, enabled: bool) !void {
         if (@hasDecl(os.TCP, "FASTOPEN")) {
             return self.socket.setOption(os.IPPROTO.TCP, os.TCP.FASTOPEN, mem.asBytes(&@as(u32, @boolToInt(enabled))));
         }
@@ -314,7 +314,7 @@ pub const Listener = struct {
     /// Set a timeout on the listener that is to occur if no new incoming connections come in
     /// after a specified number of milliseconds. A subsequent accept call to the listener
     /// will thereafter return `error.WouldBlock` should the timeout be exceeded.
-    pub fn setAcceptTimeout(self: Listener, milliseconds: usize) !void {
+    pub fn setAcceptTimeout(self: *const Listener, milliseconds: usize) !void {
         return self.socket.setReadTimeout(milliseconds);
     }
 };
diff --git a/lib/std/x/os/io.zig b/lib/std/x/os/io.zig
index 35e7c3e1e..e0c2a17f8 100644
--- a/lib/std/x/os/io.zig
+++ b/lib/std/x/os/io.zig
@@ -73,11 +73,11 @@ pub const Reactor = struct {
         return Reactor{ .fd = try os.epoll_create1(raw_flags) };
     }
 
-    pub fn deinit(self: Reactor) void {
+    pub fn deinit(self: *const Reactor) void {
         os.close(self.fd);
     }
 
-    pub fn update(self: Reactor, fd: os.fd_t, identifier: usize, interest: Reactor.Interest) !void {
+    pub fn update(self: *const Reactor, fd: os.fd_t, identifier: usize, interest: Reactor.Interest) !void {
         var flags: u32 = 0;
         flags |= if (interest.oneshot) linux.EPOLL.ONESHOT else linux.EPOLL.ET;
         if (interest.hup) flags |= linux.EPOLL.RDHUP;
@@ -95,7 +95,7 @@ pub const Reactor = struct {
         };
     }
 
-    pub fn poll(self: Reactor, comptime max_num_events: comptime_int, closure: anytype, timeout_milliseconds: ?u64) !void {
+    pub fn poll(self: *const Reactor, comptime max_num_events: comptime_int, closure: anytype, timeout_milliseconds: ?u64) !void {
         var events: [max_num_events]linux.epoll_event = undefined;
 
         const num_events = os.epoll_wait(self.fd, &events, if (timeout_milliseconds) |ms| @intCast(i32, ms) else -1);
diff --git a/lib/std/x/os/net.zig b/lib/std/x/os/net.zig
index d8af2b357..684bf8562 100644
--- a/lib/std/x/os/net.zig
+++ b/lib/std/x/os/net.zig
@@ -309,7 +309,7 @@ pub const IPv6 = extern struct {
     }
 
     /// Returns true if the address maps to an IPv4 address.
-    pub fn mapsToIPv4(self: IPv6) bool {
+    pub fn mapsToIPv4(self: *const IPv6) bool {
         return mem.startsWith(u8, &self.octets, &v4_mapped_prefix);
     }
 
diff --git a/lib/std/x/os/socket.zig b/lib/std/x/os/socket.zig
index ed354681e..64c5f4e2b 100644
--- a/lib/std/x/os/socket.zig
+++ b/lib/std/x/os/socket.zig
@@ -90,11 +90,11 @@ pub const Socket = struct {
 
         /// Encodes a generic socket address into an extern union that may be reliably
         /// casted into a `sockaddr` which may be passed into socket syscalls.
-        pub fn toNative(self: Socket.Address) extern union {
+        pub fn toNative(self: *const Socket.Address) extern union {
             ipv4: os.sockaddr.in,
             ipv6: os.sockaddr.in6,
         } {
-            return switch (self) {
+            return switch (self.*) {
                 .ipv4 => |address| .{
                     .ipv4 = .{
                         .addr = @bitCast(u32, address.host.octets),
@@ -113,8 +113,8 @@ pub const Socket = struct {
         }
 
         /// Returns the number of bytes that make up the `sockaddr` equivalent to the address.
-        pub fn getNativeSize(self: Socket.Address) u32 {
-            return switch (self) {
+        pub fn getNativeSize(self: *const Socket.Address) u32 {
+            return switch (self.*) {
                 .ipv4 => @sizeOf(os.sockaddr.in),
                 .ipv6 => @sizeOf(os.sockaddr.in6),
             };
diff --git a/lib/std/x/os/socket_posix.zig b/lib/std/x/os/socket_posix.zig
index 859075aa2..078568941 100644
--- a/lib/std/x/os/socket_posix.zig
+++ b/lib/std/x/os/socket_posix.zig
@@ -16,33 +16,33 @@ pub fn Mixin(comptime Socket: type) type {
         }
 
         /// Closes the socket.
-        pub fn deinit(self: Socket) void {
+        pub fn deinit(self: *const Socket) void {
             os.closeSocket(self.fd);
         }
 
         /// Shutdown either the read side, write side, or all side of the socket.
-        pub fn shutdown(self: Socket, how: os.ShutdownHow) !void {
+        pub fn shutdown(self: *const Socket, how: os.ShutdownHow) !void {
             return os.shutdown(self.fd, how);
         }
 
         /// Binds the socket to an address.
-        pub fn bind(self: Socket, address: Socket.Address) !void {
+        pub fn bind(self: *const Socket, address: Socket.Address) !void {
             return os.bind(self.fd, @ptrCast(*const os.sockaddr, &address.toNative()), address.getNativeSize());
         }
 
         /// Start listening for incoming connections on the socket.
-        pub fn listen(self: Socket, max_backlog_size: u31) !void {
+        pub fn listen(self: *const Socket, max_backlog_size: u31) !void {
             return os.listen(self.fd, max_backlog_size);
         }
 
         /// Have the socket attempt to the connect to an address.
-        pub fn connect(self: Socket, address: Socket.Address) !void {
+        pub fn connect(self: *const Socket, address: Socket.Address) !void {
             return os.connect(self.fd, @ptrCast(*const os.sockaddr, &address.toNative()), address.getNativeSize());
         }
 
         /// Accept a pending incoming connection queued to the kernel backlog
         /// of the socket.
-        pub fn accept(self: Socket, flags: std.enums.EnumFieldStruct(Socket.InitFlags, bool, false)) !Socket.Connection {
+        pub fn accept(self: *const Socket, flags: std.enums.EnumFieldStruct(Socket.InitFlags, bool, false)) !Socket.Connection {
             var address: Socket.Address.Native.Storage = undefined;
             var address_len: u32 = @sizeOf(Socket.Address.Native.Storage);
 
@@ -59,20 +59,20 @@ pub fn Mixin(comptime Socket: type) type {
 
         /// Read data from the socket into the buffer provided with a set of flags
         /// specified. It returns the number of bytes read into the buffer provided.
-        pub fn read(self: Socket, buf: []u8, flags: u32) !usize {
+        pub fn read(self: *const Socket, buf: []u8, flags: u32) !usize {
             return os.recv(self.fd, buf, flags);
         }
 
         /// Write a buffer of data provided to the socket with a set of flags specified.
         /// It returns the number of bytes that are written to the socket.
-        pub fn write(self: Socket, buf: []const u8, flags: u32) !usize {
+        pub fn write(self: *const Socket, buf: []const u8, flags: u32) !usize {
             return os.send(self.fd, buf, flags);
         }
 
         /// Writes multiple I/O vectors with a prepended message header to the socket
         /// with a set of flags specified. It returns the number of bytes that are
         /// written to the socket.
-        pub fn writeMessage(self: Socket, msg: Socket.Message, flags: u32) !usize {
+        pub fn writeMessage(self: *const Socket, msg: Socket.Message, flags: u32) !usize {
             while (true) {
                 const rc = os.system.sendmsg(self.fd, &msg, @intCast(c_int, flags));
                 return switch (os.errno(rc)) {
@@ -110,7 +110,7 @@ pub fn Mixin(comptime Socket: type) type {
         /// Read multiple I/O vectors with a prepended message header from the socket
         /// with a set of flags specified. It returns the number of bytes that were
         /// read into the buffer provided.
-        pub fn readMessage(self: Socket, msg: *Socket.Message, flags: u32) !usize {
+        pub fn readMessage(self: *const Socket, msg: *Socket.Message, flags: u32) !usize {
             while (true) {
                 const rc = os.system.recvmsg(self.fd, msg, @intCast(c_int, flags));
                 return switch (os.errno(rc)) {
@@ -131,7 +131,7 @@ pub fn Mixin(comptime Socket: type) type {
         }
 
         /// Query the address that the socket is locally bounded to.
-        pub fn getLocalAddress(self: Socket) !Socket.Address {
+        pub fn getLocalAddress(self: *const Socket) !Socket.Address {
             var address: Socket.Address.Native.Storage = undefined;
             var address_len: u32 = @sizeOf(Socket.Address.Native.Storage);
             try os.getsockname(self.fd, @ptrCast(*os.sockaddr, &address), &address_len);
@@ -139,7 +139,7 @@ pub fn Mixin(comptime Socket: type) type {
         }
 
         /// Query the address that the socket is connected to.
-        pub fn getRemoteAddress(self: Socket) !Socket.Address {
+        pub fn getRemoteAddress(self: *const Socket) !Socket.Address {
             var address: Socket.Address.Native.Storage = undefined;
             var address_len: u32 = @sizeOf(Socket.Address.Native.Storage);
             try os.getpeername(self.fd, @ptrCast(*os.sockaddr, &address), &address_len);
@@ -147,12 +147,12 @@ pub fn Mixin(comptime Socket: type) type {
         }
 
         /// Query and return the latest cached error on the socket.
-        pub fn getError(self: Socket) !void {
+        pub fn getError(self: *const Socket) !void {
             return os.getsockoptError(self.fd);
         }
 
         /// Query the read buffer size of the socket.
-        pub fn getReadBufferSize(self: Socket) !u32 {
+        pub fn getReadBufferSize(self: *const Socket) !u32 {
             var value: u32 = undefined;
             var value_len: u32 = @sizeOf(u32);
 
@@ -169,7 +169,7 @@ pub fn Mixin(comptime Socket: type) type {
         }
 
         /// Query the write buffer size of the socket.
-        pub fn getWriteBufferSize(self: Socket) !u32 {
+        pub fn getWriteBufferSize(self: *const Socket) !u32 {
             var value: u32 = undefined;
             var value_len: u32 = @sizeOf(u32);
 
@@ -186,7 +186,7 @@ pub fn Mixin(comptime Socket: type) type {
         }
 
         /// Set a socket option.
-        pub fn setOption(self: Socket, level: u32, code: u32, value: []const u8) !void {
+        pub fn setOption(self: *const Socket, level: u32, code: u32, value: []const u8) !void {
             return os.setsockopt(self.fd, level, code, value);
         }
 
@@ -194,7 +194,7 @@ pub fn Mixin(comptime Socket: type) type {
         /// sent, or if the timeout specified in seconds has been reached. It returns `error.UnsupportedSocketOption`
         /// if the host does not support the option for a socket to linger around up until a timeout specified in
         /// seconds.
-        pub fn setLinger(self: Socket, timeout_seconds: ?u16) !void {
+        pub fn setLinger(self: *const Socket, timeout_seconds: ?u16) !void {
             if (@hasDecl(os.SO, "LINGER")) {
                 const settings = Socket.Linger.init(timeout_seconds);
                 return self.setOption(os.SOL.SOCKET, os.SO.LINGER, mem.asBytes(&settings));
@@ -206,7 +206,7 @@ pub fn Mixin(comptime Socket: type) type {
         /// On connection-oriented sockets, have keep-alive messages be sent periodically. The timing in which keep-alive
         /// messages are sent are dependant on operating system settings. It returns `error.UnsupportedSocketOption` if
         /// the host does not support periodically sending keep-alive messages on connection-oriented sockets.
-        pub fn setKeepAlive(self: Socket, enabled: bool) !void {
+        pub fn setKeepAlive(self: *const Socket, enabled: bool) !void {
             if (@hasDecl(os.SO, "KEEPALIVE")) {
                 return self.setOption(os.SOL.SOCKET, os.SO.KEEPALIVE, mem.asBytes(&@as(u32, @boolToInt(enabled))));
             }
@@ -215,7 +215,7 @@ pub fn Mixin(comptime Socket: type) type {
 
         /// Allow multiple sockets on the same host to listen on the same address. It returns `error.UnsupportedSocketOption` if
         /// the host does not support sockets listening the same address.
-        pub fn setReuseAddress(self: Socket, enabled: bool) !void {
+        pub fn setReuseAddress(self: *const Socket, enabled: bool) !void {
             if (@hasDecl(os.SO, "REUSEADDR")) {
                 return self.setOption(os.SOL.SOCKET, os.SO.REUSEADDR, mem.asBytes(&@as(u32, @boolToInt(enabled))));
             }
@@ -224,7 +224,7 @@ pub fn Mixin(comptime Socket: type) type {
 
         /// Allow multiple sockets on the same host to listen on the same port. It returns `error.UnsupportedSocketOption` if
         /// the host does not supports sockets listening on the same port.
-        pub fn setReusePort(self: Socket, enabled: bool) !void {
+        pub fn setReusePort(self: *const Socket, enabled: bool) !void {
             if (@hasDecl(os.SO, "REUSEPORT")) {
                 return self.setOption(os.SOL.SOCKET, os.SO.REUSEPORT, mem.asBytes(&@as(u32, @boolToInt(enabled))));
             }
@@ -232,12 +232,12 @@ pub fn Mixin(comptime Socket: type) type {
         }
 
         /// Set the write buffer size of the socket.
-        pub fn setWriteBufferSize(self: Socket, size: u32) !void {
+        pub fn setWriteBufferSize(self: *const Socket, size: u32) !void {
             return self.setOption(os.SOL.SOCKET, os.SO.SNDBUF, mem.asBytes(&size));
         }
 
         /// Set the read buffer size of the socket.
-        pub fn setReadBufferSize(self: Socket, size: u32) !void {
+        pub fn setReadBufferSize(self: *const Socket, size: u32) !void {
             return self.setOption(os.SOL.SOCKET, os.SO.RCVBUF, mem.asBytes(&size));
         }
 
@@ -247,7 +247,7 @@ pub fn Mixin(comptime Socket: type) type {
         /// Set a timeout on the socket that is to occur if no messages are successfully written
         /// to its bound destination after a specified number of milliseconds. A subsequent write
         /// to the socket will thereafter return `error.WouldBlock` should the timeout be exceeded.
-        pub fn setWriteTimeout(self: Socket, milliseconds: usize) !void {
+        pub fn setWriteTimeout(self: *const Socket, milliseconds: usize) !void {
             const timeout = os.timeval{
                 .tv_sec = @intCast(i32, milliseconds / time.ms_per_s),
                 .tv_usec = @intCast(i32, (milliseconds % time.ms_per_s) * time.us_per_ms),
@@ -263,7 +263,7 @@ pub fn Mixin(comptime Socket: type) type {
         /// from its bound destination after a specified number of milliseconds. A subsequent
         /// read from the socket will thereafter return `error.WouldBlock` should the timeout be
         /// exceeded.
-        pub fn setReadTimeout(self: Socket, milliseconds: usize) !void {
+        pub fn setReadTimeout(self: *const Socket, milliseconds: usize) !void {
             const timeout = os.timeval{
                 .tv_sec = @intCast(i32, milliseconds / time.ms_per_s),
                 .tv_usec = @intCast(i32, (milliseconds % time.ms_per_s) * time.us_per_ms),
diff --git a/lib/std/zig/Ast.zig b/lib/std/zig/Ast.zig
index 62a567387..a37c59745 100644
--- a/lib/std/zig/Ast.zig
+++ b/lib/std/zig/Ast.zig
@@ -52,7 +52,7 @@ pub const RenderError = error{
 /// for allocating extra stack memory if needed, because this function utilizes recursion.
 /// Note: that's not actually true yet, see https://github.com/ziglang/zig/issues/1006.
 /// Caller owns the returned slice of bytes, allocated with `gpa`.
-pub fn render(tree: Ast, gpa: mem.Allocator) RenderError![]u8 {
+pub fn render(tree: *const Ast, gpa: mem.Allocator) RenderError![]u8 {
     var buffer = std.ArrayList(u8).init(gpa);
     defer buffer.deinit();
 
@@ -60,20 +60,20 @@ pub fn render(tree: Ast, gpa: mem.Allocator) RenderError![]u8 {
     return buffer.toOwnedSlice();
 }
 
-pub fn renderToArrayList(tree: Ast, buffer: *std.ArrayList(u8)) RenderError!void {
-    return @import("./render.zig").renderTree(buffer, tree);
+pub fn renderToArrayList(tree: *const Ast, buffer: *std.ArrayList(u8)) RenderError!void {
+    return @import("./render.zig").renderTree(buffer, tree.*);
 }
 
 /// Returns an extra offset for column and byte offset of errors that
 /// should point after the token in the error message.
-pub fn errorOffset(tree: Ast, parse_error: Error) u32 {
+pub fn errorOffset(tree: *const Ast, parse_error: Error) u32 {
     return if (parse_error.token_is_prev)
         @intCast(u32, tree.tokenSlice(parse_error.token).len)
     else
         0;
 }
 
-pub fn tokenLocation(self: Ast, start_offset: ByteOffset, token_index: TokenIndex) Location {
+pub fn tokenLocation(self: *const Ast, start_offset: ByteOffset, token_index: TokenIndex) Location {
     var loc = Location{
         .line = 0,
         .column = 0,
@@ -100,7 +100,7 @@ pub fn tokenLocation(self: Ast, start_offset: ByteOffset, token_index: TokenInde
     return loc;
 }
 
-pub fn tokenSlice(tree: Ast, token_index: TokenIndex) []const u8 {
+pub fn tokenSlice(tree: *const Ast, token_index: TokenIndex) []const u8 {
     const token_starts = tree.tokens.items(.start);
     const token_tags = tree.tokens.items(.tag);
     const token_tag = token_tags[token_index];
@@ -121,7 +121,7 @@ pub fn tokenSlice(tree: Ast, token_index: TokenIndex) []const u8 {
     return tree.source[token.loc.start..token.loc.end];
 }
 
-pub fn extraData(tree: Ast, index: usize, comptime T: type) T {
+pub fn extraData(tree: *const Ast, index: usize, comptime T: type) T {
     const fields = std.meta.fields(T);
     var result: T = undefined;
     inline for (fields) |field, i| {
@@ -131,13 +131,13 @@ pub fn extraData(tree: Ast, index: usize, comptime T: type) T {
     return result;
 }
 
-pub fn rootDecls(tree: Ast) []const Node.Index {
+pub fn rootDecls(tree: *const Ast) []const Node.Index {
     // Root is always index 0.
     const nodes_data = tree.nodes.items(.data);
     return tree.extra_data[nodes_data[0].lhs..nodes_data[0].rhs];
 }
 
-pub fn renderError(tree: Ast, parse_error: Error, stream: anytype) !void {
+pub fn renderError(tree: *const Ast, parse_error: Error, stream: anytype) !void {
     const token_tags = tree.tokens.items(.tag);
     switch (parse_error.tag) {
         .asterisk_after_ptr_deref => {
@@ -372,7 +372,7 @@ pub fn renderError(tree: Ast, parse_error: Error, stream: anytype) !void {
     }
 }
 
-pub fn firstToken(tree: Ast, node: Node.Index) TokenIndex {
+pub fn firstToken(tree: *const Ast, node: Node.Index) TokenIndex {
     const tags = tree.nodes.items(.tag);
     const datas = tree.nodes.items(.data);
     const main_tokens = tree.nodes.items(.main_token);
@@ -686,7 +686,7 @@ pub fn firstToken(tree: Ast, node: Node.Index) TokenIndex {
     };
 }
 
-pub fn lastToken(tree: Ast, node: Node.Index) TokenIndex {
+pub fn lastToken(tree: *const Ast, node: Node.Index) TokenIndex {
     const tags = tree.nodes.items(.tag);
     const datas = tree.nodes.items(.data);
     const main_tokens = tree.nodes.items(.main_token);
@@ -1218,13 +1218,13 @@ pub fn lastToken(tree: Ast, node: Node.Index) TokenIndex {
     };
 }
 
-pub fn tokensOnSameLine(tree: Ast, token1: TokenIndex, token2: TokenIndex) bool {
+pub fn tokensOnSameLine(tree: *const Ast, token1: TokenIndex, token2: TokenIndex) bool {
     const token_starts = tree.tokens.items(.start);
     const source = tree.source[token_starts[token1]..token_starts[token2]];
     return mem.indexOfScalar(u8, source, '\n') == null;
 }
 
-pub fn getNodeSource(tree: Ast, node: Node.Index) []const u8 {
+pub fn getNodeSource(tree: *const Ast, node: Node.Index) []const u8 {
     const token_starts = tree.tokens.items(.start);
     const first_token = tree.firstToken(node);
     const last_token = tree.lastToken(node);
@@ -1233,7 +1233,7 @@ pub fn getNodeSource(tree: Ast, node: Node.Index) []const u8 {
     return tree.source[start..end];
 }
 
-pub fn globalVarDecl(tree: Ast, node: Node.Index) full.VarDecl {
+pub fn globalVarDecl(tree: *const Ast, node: Node.Index) full.VarDecl {
     assert(tree.nodes.items(.tag)[node] == .global_var_decl);
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.lhs, Node.GlobalVarDecl);
@@ -1247,7 +1247,7 @@ pub fn globalVarDecl(tree: Ast, node: Node.Index) full.VarDecl {
     });
 }
 
-pub fn localVarDecl(tree: Ast, node: Node.Index) full.VarDecl {
+pub fn localVarDecl(tree: *const Ast, node: Node.Index) full.VarDecl {
     assert(tree.nodes.items(.tag)[node] == .local_var_decl);
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.lhs, Node.LocalVarDecl);
@@ -1261,7 +1261,7 @@ pub fn localVarDecl(tree: Ast, node: Node.Index) full.VarDecl {
     });
 }
 
-pub fn simpleVarDecl(tree: Ast, node: Node.Index) full.VarDecl {
+pub fn simpleVarDecl(tree: *const Ast, node: Node.Index) full.VarDecl {
     assert(tree.nodes.items(.tag)[node] == .simple_var_decl);
     const data = tree.nodes.items(.data)[node];
     return tree.fullVarDecl(.{
@@ -1274,7 +1274,7 @@ pub fn simpleVarDecl(tree: Ast, node: Node.Index) full.VarDecl {
     });
 }
 
-pub fn alignedVarDecl(tree: Ast, node: Node.Index) full.VarDecl {
+pub fn alignedVarDecl(tree: *const Ast, node: Node.Index) full.VarDecl {
     assert(tree.nodes.items(.tag)[node] == .aligned_var_decl);
     const data = tree.nodes.items(.data)[node];
     return tree.fullVarDecl(.{
@@ -1287,7 +1287,7 @@ pub fn alignedVarDecl(tree: Ast, node: Node.Index) full.VarDecl {
     });
 }
 
-pub fn ifSimple(tree: Ast, node: Node.Index) full.If {
+pub fn ifSimple(tree: *const Ast, node: Node.Index) full.If {
     assert(tree.nodes.items(.tag)[node] == .if_simple);
     const data = tree.nodes.items(.data)[node];
     return tree.fullIf(.{
@@ -1298,7 +1298,7 @@ pub fn ifSimple(tree: Ast, node: Node.Index) full.If {
     });
 }
 
-pub fn ifFull(tree: Ast, node: Node.Index) full.If {
+pub fn ifFull(tree: *const Ast, node: Node.Index) full.If {
     assert(tree.nodes.items(.tag)[node] == .@"if");
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.rhs, Node.If);
@@ -1310,7 +1310,7 @@ pub fn ifFull(tree: Ast, node: Node.Index) full.If {
     });
 }
 
-pub fn containerField(tree: Ast, node: Node.Index) full.ContainerField {
+pub fn containerField(tree: *const Ast, node: Node.Index) full.ContainerField {
     assert(tree.nodes.items(.tag)[node] == .container_field);
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.rhs, Node.ContainerField);
@@ -1322,7 +1322,7 @@ pub fn containerField(tree: Ast, node: Node.Index) full.ContainerField {
     });
 }
 
-pub fn containerFieldInit(tree: Ast, node: Node.Index) full.ContainerField {
+pub fn containerFieldInit(tree: *const Ast, node: Node.Index) full.ContainerField {
     assert(tree.nodes.items(.tag)[node] == .container_field_init);
     const data = tree.nodes.items(.data)[node];
     return tree.fullContainerField(.{
@@ -1333,7 +1333,7 @@ pub fn containerFieldInit(tree: Ast, node: Node.Index) full.ContainerField {
     });
 }
 
-pub fn containerFieldAlign(tree: Ast, node: Node.Index) full.ContainerField {
+pub fn containerFieldAlign(tree: *const Ast, node: Node.Index) full.ContainerField {
     assert(tree.nodes.items(.tag)[node] == .container_field_align);
     const data = tree.nodes.items(.data)[node];
     return tree.fullContainerField(.{
@@ -1344,7 +1344,7 @@ pub fn containerFieldAlign(tree: Ast, node: Node.Index) full.ContainerField {
     });
 }
 
-pub fn fnProtoSimple(tree: Ast, buffer: *[1]Node.Index, node: Node.Index) full.FnProto {
+pub fn fnProtoSimple(tree: *const Ast, buffer: *[1]Node.Index, node: Node.Index) full.FnProto {
     assert(tree.nodes.items(.tag)[node] == .fn_proto_simple);
     const data = tree.nodes.items(.data)[node];
     buffer[0] = data.lhs;
@@ -1361,7 +1361,7 @@ pub fn fnProtoSimple(tree: Ast, buffer: *[1]Node.Index, node: Node.Index) full.F
     });
 }
 
-pub fn fnProtoMulti(tree: Ast, node: Node.Index) full.FnProto {
+pub fn fnProtoMulti(tree: *const Ast, node: Node.Index) full.FnProto {
     assert(tree.nodes.items(.tag)[node] == .fn_proto_multi);
     const data = tree.nodes.items(.data)[node];
     const params_range = tree.extraData(data.lhs, Node.SubRange);
@@ -1378,7 +1378,7 @@ pub fn fnProtoMulti(tree: Ast, node: Node.Index) full.FnProto {
     });
 }
 
-pub fn fnProtoOne(tree: Ast, buffer: *[1]Node.Index, node: Node.Index) full.FnProto {
+pub fn fnProtoOne(tree: *const Ast, buffer: *[1]Node.Index, node: Node.Index) full.FnProto {
     assert(tree.nodes.items(.tag)[node] == .fn_proto_one);
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.lhs, Node.FnProtoOne);
@@ -1396,7 +1396,7 @@ pub fn fnProtoOne(tree: Ast, buffer: *[1]Node.Index, node: Node.Index) full.FnPr
     });
 }
 
-pub fn fnProto(tree: Ast, node: Node.Index) full.FnProto {
+pub fn fnProto(tree: *const Ast, node: Node.Index) full.FnProto {
     assert(tree.nodes.items(.tag)[node] == .fn_proto);
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.lhs, Node.FnProto);
@@ -1413,7 +1413,7 @@ pub fn fnProto(tree: Ast, node: Node.Index) full.FnProto {
     });
 }
 
-pub fn structInitOne(tree: Ast, buffer: *[1]Node.Index, node: Node.Index) full.StructInit {
+pub fn structInitOne(tree: *const Ast, buffer: *[1]Node.Index, node: Node.Index) full.StructInit {
     assert(tree.nodes.items(.tag)[node] == .struct_init_one or
         tree.nodes.items(.tag)[node] == .struct_init_one_comma);
     const data = tree.nodes.items(.data)[node];
@@ -1426,7 +1426,7 @@ pub fn structInitOne(tree: Ast, buffer: *[1]Node.Index, node: Node.Index) full.S
     });
 }
 
-pub fn structInitDotTwo(tree: Ast, buffer: *[2]Node.Index, node: Node.Index) full.StructInit {
+pub fn structInitDotTwo(tree: *const Ast, buffer: *[2]Node.Index, node: Node.Index) full.StructInit {
     assert(tree.nodes.items(.tag)[node] == .struct_init_dot_two or
         tree.nodes.items(.tag)[node] == .struct_init_dot_two_comma);
     const data = tree.nodes.items(.data)[node];
@@ -1444,7 +1444,7 @@ pub fn structInitDotTwo(tree: Ast, buffer: *[2]Node.Index, node: Node.Index) ful
     });
 }
 
-pub fn structInitDot(tree: Ast, node: Node.Index) full.StructInit {
+pub fn structInitDot(tree: *const Ast, node: Node.Index) full.StructInit {
     assert(tree.nodes.items(.tag)[node] == .struct_init_dot or
         tree.nodes.items(.tag)[node] == .struct_init_dot_comma);
     const data = tree.nodes.items(.data)[node];
@@ -1455,7 +1455,7 @@ pub fn structInitDot(tree: Ast, node: Node.Index) full.StructInit {
     });
 }
 
-pub fn structInit(tree: Ast, node: Node.Index) full.StructInit {
+pub fn structInit(tree: *const Ast, node: Node.Index) full.StructInit {
     assert(tree.nodes.items(.tag)[node] == .struct_init or
         tree.nodes.items(.tag)[node] == .struct_init_comma);
     const data = tree.nodes.items(.data)[node];
@@ -1467,7 +1467,7 @@ pub fn structInit(tree: Ast, node: Node.Index) full.StructInit {
     });
 }
 
-pub fn arrayInitOne(tree: Ast, buffer: *[1]Node.Index, node: Node.Index) full.ArrayInit {
+pub fn arrayInitOne(tree: *const Ast, buffer: *[1]Node.Index, node: Node.Index) full.ArrayInit {
     assert(tree.nodes.items(.tag)[node] == .array_init_one or
         tree.nodes.items(.tag)[node] == .array_init_one_comma);
     const data = tree.nodes.items(.data)[node];
@@ -1482,7 +1482,7 @@ pub fn arrayInitOne(tree: Ast, buffer: *[1]Node.Index, node: Node.Index) full.Ar
     };
 }
 
-pub fn arrayInitDotTwo(tree: Ast, buffer: *[2]Node.Index, node: Node.Index) full.ArrayInit {
+pub fn arrayInitDotTwo(tree: *const Ast, buffer: *[2]Node.Index, node: Node.Index) full.ArrayInit {
     assert(tree.nodes.items(.tag)[node] == .array_init_dot_two or
         tree.nodes.items(.tag)[node] == .array_init_dot_two_comma);
     const data = tree.nodes.items(.data)[node];
@@ -1502,7 +1502,7 @@ pub fn arrayInitDotTwo(tree: Ast, buffer: *[2]Node.Index, node: Node.Index) full
     };
 }
 
-pub fn arrayInitDot(tree: Ast, node: Node.Index) full.ArrayInit {
+pub fn arrayInitDot(tree: *const Ast, node: Node.Index) full.ArrayInit {
     assert(tree.nodes.items(.tag)[node] == .array_init_dot or
         tree.nodes.items(.tag)[node] == .array_init_dot_comma);
     const data = tree.nodes.items(.data)[node];
@@ -1515,7 +1515,7 @@ pub fn arrayInitDot(tree: Ast, node: Node.Index) full.ArrayInit {
     };
 }
 
-pub fn arrayInit(tree: Ast, node: Node.Index) full.ArrayInit {
+pub fn arrayInit(tree: *const Ast, node: Node.Index) full.ArrayInit {
     assert(tree.nodes.items(.tag)[node] == .array_init or
         tree.nodes.items(.tag)[node] == .array_init_comma);
     const data = tree.nodes.items(.data)[node];
@@ -1529,7 +1529,7 @@ pub fn arrayInit(tree: Ast, node: Node.Index) full.ArrayInit {
     };
 }
 
-pub fn arrayType(tree: Ast, node: Node.Index) full.ArrayType {
+pub fn arrayType(tree: *const Ast, node: Node.Index) full.ArrayType {
     assert(tree.nodes.items(.tag)[node] == .array_type);
     const data = tree.nodes.items(.data)[node];
     return .{
@@ -1542,7 +1542,7 @@ pub fn arrayType(tree: Ast, node: Node.Index) full.ArrayType {
     };
 }
 
-pub fn arrayTypeSentinel(tree: Ast, node: Node.Index) full.ArrayType {
+pub fn arrayTypeSentinel(tree: *const Ast, node: Node.Index) full.ArrayType {
     assert(tree.nodes.items(.tag)[node] == .array_type_sentinel);
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.rhs, Node.ArrayTypeSentinel);
@@ -1557,7 +1557,7 @@ pub fn arrayTypeSentinel(tree: Ast, node: Node.Index) full.ArrayType {
     };
 }
 
-pub fn ptrTypeAligned(tree: Ast, node: Node.Index) full.PtrType {
+pub fn ptrTypeAligned(tree: *const Ast, node: Node.Index) full.PtrType {
     assert(tree.nodes.items(.tag)[node] == .ptr_type_aligned);
     const data = tree.nodes.items(.data)[node];
     return tree.fullPtrType(.{
@@ -1571,7 +1571,7 @@ pub fn ptrTypeAligned(tree: Ast, node: Node.Index) full.PtrType {
     });
 }
 
-pub fn ptrTypeSentinel(tree: Ast, node: Node.Index) full.PtrType {
+pub fn ptrTypeSentinel(tree: *const Ast, node: Node.Index) full.PtrType {
     assert(tree.nodes.items(.tag)[node] == .ptr_type_sentinel);
     const data = tree.nodes.items(.data)[node];
     return tree.fullPtrType(.{
@@ -1585,7 +1585,7 @@ pub fn ptrTypeSentinel(tree: Ast, node: Node.Index) full.PtrType {
     });
 }
 
-pub fn ptrType(tree: Ast, node: Node.Index) full.PtrType {
+pub fn ptrType(tree: *const Ast, node: Node.Index) full.PtrType {
     assert(tree.nodes.items(.tag)[node] == .ptr_type);
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.lhs, Node.PtrType);
@@ -1600,7 +1600,7 @@ pub fn ptrType(tree: Ast, node: Node.Index) full.PtrType {
     });
 }
 
-pub fn ptrTypeBitRange(tree: Ast, node: Node.Index) full.PtrType {
+pub fn ptrTypeBitRange(tree: *const Ast, node: Node.Index) full.PtrType {
     assert(tree.nodes.items(.tag)[node] == .ptr_type_bit_range);
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.lhs, Node.PtrTypeBitRange);
@@ -1615,7 +1615,7 @@ pub fn ptrTypeBitRange(tree: Ast, node: Node.Index) full.PtrType {
     });
 }
 
-pub fn sliceOpen(tree: Ast, node: Node.Index) full.Slice {
+pub fn sliceOpen(tree: *const Ast, node: Node.Index) full.Slice {
     assert(tree.nodes.items(.tag)[node] == .slice_open);
     const data = tree.nodes.items(.data)[node];
     return .{
@@ -1629,7 +1629,7 @@ pub fn sliceOpen(tree: Ast, node: Node.Index) full.Slice {
     };
 }
 
-pub fn slice(tree: Ast, node: Node.Index) full.Slice {
+pub fn slice(tree: *const Ast, node: Node.Index) full.Slice {
     assert(tree.nodes.items(.tag)[node] == .slice);
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.rhs, Node.Slice);
@@ -1644,7 +1644,7 @@ pub fn slice(tree: Ast, node: Node.Index) full.Slice {
     };
 }
 
-pub fn sliceSentinel(tree: Ast, node: Node.Index) full.Slice {
+pub fn sliceSentinel(tree: *const Ast, node: Node.Index) full.Slice {
     assert(tree.nodes.items(.tag)[node] == .slice_sentinel);
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.rhs, Node.SliceSentinel);
@@ -1659,7 +1659,7 @@ pub fn sliceSentinel(tree: Ast, node: Node.Index) full.Slice {
     };
 }
 
-pub fn containerDeclTwo(tree: Ast, buffer: *[2]Node.Index, node: Node.Index) full.ContainerDecl {
+pub fn containerDeclTwo(tree: *const Ast, buffer: *[2]Node.Index, node: Node.Index) full.ContainerDecl {
     assert(tree.nodes.items(.tag)[node] == .container_decl_two or
         tree.nodes.items(.tag)[node] == .container_decl_two_trailing);
     const data = tree.nodes.items(.data)[node];
@@ -1678,7 +1678,7 @@ pub fn containerDeclTwo(tree: Ast, buffer: *[2]Node.Index, node: Node.Index) ful
     });
 }
 
-pub fn containerDecl(tree: Ast, node: Node.Index) full.ContainerDecl {
+pub fn containerDecl(tree: *const Ast, node: Node.Index) full.ContainerDecl {
     assert(tree.nodes.items(.tag)[node] == .container_decl or
         tree.nodes.items(.tag)[node] == .container_decl_trailing);
     const data = tree.nodes.items(.data)[node];
@@ -1690,7 +1690,7 @@ pub fn containerDecl(tree: Ast, node: Node.Index) full.ContainerDecl {
     });
 }
 
-pub fn containerDeclArg(tree: Ast, node: Node.Index) full.ContainerDecl {
+pub fn containerDeclArg(tree: *const Ast, node: Node.Index) full.ContainerDecl {
     assert(tree.nodes.items(.tag)[node] == .container_decl_arg or
         tree.nodes.items(.tag)[node] == .container_decl_arg_trailing);
     const data = tree.nodes.items(.data)[node];
@@ -1703,7 +1703,7 @@ pub fn containerDeclArg(tree: Ast, node: Node.Index) full.ContainerDecl {
     });
 }
 
-pub fn containerDeclRoot(tree: Ast) full.ContainerDecl {
+pub fn containerDeclRoot(tree: *const Ast) full.ContainerDecl {
     return .{
         .layout_token = null,
         .ast = .{
@@ -1715,7 +1715,7 @@ pub fn containerDeclRoot(tree: Ast) full.ContainerDecl {
     };
 }
 
-pub fn taggedUnionTwo(tree: Ast, buffer: *[2]Node.Index, node: Node.Index) full.ContainerDecl {
+pub fn taggedUnionTwo(tree: *const Ast, buffer: *[2]Node.Index, node: Node.Index) full.ContainerDecl {
     assert(tree.nodes.items(.tag)[node] == .tagged_union_two or
         tree.nodes.items(.tag)[node] == .tagged_union_two_trailing);
     const data = tree.nodes.items(.data)[node];
@@ -1735,7 +1735,7 @@ pub fn taggedUnionTwo(tree: Ast, buffer: *[2]Node.Index, node: Node.Index) full.
     });
 }
 
-pub fn taggedUnion(tree: Ast, node: Node.Index) full.ContainerDecl {
+pub fn taggedUnion(tree: *const Ast, node: Node.Index) full.ContainerDecl {
     assert(tree.nodes.items(.tag)[node] == .tagged_union or
         tree.nodes.items(.tag)[node] == .tagged_union_trailing);
     const data = tree.nodes.items(.data)[node];
@@ -1748,7 +1748,7 @@ pub fn taggedUnion(tree: Ast, node: Node.Index) full.ContainerDecl {
     });
 }
 
-pub fn taggedUnionEnumTag(tree: Ast, node: Node.Index) full.ContainerDecl {
+pub fn taggedUnionEnumTag(tree: *const Ast, node: Node.Index) full.ContainerDecl {
     assert(tree.nodes.items(.tag)[node] == .tagged_union_enum_tag or
         tree.nodes.items(.tag)[node] == .tagged_union_enum_tag_trailing);
     const data = tree.nodes.items(.data)[node];
@@ -1762,7 +1762,7 @@ pub fn taggedUnionEnumTag(tree: Ast, node: Node.Index) full.ContainerDecl {
     });
 }
 
-pub fn switchCaseOne(tree: Ast, node: Node.Index) full.SwitchCase {
+pub fn switchCaseOne(tree: *const Ast, node: Node.Index) full.SwitchCase {
     const data = &tree.nodes.items(.data)[node];
     const values: *[1]Node.Index = &data.lhs;
     return tree.fullSwitchCase(.{
@@ -1772,7 +1772,7 @@ pub fn switchCaseOne(tree: Ast, node: Node.Index) full.SwitchCase {
     }, node);
 }
 
-pub fn switchCase(tree: Ast, node: Node.Index) full.SwitchCase {
+pub fn switchCase(tree: *const Ast, node: Node.Index) full.SwitchCase {
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.lhs, Node.SubRange);
     return tree.fullSwitchCase(.{
@@ -1782,7 +1782,7 @@ pub fn switchCase(tree: Ast, node: Node.Index) full.SwitchCase {
     }, node);
 }
 
-pub fn asmSimple(tree: Ast, node: Node.Index) full.Asm {
+pub fn asmSimple(tree: *const Ast, node: Node.Index) full.Asm {
     const data = tree.nodes.items(.data)[node];
     return tree.fullAsm(.{
         .asm_token = tree.nodes.items(.main_token)[node],
@@ -1792,7 +1792,7 @@ pub fn asmSimple(tree: Ast, node: Node.Index) full.Asm {
     });
 }
 
-pub fn asmFull(tree: Ast, node: Node.Index) full.Asm {
+pub fn asmFull(tree: *const Ast, node: Node.Index) full.Asm {
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.rhs, Node.Asm);
     return tree.fullAsm(.{
@@ -1803,7 +1803,7 @@ pub fn asmFull(tree: Ast, node: Node.Index) full.Asm {
     });
 }
 
-pub fn whileSimple(tree: Ast, node: Node.Index) full.While {
+pub fn whileSimple(tree: *const Ast, node: Node.Index) full.While {
     const data = tree.nodes.items(.data)[node];
     return tree.fullWhile(.{
         .while_token = tree.nodes.items(.main_token)[node],
@@ -1814,7 +1814,7 @@ pub fn whileSimple(tree: Ast, node: Node.Index) full.While {
     });
 }
 
-pub fn whileCont(tree: Ast, node: Node.Index) full.While {
+pub fn whileCont(tree: *const Ast, node: Node.Index) full.While {
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.rhs, Node.WhileCont);
     return tree.fullWhile(.{
@@ -1826,7 +1826,7 @@ pub fn whileCont(tree: Ast, node: Node.Index) full.While {
     });
 }
 
-pub fn whileFull(tree: Ast, node: Node.Index) full.While {
+pub fn whileFull(tree: *const Ast, node: Node.Index) full.While {
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.rhs, Node.While);
     return tree.fullWhile(.{
@@ -1838,7 +1838,7 @@ pub fn whileFull(tree: Ast, node: Node.Index) full.While {
     });
 }
 
-pub fn forSimple(tree: Ast, node: Node.Index) full.While {
+pub fn forSimple(tree: *const Ast, node: Node.Index) full.While {
     const data = tree.nodes.items(.data)[node];
     return tree.fullWhile(.{
         .while_token = tree.nodes.items(.main_token)[node],
@@ -1849,7 +1849,7 @@ pub fn forSimple(tree: Ast, node: Node.Index) full.While {
     });
 }
 
-pub fn forFull(tree: Ast, node: Node.Index) full.While {
+pub fn forFull(tree: *const Ast, node: Node.Index) full.While {
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.rhs, Node.If);
     return tree.fullWhile(.{
@@ -1861,7 +1861,7 @@ pub fn forFull(tree: Ast, node: Node.Index) full.While {
     });
 }
 
-pub fn callOne(tree: Ast, buffer: *[1]Node.Index, node: Node.Index) full.Call {
+pub fn callOne(tree: *const Ast, buffer: *[1]Node.Index, node: Node.Index) full.Call {
     const data = tree.nodes.items(.data)[node];
     buffer.* = .{data.rhs};
     const params = if (data.rhs != 0) buffer[0..1] else buffer[0..0];
@@ -1872,7 +1872,7 @@ pub fn callOne(tree: Ast, buffer: *[1]Node.Index, node: Node.Index) full.Call {
     });
 }
 
-pub fn callFull(tree: Ast, node: Node.Index) full.Call {
+pub fn callFull(tree: *const Ast, node: Node.Index) full.Call {
     const data = tree.nodes.items(.data)[node];
     const extra = tree.extraData(data.rhs, Node.SubRange);
     return tree.fullCall(.{
@@ -1882,7 +1882,7 @@ pub fn callFull(tree: Ast, node: Node.Index) full.Call {
     });
 }
 
-fn fullVarDecl(tree: Ast, info: full.VarDecl.Components) full.VarDecl {
+fn fullVarDecl(tree: *const Ast, info: full.VarDecl.Components) full.VarDecl {
     const token_tags = tree.tokens.items(.tag);
     var result: full.VarDecl = .{
         .ast = info,
@@ -1907,7 +1907,7 @@ fn fullVarDecl(tree: Ast, info: full.VarDecl.Components) full.VarDecl {
     return result;
 }
 
-fn fullIf(tree: Ast, info: full.If.Components) full.If {
+fn fullIf(tree: *const Ast, info: full.If.Components) full.If {
     const token_tags = tree.tokens.items(.tag);
     var result: full.If = .{
         .ast = info,
@@ -1932,7 +1932,7 @@ fn fullIf(tree: Ast, info: full.If.Components) full.If {
     return result;
 }
 
-fn fullContainerField(tree: Ast, info: full.ContainerField.Components) full.ContainerField {
+fn fullContainerField(tree: *const Ast, info: full.ContainerField.Components) full.ContainerField {
     const token_tags = tree.tokens.items(.tag);
     var result: full.ContainerField = .{
         .ast = info,
@@ -1946,7 +1946,7 @@ fn fullContainerField(tree: Ast, info: full.ContainerField.Components) full.Cont
     return result;
 }
 
-fn fullFnProto(tree: Ast, info: full.FnProto.Components) full.FnProto {
+fn fullFnProto(tree: *const Ast, info: full.FnProto.Components) full.FnProto {
     const token_tags = tree.tokens.items(.tag);
     var result: full.FnProto = .{
         .ast = info,
@@ -1982,7 +1982,7 @@ fn fullFnProto(tree: Ast, info: full.FnProto.Components) full.FnProto {
     return result;
 }
 
-fn fullStructInit(tree: Ast, info: full.StructInit.Components) full.StructInit {
+fn fullStructInit(tree: *const Ast, info: full.StructInit.Components) full.StructInit {
     _ = tree;
     var result: full.StructInit = .{
         .ast = info,
@@ -1990,7 +1990,7 @@ fn fullStructInit(tree: Ast, info: full.StructInit.Components) full.StructInit {
     return result;
 }
 
-fn fullPtrType(tree: Ast, info: full.PtrType.Components) full.PtrType {
+fn fullPtrType(tree: *const Ast, info: full.PtrType.Components) full.PtrType {
     const token_tags = tree.tokens.items(.tag);
     // TODO: looks like stage1 isn't quite smart enough to handle enum
     // literals in some places here
@@ -2039,7 +2039,7 @@ fn fullPtrType(tree: Ast, info: full.PtrType.Components) full.PtrType {
     return result;
 }
 
-fn fullContainerDecl(tree: Ast, info: full.ContainerDecl.Components) full.ContainerDecl {
+fn fullContainerDecl(tree: *const Ast, info: full.ContainerDecl.Components) full.ContainerDecl {
     const token_tags = tree.tokens.items(.tag);
     var result: full.ContainerDecl = .{
         .ast = info,
@@ -2052,7 +2052,7 @@ fn fullContainerDecl(tree: Ast, info: full.ContainerDecl.Components) full.Contai
     return result;
 }
 
-fn fullSwitchCase(tree: Ast, info: full.SwitchCase.Components, node: Node.Index) full.SwitchCase {
+fn fullSwitchCase(tree: *const Ast, info: full.SwitchCase.Components, node: Node.Index) full.SwitchCase {
     const token_tags = tree.tokens.items(.tag);
     const node_tags = tree.nodes.items(.tag);
     var result: full.SwitchCase = .{
@@ -2070,7 +2070,7 @@ fn fullSwitchCase(tree: Ast, info: full.SwitchCase.Components, node: Node.Index)
     return result;
 }
 
-fn fullAsm(tree: Ast, info: full.Asm.Components) full.Asm {
+fn fullAsm(tree: *const Ast, info: full.Asm.Components) full.Asm {
     const token_tags = tree.tokens.items(.tag);
     const node_tags = tree.nodes.items(.tag);
     var result: full.Asm = .{
@@ -2133,7 +2133,7 @@ fn fullAsm(tree: Ast, info: full.Asm.Components) full.Asm {
     return result;
 }
 
-fn fullWhile(tree: Ast, info: full.While.Components) full.While {
+fn fullWhile(tree: *const Ast, info: full.While.Components) full.While {
     const token_tags = tree.tokens.items(.tag);
     var result: full.While = .{
         .ast = info,
@@ -2168,7 +2168,7 @@ fn fullWhile(tree: Ast, info: full.While.Components) full.While {
     return result;
 }
 
-fn fullCall(tree: Ast, info: full.Call.Components) full.Call {
+fn fullCall(tree: *const Ast, info: full.Call.Components) full.Call {
     const token_tags = tree.tokens.items(.tag);
     var result: full.Call = .{
         .ast = info,
diff --git a/lib/std/zig/CrossTarget.zig b/lib/std/zig/CrossTarget.zig
index 6c59a4a3a..9c79ecd22 100644
--- a/lib/std/zig/CrossTarget.zig
+++ b/lib/std/zig/CrossTarget.zig
@@ -169,7 +169,7 @@ fn updateOsVersionRange(self: *CrossTarget, os: Target.Os) void {
 }
 
 /// TODO deprecated, use `std.zig.system.NativeTargetInfo.detect`.
-pub fn toTarget(self: CrossTarget) Target {
+pub fn toTarget(self: *const CrossTarget) Target {
     return .{
         .cpu = self.getCpu(),
         .os = self.getOs(),
@@ -354,7 +354,7 @@ pub fn parseCpuArch(args: ParseOptions) ?Target.Cpu.Arch {
 }
 
 /// TODO deprecated, use `std.zig.system.NativeTargetInfo.detect`.
-pub fn getCpu(self: CrossTarget) Target.Cpu {
+pub fn getCpu(self: *const CrossTarget) Target.Cpu {
     switch (self.cpu_model) {
         .native => {
             // This works when doing `zig build` because Zig generates a build executable using
@@ -385,23 +385,23 @@ pub fn getCpu(self: CrossTarget) Target.Cpu {
     }
 }
 
-pub fn getCpuArch(self: CrossTarget) Target.Cpu.Arch {
+pub fn getCpuArch(self: *const CrossTarget) Target.Cpu.Arch {
     return self.cpu_arch orelse builtin.cpu.arch;
 }
 
-pub fn getCpuModel(self: CrossTarget) *const Target.Cpu.Model {
+pub fn getCpuModel(self: *const CrossTarget) *const Target.Cpu.Model {
     return switch (self.cpu_model) {
         .explicit => |cpu_model| cpu_model,
         else => self.getCpu().model,
     };
 }
 
-pub fn getCpuFeatures(self: CrossTarget) Target.Cpu.Feature.Set {
+pub fn getCpuFeatures(self: *const CrossTarget) Target.Cpu.Feature.Set {
     return self.getCpu().features;
 }
 
 /// TODO deprecated, use `std.zig.system.NativeTargetInfo.detect`.
-pub fn getOs(self: CrossTarget) Target.Os {
+pub fn getOs(self: *const CrossTarget) Target.Os {
     // `builtin.os` works when doing `zig build` because Zig generates a build executable using
     // native OS version range. However this will not be accurate otherwise, and
     // will need to be integrated with `std.zig.system.NativeTargetInfo.detect`.
@@ -433,12 +433,12 @@ pub fn getOs(self: CrossTarget) Target.Os {
     return adjusted_os;
 }
 
-pub fn getOsTag(self: CrossTarget) Target.Os.Tag {
+pub fn getOsTag(self: *const CrossTarget) Target.Os.Tag {
     return self.os_tag orelse builtin.os.tag;
 }
 
 /// TODO deprecated, use `std.zig.system.NativeTargetInfo.detect`.
-pub fn getOsVersionMin(self: CrossTarget) OsVersion {
+pub fn getOsVersionMin(self: *const CrossTarget) OsVersion {
     if (self.os_version_min) |version_min| return version_min;
     var tmp: CrossTarget = undefined;
     tmp.updateOsVersionRange(self.getOs());
@@ -446,7 +446,7 @@ pub fn getOsVersionMin(self: CrossTarget) OsVersion {
 }
 
 /// TODO deprecated, use `std.zig.system.NativeTargetInfo.detect`.
-pub fn getOsVersionMax(self: CrossTarget) OsVersion {
+pub fn getOsVersionMax(self: *const CrossTarget) OsVersion {
     if (self.os_version_max) |version_max| return version_max;
     var tmp: CrossTarget = undefined;
     tmp.updateOsVersionRange(self.getOs());
@@ -454,7 +454,7 @@ pub fn getOsVersionMax(self: CrossTarget) OsVersion {
 }
 
 /// TODO deprecated, use `std.zig.system.NativeTargetInfo.detect`.
-pub fn getAbi(self: CrossTarget) Target.Abi {
+pub fn getAbi(self: *const CrossTarget) Target.Abi {
     if (self.abi) |abi| return abi;
 
     if (self.os_tag == null) {
@@ -467,74 +467,74 @@ pub fn getAbi(self: CrossTarget) Target.Abi {
     return Target.Abi.default(self.getCpuArch(), self.getOs());
 }
 
-pub fn isFreeBSD(self: CrossTarget) bool {
+pub fn isFreeBSD(self: *const CrossTarget) bool {
     return self.getOsTag() == .freebsd;
 }
 
-pub fn isDarwin(self: CrossTarget) bool {
+pub fn isDarwin(self: *const CrossTarget) bool {
     return self.getOsTag().isDarwin();
 }
 
-pub fn isNetBSD(self: CrossTarget) bool {
+pub fn isNetBSD(self: *const CrossTarget) bool {
     return self.getOsTag() == .netbsd;
 }
 
-pub fn isOpenBSD(self: CrossTarget) bool {
+pub fn isOpenBSD(self: *const CrossTarget) bool {
     return self.getOsTag() == .openbsd;
 }
 
-pub fn isUefi(self: CrossTarget) bool {
+pub fn isUefi(self: *const CrossTarget) bool {
     return self.getOsTag() == .uefi;
 }
 
-pub fn isDragonFlyBSD(self: CrossTarget) bool {
+pub fn isDragonFlyBSD(self: *const CrossTarget) bool {
     return self.getOsTag() == .dragonfly;
 }
 
-pub fn isLinux(self: CrossTarget) bool {
+pub fn isLinux(self: *const CrossTarget) bool {
     return self.getOsTag() == .linux;
 }
 
-pub fn isWindows(self: CrossTarget) bool {
+pub fn isWindows(self: *const CrossTarget) bool {
     return self.getOsTag() == .windows;
 }
 
-pub fn exeFileExt(self: CrossTarget) [:0]const u8 {
+pub fn exeFileExt(self: *const CrossTarget) [:0]const u8 {
     return Target.exeFileExtSimple(self.getCpuArch(), self.getOsTag());
 }
 
-pub fn staticLibSuffix(self: CrossTarget) [:0]const u8 {
+pub fn staticLibSuffix(self: *const CrossTarget) [:0]const u8 {
     return Target.staticLibSuffix_os_abi(self.getOsTag(), self.getAbi());
 }
 
-pub fn dynamicLibSuffix(self: CrossTarget) [:0]const u8 {
+pub fn dynamicLibSuffix(self: *const CrossTarget) [:0]const u8 {
     return self.getOsTag().dynamicLibSuffix();
 }
 
-pub fn libPrefix(self: CrossTarget) [:0]const u8 {
+pub fn libPrefix(self: *const CrossTarget) [:0]const u8 {
     return Target.libPrefix_os_abi(self.getOsTag(), self.getAbi());
 }
 
-pub fn isNativeCpu(self: CrossTarget) bool {
+pub fn isNativeCpu(self: *const CrossTarget) bool {
     return self.cpu_arch == null and
         (self.cpu_model == .native or self.cpu_model == .determined_by_cpu_arch) and
         self.cpu_features_sub.isEmpty() and self.cpu_features_add.isEmpty();
 }
 
-pub fn isNativeOs(self: CrossTarget) bool {
+pub fn isNativeOs(self: *const CrossTarget) bool {
     return self.os_tag == null and self.os_version_min == null and self.os_version_max == null and
         self.dynamic_linker.get() == null and self.glibc_version == null;
 }
 
-pub fn isNativeAbi(self: CrossTarget) bool {
+pub fn isNativeAbi(self: *const CrossTarget) bool {
     return self.os_tag == null and self.abi == null;
 }
 
-pub fn isNative(self: CrossTarget) bool {
+pub fn isNative(self: *const CrossTarget) bool {
     return self.isNativeCpu() and self.isNativeOs() and self.isNativeAbi();
 }
 
-pub fn zigTriple(self: CrossTarget, allocator: mem.Allocator) error{OutOfMemory}![]u8 {
+pub fn zigTriple(self: *const CrossTarget, allocator: mem.Allocator) error{OutOfMemory}![]u8 {
     if (self.isNative()) {
         return allocator.dupe(u8, "native");
     }
@@ -573,24 +573,24 @@ pub fn zigTriple(self: CrossTarget, allocator: mem.Allocator) error{OutOfMemory}
     return result.toOwnedSlice();
 }
 
-pub fn allocDescription(self: CrossTarget, allocator: mem.Allocator) ![]u8 {
+pub fn allocDescription(self: *const CrossTarget, allocator: mem.Allocator) ![]u8 {
     // TODO is there anything else worthy of the description that is not
     // already captured in the triple?
     return self.zigTriple(allocator);
 }
 
-pub fn linuxTriple(self: CrossTarget, allocator: mem.Allocator) ![]u8 {
+pub fn linuxTriple(self: *const CrossTarget, allocator: mem.Allocator) ![]u8 {
     return Target.linuxTripleSimple(allocator, self.getCpuArch(), self.getOsTag(), self.getAbi());
 }
 
-pub fn wantSharedLibSymLinks(self: CrossTarget) bool {
+pub fn wantSharedLibSymLinks(self: *const CrossTarget) bool {
     return self.getOsTag() != .windows;
 }
 
 pub const VcpkgLinkage = std.builtin.LinkMode;
 
 /// Returned slice must be freed by the caller.
-pub fn vcpkgTriplet(self: CrossTarget, allocator: mem.Allocator, linkage: VcpkgLinkage) ![]u8 {
+pub fn vcpkgTriplet(self: *const CrossTarget, allocator: mem.Allocator, linkage: VcpkgLinkage) ![]u8 {
     const arch = switch (self.getCpuArch()) {
         .i386 => "x86",
         .x86_64 => "x64",
@@ -624,7 +624,7 @@ pub fn vcpkgTriplet(self: CrossTarget, allocator: mem.Allocator, linkage: VcpkgL
     return std.fmt.allocPrint(allocator, "{s}-{s}{s}", .{ arch, os, static_suffix });
 }
 
-pub fn isGnuLibC(self: CrossTarget) bool {
+pub fn isGnuLibC(self: *const CrossTarget) bool {
     return Target.isGnuLibC_os_tag_abi(self.getOsTag(), self.getAbi());
 }
 
@@ -633,11 +633,11 @@ pub fn setGnuLibCVersion(self: *CrossTarget, major: u32, minor: u32, patch: u32)
     self.glibc_version = SemVer{ .major = major, .minor = minor, .patch = patch };
 }
 
-pub fn getObjectFormat(self: CrossTarget) Target.ObjectFormat {
+pub fn getObjectFormat(self: *const CrossTarget) Target.ObjectFormat {
     return self.ofmt orelse Target.ObjectFormat.default(self.getOsTag(), self.getCpuArch());
 }
 
-pub fn updateCpuFeatures(self: CrossTarget, set: *Target.Cpu.Feature.Set) void {
+pub fn updateCpuFeatures(self: *const CrossTarget, set: *Target.Cpu.Feature.Set) void {
     set.removeFeatureSet(self.cpu_features_sub);
     set.addFeatureSet(self.cpu_features_add);
     set.populateDependencies(self.getCpuArch().allFeaturesList());
diff --git a/lib/std/zig/parse.zig b/lib/std/zig/parse.zig
index db56cef21..1d47d63f1 100644
--- a/lib/std/zig/parse.zig
+++ b/lib/std/zig/parse.zig
@@ -102,7 +102,7 @@ const Parser = struct {
         rhs: Node.Index,
         trailing: bool,
 
-        fn toSpan(self: Members, p: *Parser) !Node.SubRange {
+        fn toSpan(self: *const Members, p: *Parser) !Node.SubRange {
             if (self.len <= 2) {
                 const nodes = [2]Node.Index{ self.lhs, self.rhs };
                 return p.listToSpan(nodes[0..self.len]);
diff --git a/lib/std/zig/tokenizer.zig b/lib/std/zig/tokenizer.zig
index d322b98f7..421ca6dde 100644
--- a/lib/std/zig/tokenizer.zig
+++ b/lib/std/zig/tokenizer.zig
@@ -318,8 +318,8 @@ pub const Token = struct {
             };
         }
 
-        pub fn symbol(tag: Tag) []const u8 {
-            return tag.lexeme() orelse switch (tag) {
+        pub fn symbol(tag: *const Tag) []const u8 {
+            return tag.lexeme() orelse switch (tag.*) {
                 .invalid => "invalid bytes",
                 .identifier => "an identifier",
                 .string_literal, .multiline_string_literal_line => "a string literal",
